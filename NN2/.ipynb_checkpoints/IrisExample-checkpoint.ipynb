{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnVLqgJPKZYn"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, from_numpy, optim\n",
    "import numpy as np\n",
    "#pandas- librărie pentru lucrul cu fișierele\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoINPLfdmvGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ioana/faculta/si/regresie/my_proj\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "df=pd.read_csv(\"iris.csv\",header=0, error_bad_lines=False, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGjK2mEym5gP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [2, 4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [3, 4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4, 4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5, 5.0, 3.6, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [6, 5.4, 3.9, 1.7, 0.4, 'Iris-setosa'],\n",
       "       [7, 4.6, 3.4, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [8, 5.0, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [9, 4.4, 2.9, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [10, 4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [11, 5.4, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [12, 4.8, 3.4, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [13, 4.8, 3.0, 1.4, 0.1, 'Iris-setosa'],\n",
       "       [14, 4.3, 3.0, 1.1, 0.1, 'Iris-setosa'],\n",
       "       [15, 5.8, 4.0, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [16, 5.7, 4.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [17, 5.4, 3.9, 1.3, 0.4, 'Iris-setosa'],\n",
       "       [18, 5.1, 3.5, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [19, 5.7, 3.8, 1.7, 0.3, 'Iris-setosa'],\n",
       "       [20, 5.1, 3.8, 1.5, 0.3, 'Iris-setosa'],\n",
       "       [21, 5.4, 3.4, 1.7, 0.2, 'Iris-setosa'],\n",
       "       [22, 5.1, 3.7, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [23, 4.6, 3.6, 1.0, 0.2, 'Iris-setosa'],\n",
       "       [24, 5.1, 3.3, 1.7, 0.5, 'Iris-setosa'],\n",
       "       [25, 4.8, 3.4, 1.9, 0.2, 'Iris-setosa'],\n",
       "       [26, 5.0, 3.0, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [27, 5.0, 3.4, 1.6, 0.4, 'Iris-setosa'],\n",
       "       [28, 5.2, 3.5, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [29, 5.2, 3.4, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [30, 4.7, 3.2, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [31, 4.8, 3.1, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [32, 5.4, 3.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [33, 5.2, 4.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [34, 5.5, 4.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [35, 4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [36, 5.0, 3.2, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [37, 5.5, 3.5, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [38, 4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [39, 4.4, 3.0, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [40, 5.1, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [41, 5.0, 3.5, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [42, 4.5, 2.3, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [43, 4.4, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [44, 5.0, 3.5, 1.6, 0.6, 'Iris-setosa'],\n",
       "       [45, 5.1, 3.8, 1.9, 0.4, 'Iris-setosa'],\n",
       "       [46, 4.8, 3.0, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [47, 5.1, 3.8, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [48, 4.6, 3.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [49, 5.3, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [50, 5.0, 3.3, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [51, 7.0, 3.2, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [52, 6.4, 3.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [53, 6.9, 3.1, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [54, 5.5, 2.3, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [55, 6.5, 2.8, 4.6, 1.5, 'Iris-versicolor'],\n",
       "       [56, 5.7, 2.8, 4.5, 1.3, 'Iris-versicolor'],\n",
       "       [57, 6.3, 3.3, 4.7, 1.6, 'Iris-versicolor'],\n",
       "       [58, 4.9, 2.4, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [59, 6.6, 2.9, 4.6, 1.3, 'Iris-versicolor'],\n",
       "       [60, 5.2, 2.7, 3.9, 1.4, 'Iris-versicolor'],\n",
       "       [61, 5.0, 2.0, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [62, 5.9, 3.0, 4.2, 1.5, 'Iris-versicolor'],\n",
       "       [63, 6.0, 2.2, 4.0, 1.0, 'Iris-versicolor'],\n",
       "       [64, 6.1, 2.9, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [65, 5.6, 2.9, 3.6, 1.3, 'Iris-versicolor'],\n",
       "       [66, 6.7, 3.1, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [67, 5.6, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [68, 5.8, 2.7, 4.1, 1.0, 'Iris-versicolor'],\n",
       "       [69, 6.2, 2.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [70, 5.6, 2.5, 3.9, 1.1, 'Iris-versicolor'],\n",
       "       [71, 5.9, 3.2, 4.8, 1.8, 'Iris-versicolor'],\n",
       "       [72, 6.1, 2.8, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [73, 6.3, 2.5, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [74, 6.1, 2.8, 4.7, 1.2, 'Iris-versicolor'],\n",
       "       [75, 6.4, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [76, 6.6, 3.0, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [77, 6.8, 2.8, 4.8, 1.4, 'Iris-versicolor'],\n",
       "       [78, 6.7, 3.0, 5.0, 1.7, 'Iris-versicolor'],\n",
       "       [79, 6.0, 2.9, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [80, 5.7, 2.6, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [81, 5.5, 2.4, 3.8, 1.1, 'Iris-versicolor'],\n",
       "       [82, 5.5, 2.4, 3.7, 1.0, 'Iris-versicolor'],\n",
       "       [83, 5.8, 2.7, 3.9, 1.2, 'Iris-versicolor'],\n",
       "       [84, 6.0, 2.7, 5.1, 1.6, 'Iris-versicolor'],\n",
       "       [85, 5.4, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [86, 6.0, 3.4, 4.5, 1.6, 'Iris-versicolor'],\n",
       "       [87, 6.7, 3.1, 4.7, 1.5, 'Iris-versicolor'],\n",
       "       [88, 6.3, 2.3, 4.4, 1.3, 'Iris-versicolor'],\n",
       "       [89, 5.6, 3.0, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [90, 5.5, 2.5, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [91, 5.5, 2.6, 4.4, 1.2, 'Iris-versicolor'],\n",
       "       [92, 6.1, 3.0, 4.6, 1.4, 'Iris-versicolor'],\n",
       "       [93, 5.8, 2.6, 4.0, 1.2, 'Iris-versicolor'],\n",
       "       [94, 5.0, 2.3, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [95, 5.6, 2.7, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [96, 5.7, 3.0, 4.2, 1.2, 'Iris-versicolor'],\n",
       "       [97, 5.7, 2.9, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [98, 6.2, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [99, 5.1, 2.5, 3.0, 1.1, 'Iris-versicolor'],\n",
       "       [100, 5.7, 2.8, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [101, 6.3, 3.3, 6.0, 2.5, 'Iris-virginica'],\n",
       "       [102, 5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [103, 7.1, 3.0, 5.9, 2.1, 'Iris-virginica'],\n",
       "       [104, 6.3, 2.9, 5.6, 1.8, 'Iris-virginica'],\n",
       "       [105, 6.5, 3.0, 5.8, 2.2, 'Iris-virginica'],\n",
       "       [106, 7.6, 3.0, 6.6, 2.1, 'Iris-virginica'],\n",
       "       [107, 4.9, 2.5, 4.5, 1.7, 'Iris-virginica'],\n",
       "       [108, 7.3, 2.9, 6.3, 1.8, 'Iris-virginica'],\n",
       "       [109, 6.7, 2.5, 5.8, 1.8, 'Iris-virginica'],\n",
       "       [110, 7.2, 3.6, 6.1, 2.5, 'Iris-virginica'],\n",
       "       [111, 6.5, 3.2, 5.1, 2.0, 'Iris-virginica'],\n",
       "       [112, 6.4, 2.7, 5.3, 1.9, 'Iris-virginica'],\n",
       "       [113, 6.8, 3.0, 5.5, 2.1, 'Iris-virginica'],\n",
       "       [114, 5.7, 2.5, 5.0, 2.0, 'Iris-virginica'],\n",
       "       [115, 5.8, 2.8, 5.1, 2.4, 'Iris-virginica'],\n",
       "       [116, 6.4, 3.2, 5.3, 2.3, 'Iris-virginica'],\n",
       "       [117, 6.5, 3.0, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [118, 7.7, 3.8, 6.7, 2.2, 'Iris-virginica'],\n",
       "       [119, 7.7, 2.6, 6.9, 2.3, 'Iris-virginica'],\n",
       "       [120, 6.0, 2.2, 5.0, 1.5, 'Iris-virginica'],\n",
       "       [121, 6.9, 3.2, 5.7, 2.3, 'Iris-virginica'],\n",
       "       [122, 5.6, 2.8, 4.9, 2.0, 'Iris-virginica'],\n",
       "       [123, 7.7, 2.8, 6.7, 2.0, 'Iris-virginica'],\n",
       "       [124, 6.3, 2.7, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [125, 6.7, 3.3, 5.7, 2.1, 'Iris-virginica'],\n",
       "       [126, 7.2, 3.2, 6.0, 1.8, 'Iris-virginica'],\n",
       "       [127, 6.2, 2.8, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [128, 6.1, 3.0, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [129, 6.4, 2.8, 5.6, 2.1, 'Iris-virginica'],\n",
       "       [130, 7.2, 3.0, 5.8, 1.6, 'Iris-virginica'],\n",
       "       [131, 7.4, 2.8, 6.1, 1.9, 'Iris-virginica'],\n",
       "       [132, 7.9, 3.8, 6.4, 2.0, 'Iris-virginica'],\n",
       "       [133, 6.4, 2.8, 5.6, 2.2, 'Iris-virginica'],\n",
       "       [134, 6.3, 2.8, 5.1, 1.5, 'Iris-virginica'],\n",
       "       [135, 6.1, 2.6, 5.6, 1.4, 'Iris-virginica'],\n",
       "       [136, 7.7, 3.0, 6.1, 2.3, 'Iris-virginica'],\n",
       "       [137, 6.3, 3.4, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [138, 6.4, 3.1, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [139, 6.0, 3.0, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [140, 6.9, 3.1, 5.4, 2.1, 'Iris-virginica'],\n",
       "       [141, 6.7, 3.1, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [142, 6.9, 3.1, 5.1, 2.3, 'Iris-virginica'],\n",
       "       [143, 5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [144, 6.8, 3.2, 5.9, 2.3, 'Iris-virginica'],\n",
       "       [145, 6.7, 3.3, 5.7, 2.5, 'Iris-virginica'],\n",
       "       [146, 6.7, 3.0, 5.2, 2.3, 'Iris-virginica'],\n",
       "       [147, 6.3, 2.5, 5.0, 1.9, 'Iris-virginica'],\n",
       "       [148, 6.5, 3.0, 5.2, 2.0, 'Iris-virginica'],\n",
       "       [149, 6.2, 3.4, 5.4, 2.3, 'Iris-virginica'],\n",
       "       [150, 5.9, 3.0, 5.1, 1.8, 'Iris-virginica']], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVMR_ijqKj-r"
   },
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        #Citim setul de date\n",
    "        df=pd.read_csv(\"iris.csv\",header=0)\n",
    "        xy = df.values\n",
    "        self.len = xy.shape[0]\n",
    "        #Vom folosi ca input toate valorile mai puțin ultima coloană\n",
    "        self.x_data = torch.from_numpy(np.array(xy[:, 0:-1], dtype=np.float32))\n",
    "        #Vom folosi ca output ultima coloană\n",
    "        encoder = LabelBinarizer()\n",
    "        transformed_label = encoder.fit_transform(xy[:, [-1]])\n",
    "        #print(transformed_label)\n",
    "        #le.fit(xy[:, [-1]])\n",
    "        #print(list(le.classes_))\n",
    "        self.y_data = torch.from_numpy(np.array(transformed_label, dtype=np.float32))\n",
    "        #print(self.y_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVWrVEUMKkBU"
   },
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()\n",
    "#DataLoader - un utilitar ce ne ajută să împărțim setul de date pe batch-uri și astfel să facem antrenare în mod Mini-Batch\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44aFZMd_KkC_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 5.1000, 3.5000, 1.4000, 0.2000]), tensor([1., 0., 0.]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07jL_JLEKkF6"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(5, 6)\n",
    "        self.l2 = nn.Linear(6, 4)\n",
    "        self.l3 = nn.Linear(4, 3)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.relu = nn.functional.relu(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = nn.functional.relu(input=self.l2(out1), inplace=False)\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWeFa6ZzKkH3"
   },
   "outputs": [],
   "source": [
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHWknpAvKkKj"
   },
   "outputs": [],
   "source": [
    "criterion1 = nn.BCELoss(reduction='sum')\n",
    "criterion2 = nn.BCELoss(reduction='sum')\n",
    "criterion3 = nn.BCELoss(reduction='sum')\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THRIbzCKKkNI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5601, 0.5263, 0.4091],\n",
      "        [0.5602, 0.5264, 0.4092],\n",
      "        [0.5606, 0.5268, 0.4095],\n",
      "        [0.5599, 0.5260, 0.4089],\n",
      "        [0.5606, 0.5268, 0.4095],\n",
      "        [0.5606, 0.5268, 0.4095],\n",
      "        [0.5605, 0.5267, 0.4094],\n",
      "        [0.5606, 0.5268, 0.4095]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.]])\n",
      "Epoch 1 | Batch: 1\n",
      "tensor(16.3186)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-5d477d23a29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;31m#optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(200):\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "      # get the inputs\n",
    "      inputs, labels = data\n",
    "      #print(inputs)\n",
    "      #print(labels)\n",
    "      # Forward pass: Compute predicted y by passing x to the model\n",
    "      y_pred = model(inputs)\n",
    "      loss1 = criterion1(y_pred[:, 0], labels[:, 0])\n",
    "      loss2 = criterion2(y_pred[:, 1], labels[:, 1])\n",
    "      loss3 = criterion3(y_pred[:, 2], labels[:, 2])\n",
    "      # Compute and print loss\n",
    "      if (epoch % 10 == 0):\n",
    "          print(y_pred)\n",
    "          print(labels)\n",
    "          print(loss1)\n",
    "          print(loss2)\n",
    "          print(loss3)\n",
    "          print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {(loss1 + loss2 + loss3).item():.4f}')\n",
    "            \n",
    "      # Zero gradients, perform a backward pass, and update the weights.\n",
    "      #optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "print(y_pred)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njl2IFOYKkUk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCEVG-2nKkXB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfQIH8ODKkZ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5WciYowKkb6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBPgswFWKke1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yajmAIpKkhH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLCBbLsmKklV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DiabetesExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
