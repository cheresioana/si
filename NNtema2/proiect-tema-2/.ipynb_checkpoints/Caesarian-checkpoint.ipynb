{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaugarea unui set de date nou pentru clasificare\n",
    "\n",
    "Am folosit un set de date refertor la operatiile de cezariana (0 daca nu este nevoie sa se faca cezariana, si 1 daca este nevoie).\n",
    "Ca si feature-uri sunt: Age, delevery number, Delivery number, Delivery time, blood of pressure, heart problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnVLqgJPKZYn"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, from_numpy, optim\n",
    "import numpy as np\n",
    "#pandas- librărie pentru lucrul cu fișierele\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoINPLfdmvGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ioana/faculta/si/si/NNtema2/proiect-tema-2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "df=pd.read_csv(\"caesarian.csv\", error_bad_lines=False, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGjK2mEym5gP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26,  2,  0,  1,  0,  1],\n",
       "       [26,  2,  1,  1,  0,  0],\n",
       "       [28,  1,  0,  2,  0,  0],\n",
       "       [22,  2,  0,  1,  0,  1],\n",
       "       [26,  1,  1,  0,  0,  0],\n",
       "       [27,  2,  0,  1,  0,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[0:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVMR_ijqKj-r"
   },
   "outputs": [],
   "source": [
    "#Dataset - o clasă din PyTorch foarte utilă gestionării seturilor de date\n",
    "class CaesarianDataset(Dataset):\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        #Citim setul de date\n",
    "        df=pd.read_csv(\"caesarian.csv\",header=None, dtype=np.float32)\n",
    "        data = normalize(df.values, axis=0, norm='max')\n",
    "        xy = torch.from_numpy(data)\n",
    "        self.len = xy.shape[0]\n",
    "        #Vom folosi ca input toate valorile mai puțin ultima coloană\n",
    "        self.x_data = xy[:, 0:-1]\n",
    "        #normalizam prima coloana\n",
    "        self.x_data = self.x_data / self.x_data.max(0, keepdim=True)[0]\n",
    "        #print(self.x_data)\n",
    "        #Vom folosi ca output ultima coloană\n",
    "        self.y_data = xy[:, [-1]]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVWrVEUMKkBU"
   },
   "outputs": [],
   "source": [
    "dataset = CaesarianDataset()\n",
    "#DataLoader - un utilitar ce ne ajută să împărțim setul de date pe batch-uri și astfel să facem antrenare în mod Mini-Batch\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44aFZMd_KkC_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5500, 0.2500, 0.0000, 1.0000, 0.0000]), tensor([0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07jL_JLEKkF6"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(5, 6)\n",
    "        self.l2 = nn.Linear(6, 4)\n",
    "        self.l3 = nn.Linear(4, 1)\n",
    "        torch.manual_seed(1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        \n",
    "        \n",
    "        out2 = nn.functional.relu(input=self.l2(out1), inplace=False)\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWeFa6ZzKkH3"
   },
   "outputs": [],
   "source": [
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHWknpAvKkKj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THRIbzCKKkNI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch: 1 | Loss: 10.7739\n",
      "Epoch 1 | Batch: 2 | Loss: 12.5602\n",
      "Epoch 1 | Batch: 3 | Loss: 11.2804\n",
      "Epoch 1 | Batch: 4 | Loss: 10.5310\n",
      "Epoch 1 | Batch: 5 | Loss: 11.3492\n",
      "Mean of loss / batch 11.29896068572998\n",
      "Epoch 2 | Batch: 1 | Loss: 10.9681\n",
      "Epoch 2 | Batch: 2 | Loss: 11.5270\n",
      "Epoch 2 | Batch: 3 | Loss: 10.8147\n",
      "Epoch 2 | Batch: 4 | Loss: 10.7241\n",
      "Epoch 2 | Batch: 5 | Loss: 10.6748\n",
      "Mean of loss / batch 10.941723823547363\n",
      "Epoch 3 | Batch: 1 | Loss: 11.3194\n",
      "Epoch 3 | Batch: 2 | Loss: 10.9658\n",
      "Epoch 3 | Batch: 3 | Loss: 11.4979\n",
      "Epoch 3 | Batch: 4 | Loss: 10.6639\n",
      "Epoch 3 | Batch: 5 | Loss: 10.3980\n",
      "Mean of loss / batch 10.969015121459961\n",
      "Epoch 4 | Batch: 1 | Loss: 11.3780\n",
      "Epoch 4 | Batch: 2 | Loss: 10.9693\n",
      "Epoch 4 | Batch: 3 | Loss: 10.0857\n",
      "Epoch 4 | Batch: 4 | Loss: 11.0277\n",
      "Epoch 4 | Batch: 5 | Loss: 11.4175\n",
      "Mean of loss / batch 10.975618362426758\n",
      "Epoch 5 | Batch: 1 | Loss: 10.6516\n",
      "Epoch 5 | Batch: 2 | Loss: 10.9851\n",
      "Epoch 5 | Batch: 3 | Loss: 11.3141\n",
      "Epoch 5 | Batch: 4 | Loss: 10.6943\n",
      "Epoch 5 | Batch: 5 | Loss: 10.9720\n",
      "Mean of loss / batch 10.923410415649414\n",
      "Epoch 6 | Batch: 1 | Loss: 10.3593\n",
      "Epoch 6 | Batch: 2 | Loss: 11.8041\n",
      "Epoch 6 | Batch: 3 | Loss: 9.9044\n",
      "Epoch 6 | Batch: 4 | Loss: 12.9213\n",
      "Epoch 6 | Batch: 5 | Loss: 10.7494\n",
      "Mean of loss / batch 11.147692680358887\n",
      "Epoch 7 | Batch: 1 | Loss: 10.6880\n",
      "Epoch 7 | Batch: 2 | Loss: 10.3239\n",
      "Epoch 7 | Batch: 3 | Loss: 12.2479\n",
      "Epoch 7 | Batch: 4 | Loss: 10.7389\n",
      "Epoch 7 | Batch: 5 | Loss: 10.9625\n",
      "Mean of loss / batch 10.992241859436035\n",
      "Epoch 8 | Batch: 1 | Loss: 10.9653\n",
      "Epoch 8 | Batch: 2 | Loss: 10.1534\n",
      "Epoch 8 | Batch: 3 | Loss: 10.1707\n",
      "Epoch 8 | Batch: 4 | Loss: 11.5576\n",
      "Epoch 8 | Batch: 5 | Loss: 12.1697\n",
      "Mean of loss / batch 11.00334358215332\n",
      "Epoch 9 | Batch: 1 | Loss: 11.5950\n",
      "Epoch 9 | Batch: 2 | Loss: 10.9659\n",
      "Epoch 9 | Batch: 3 | Loss: 10.9751\n",
      "Epoch 9 | Batch: 4 | Loss: 10.9707\n",
      "Epoch 9 | Batch: 5 | Loss: 10.4012\n",
      "Mean of loss / batch 10.981565475463867\n",
      "Epoch 10 | Batch: 1 | Loss: 9.5540\n",
      "Epoch 10 | Batch: 2 | Loss: 11.6755\n",
      "Epoch 10 | Batch: 3 | Loss: 11.4587\n",
      "Epoch 10 | Batch: 4 | Loss: 10.6280\n",
      "Epoch 10 | Batch: 5 | Loss: 11.7370\n",
      "Mean of loss / batch 11.010663032531738\n",
      "Epoch 11 | Batch: 1 | Loss: 10.7063\n",
      "Epoch 11 | Batch: 2 | Loss: 10.9621\n",
      "Epoch 11 | Batch: 3 | Loss: 10.6783\n",
      "Epoch 11 | Batch: 4 | Loss: 11.3077\n",
      "Epoch 11 | Batch: 5 | Loss: 10.9537\n",
      "Mean of loss / batch 10.92162799835205\n",
      "Epoch 12 | Batch: 1 | Loss: 11.7451\n",
      "Epoch 12 | Batch: 2 | Loss: 10.8827\n",
      "Epoch 12 | Batch: 3 | Loss: 10.9659\n",
      "Epoch 12 | Batch: 4 | Loss: 11.1620\n",
      "Epoch 12 | Batch: 5 | Loss: 10.3510\n",
      "Mean of loss / batch 11.021347045898438\n",
      "Epoch 13 | Batch: 1 | Loss: 10.9832\n",
      "Epoch 13 | Batch: 2 | Loss: 11.3261\n",
      "Epoch 13 | Batch: 3 | Loss: 10.3869\n",
      "Epoch 13 | Batch: 4 | Loss: 10.6217\n",
      "Epoch 13 | Batch: 5 | Loss: 11.4165\n",
      "Mean of loss / batch 10.946882247924805\n",
      "Epoch 14 | Batch: 1 | Loss: 11.9458\n",
      "Epoch 14 | Batch: 2 | Loss: 10.9719\n",
      "Epoch 14 | Batch: 3 | Loss: 10.2807\n",
      "Epoch 14 | Batch: 4 | Loss: 11.7857\n",
      "Epoch 14 | Batch: 5 | Loss: 10.4323\n",
      "Mean of loss / batch 11.083263397216797\n",
      "Epoch 15 | Batch: 1 | Loss: 11.3483\n",
      "Epoch 15 | Batch: 2 | Loss: 11.2527\n",
      "Epoch 15 | Batch: 3 | Loss: 10.2523\n",
      "Epoch 15 | Batch: 4 | Loss: 11.7820\n",
      "Epoch 15 | Batch: 5 | Loss: 10.4447\n",
      "Mean of loss / batch 11.015985488891602\n",
      "Epoch 16 | Batch: 1 | Loss: 10.2528\n",
      "Epoch 16 | Batch: 2 | Loss: 11.9123\n",
      "Epoch 16 | Batch: 3 | Loss: 11.2544\n",
      "Epoch 16 | Batch: 4 | Loss: 10.0045\n",
      "Epoch 16 | Batch: 5 | Loss: 11.9462\n",
      "Mean of loss / batch 11.07406997680664\n",
      "Epoch 17 | Batch: 1 | Loss: 10.9644\n",
      "Epoch 17 | Batch: 2 | Loss: 11.5226\n",
      "Epoch 17 | Batch: 3 | Loss: 10.7731\n",
      "Epoch 17 | Batch: 4 | Loss: 10.9670\n",
      "Epoch 17 | Batch: 5 | Loss: 10.4593\n",
      "Mean of loss / batch 10.937261581420898\n",
      "Epoch 18 | Batch: 1 | Loss: 11.3330\n",
      "Epoch 18 | Batch: 2 | Loss: 11.7962\n",
      "Epoch 18 | Batch: 3 | Loss: 10.7586\n",
      "Epoch 18 | Batch: 4 | Loss: 10.6862\n",
      "Epoch 18 | Batch: 5 | Loss: 10.3502\n",
      "Mean of loss / batch 10.984861373901367\n",
      "Epoch 19 | Batch: 1 | Loss: 10.5734\n",
      "Epoch 19 | Batch: 2 | Loss: 11.4417\n",
      "Epoch 19 | Batch: 3 | Loss: 10.9703\n",
      "Epoch 19 | Batch: 4 | Loss: 10.0167\n",
      "Epoch 19 | Batch: 5 | Loss: 11.9612\n",
      "Mean of loss / batch 10.992646217346191\n",
      "Epoch 20 | Batch: 1 | Loss: 11.2740\n",
      "Epoch 20 | Batch: 2 | Loss: 10.9279\n",
      "Epoch 20 | Batch: 3 | Loss: 11.4425\n",
      "Epoch 20 | Batch: 4 | Loss: 10.6927\n",
      "Epoch 20 | Batch: 5 | Loss: 10.4082\n",
      "Mean of loss / batch 10.949074745178223\n",
      "Epoch 21 | Batch: 1 | Loss: 10.2465\n",
      "Epoch 21 | Batch: 2 | Loss: 11.0223\n",
      "Epoch 21 | Batch: 3 | Loss: 11.8443\n",
      "Epoch 21 | Batch: 4 | Loss: 10.6722\n",
      "Epoch 21 | Batch: 5 | Loss: 10.9236\n",
      "Mean of loss / batch 10.941800117492676\n",
      "Epoch 22 | Batch: 1 | Loss: 10.3237\n",
      "Epoch 22 | Batch: 2 | Loss: 11.4013\n",
      "Epoch 22 | Batch: 3 | Loss: 10.3148\n",
      "Epoch 22 | Batch: 4 | Loss: 10.5804\n",
      "Epoch 22 | Batch: 5 | Loss: 12.3205\n",
      "Mean of loss / batch 10.988151550292969\n",
      "Epoch 23 | Batch: 1 | Loss: 11.1464\n",
      "Epoch 23 | Batch: 2 | Loss: 11.1705\n",
      "Epoch 23 | Batch: 3 | Loss: 10.5247\n",
      "Epoch 23 | Batch: 4 | Loss: 9.9404\n",
      "Epoch 23 | Batch: 5 | Loss: 12.5245\n",
      "Mean of loss / batch 11.061274528503418\n",
      "Epoch 24 | Batch: 1 | Loss: 11.1930\n",
      "Epoch 24 | Batch: 2 | Loss: 10.9151\n",
      "Epoch 24 | Batch: 3 | Loss: 10.5479\n",
      "Epoch 24 | Batch: 4 | Loss: 10.2606\n",
      "Epoch 24 | Batch: 5 | Loss: 11.8845\n",
      "Mean of loss / batch 10.960222244262695\n",
      "Epoch 25 | Batch: 1 | Loss: 11.2179\n",
      "Epoch 25 | Batch: 2 | Loss: 10.9317\n",
      "Epoch 25 | Batch: 3 | Loss: 10.7148\n",
      "Epoch 25 | Batch: 4 | Loss: 10.6510\n",
      "Epoch 25 | Batch: 5 | Loss: 10.9339\n",
      "Mean of loss / batch 10.889856338500977\n",
      "Epoch 26 | Batch: 1 | Loss: 10.2876\n",
      "Epoch 26 | Batch: 2 | Loss: 11.8273\n",
      "Epoch 26 | Batch: 3 | Loss: 10.4002\n",
      "Epoch 26 | Batch: 4 | Loss: 11.7227\n",
      "Epoch 26 | Batch: 5 | Loss: 10.7208\n",
      "Mean of loss / batch 10.991719245910645\n",
      "Epoch 27 | Batch: 1 | Loss: 11.8345\n",
      "Epoch 27 | Batch: 2 | Loss: 11.0675\n",
      "Epoch 27 | Batch: 3 | Loss: 11.0449\n",
      "Epoch 27 | Batch: 4 | Loss: 10.5478\n",
      "Epoch 27 | Batch: 5 | Loss: 10.5582\n",
      "Mean of loss / batch 11.010581970214844\n",
      "Epoch 28 | Batch: 1 | Loss: 10.5249\n",
      "Epoch 28 | Batch: 2 | Loss: 10.5194\n",
      "Epoch 28 | Batch: 3 | Loss: 11.0168\n",
      "Epoch 28 | Batch: 4 | Loss: 10.1849\n",
      "Epoch 28 | Batch: 5 | Loss: 12.5708\n",
      "Mean of loss / batch 10.963374137878418\n",
      "Epoch 29 | Batch: 1 | Loss: 10.6383\n",
      "Epoch 29 | Batch: 2 | Loss: 11.5394\n",
      "Epoch 29 | Batch: 3 | Loss: 11.1423\n",
      "Epoch 29 | Batch: 4 | Loss: 10.7150\n",
      "Epoch 29 | Batch: 5 | Loss: 10.6006\n",
      "Mean of loss / batch 10.927118301391602\n",
      "Epoch 30 | Batch: 1 | Loss: 11.6489\n",
      "Epoch 30 | Batch: 2 | Loss: 10.7420\n",
      "Epoch 30 | Batch: 3 | Loss: 10.1620\n",
      "Epoch 30 | Batch: 4 | Loss: 10.0310\n",
      "Epoch 30 | Batch: 5 | Loss: 12.6194\n",
      "Mean of loss / batch 11.040687561035156\n",
      "Epoch 31 | Batch: 1 | Loss: 11.6996\n",
      "Epoch 31 | Batch: 2 | Loss: 10.8566\n",
      "Epoch 31 | Batch: 3 | Loss: 10.2107\n",
      "Epoch 31 | Batch: 4 | Loss: 11.8357\n",
      "Epoch 31 | Batch: 5 | Loss: 10.6132\n",
      "Mean of loss / batch 11.043169021606445\n",
      "Epoch 32 | Batch: 1 | Loss: 10.8767\n",
      "Epoch 32 | Batch: 2 | Loss: 10.9255\n",
      "Epoch 32 | Batch: 3 | Loss: 10.8606\n",
      "Epoch 32 | Batch: 4 | Loss: 10.9837\n",
      "Epoch 32 | Batch: 5 | Loss: 10.5643\n",
      "Mean of loss / batch 10.842154502868652\n",
      "Epoch 33 | Batch: 1 | Loss: 11.2160\n",
      "Epoch 33 | Batch: 2 | Loss: 10.8832\n",
      "Epoch 33 | Batch: 3 | Loss: 10.1247\n",
      "Epoch 33 | Batch: 4 | Loss: 11.4185\n",
      "Epoch 33 | Batch: 5 | Loss: 10.9393\n",
      "Mean of loss / batch 10.916338920593262\n",
      "Epoch 34 | Batch: 1 | Loss: 10.3145\n",
      "Epoch 34 | Batch: 2 | Loss: 12.2391\n",
      "Epoch 34 | Batch: 3 | Loss: 10.4116\n",
      "Epoch 34 | Batch: 4 | Loss: 11.5512\n",
      "Epoch 34 | Batch: 5 | Loss: 10.7102\n",
      "Mean of loss / batch 11.04531192779541\n",
      "Epoch 35 | Batch: 1 | Loss: 12.2749\n",
      "Epoch 35 | Batch: 2 | Loss: 11.1159\n",
      "Epoch 35 | Batch: 3 | Loss: 11.3611\n",
      "Epoch 35 | Batch: 4 | Loss: 10.5826\n",
      "Epoch 35 | Batch: 5 | Loss: 10.6439\n",
      "Mean of loss / batch 11.195688247680664\n",
      "Epoch 36 | Batch: 1 | Loss: 11.3604\n",
      "Epoch 36 | Batch: 2 | Loss: 10.0820\n",
      "Epoch 36 | Batch: 3 | Loss: 10.5953\n",
      "Epoch 36 | Batch: 4 | Loss: 11.9445\n",
      "Epoch 36 | Batch: 5 | Loss: 10.9723\n",
      "Mean of loss / batch 10.990909576416016\n",
      "Epoch 37 | Batch: 1 | Loss: 10.3692\n",
      "Epoch 37 | Batch: 2 | Loss: 12.5657\n",
      "Epoch 37 | Batch: 3 | Loss: 10.6532\n",
      "Epoch 37 | Batch: 4 | Loss: 10.9667\n",
      "Epoch 37 | Batch: 5 | Loss: 10.6911\n",
      "Mean of loss / batch 11.04918098449707\n",
      "Epoch 38 | Batch: 1 | Loss: 11.6152\n",
      "Epoch 38 | Batch: 2 | Loss: 11.1758\n",
      "Epoch 38 | Batch: 3 | Loss: 10.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Batch: 4 | Loss: 10.2680\n",
      "Epoch 38 | Batch: 5 | Loss: 11.0007\n",
      "Mean of loss / batch 10.974699020385742\n",
      "Epoch 39 | Batch: 1 | Loss: 11.7081\n",
      "Epoch 39 | Batch: 2 | Loss: 10.2491\n",
      "Epoch 39 | Batch: 3 | Loss: 11.3945\n",
      "Epoch 39 | Batch: 4 | Loss: 10.3448\n",
      "Epoch 39 | Batch: 5 | Loss: 11.4109\n",
      "Mean of loss / batch 11.021490097045898\n",
      "Epoch 40 | Batch: 1 | Loss: 12.5870\n",
      "Epoch 40 | Batch: 2 | Loss: 11.0387\n",
      "Epoch 40 | Batch: 3 | Loss: 10.9155\n",
      "Epoch 40 | Batch: 4 | Loss: 10.4435\n",
      "Epoch 40 | Batch: 5 | Loss: 10.2971\n",
      "Mean of loss / batch 11.05634880065918\n",
      "Epoch 41 | Batch: 1 | Loss: 11.0234\n",
      "Epoch 41 | Batch: 2 | Loss: 10.2216\n",
      "Epoch 41 | Batch: 3 | Loss: 10.1257\n",
      "Epoch 41 | Batch: 4 | Loss: 10.0628\n",
      "Epoch 41 | Batch: 5 | Loss: 14.0132\n",
      "Mean of loss / batch 11.08936595916748\n",
      "Epoch 42 | Batch: 1 | Loss: 10.7059\n",
      "Epoch 42 | Batch: 2 | Loss: 10.0483\n",
      "Epoch 42 | Batch: 3 | Loss: 10.5928\n",
      "Epoch 42 | Batch: 4 | Loss: 11.9663\n",
      "Epoch 42 | Batch: 5 | Loss: 11.6110\n",
      "Mean of loss / batch 10.984879493713379\n",
      "Epoch 43 | Batch: 1 | Loss: 11.5854\n",
      "Epoch 43 | Batch: 2 | Loss: 10.8408\n",
      "Epoch 43 | Batch: 3 | Loss: 10.7135\n",
      "Epoch 43 | Batch: 4 | Loss: 10.6685\n",
      "Epoch 43 | Batch: 5 | Loss: 11.3227\n",
      "Mean of loss / batch 11.026163101196289\n",
      "Epoch 44 | Batch: 1 | Loss: 10.4181\n",
      "Epoch 44 | Batch: 2 | Loss: 10.6229\n",
      "Epoch 44 | Batch: 3 | Loss: 10.2133\n",
      "Epoch 44 | Batch: 4 | Loss: 10.5884\n",
      "Epoch 44 | Batch: 5 | Loss: 13.4446\n",
      "Mean of loss / batch 11.057451248168945\n",
      "Epoch 45 | Batch: 1 | Loss: 10.4261\n",
      "Epoch 45 | Batch: 2 | Loss: 10.2901\n",
      "Epoch 45 | Batch: 3 | Loss: 11.0258\n",
      "Epoch 45 | Batch: 4 | Loss: 11.0045\n",
      "Epoch 45 | Batch: 5 | Loss: 12.4537\n",
      "Mean of loss / batch 11.040050506591797\n",
      "Epoch 46 | Batch: 1 | Loss: 10.7012\n",
      "Epoch 46 | Batch: 2 | Loss: 11.2302\n",
      "Epoch 46 | Batch: 3 | Loss: 10.9681\n",
      "Epoch 46 | Batch: 4 | Loss: 10.7471\n",
      "Epoch 46 | Batch: 5 | Loss: 11.2423\n",
      "Mean of loss / batch 10.977767944335938\n",
      "Epoch 47 | Batch: 1 | Loss: 11.1880\n",
      "Epoch 47 | Batch: 2 | Loss: 10.6216\n",
      "Epoch 47 | Batch: 3 | Loss: 10.9682\n",
      "Epoch 47 | Batch: 4 | Loss: 11.5348\n",
      "Epoch 47 | Batch: 5 | Loss: 10.6209\n",
      "Mean of loss / batch 10.986711502075195\n",
      "Epoch 48 | Batch: 1 | Loss: 10.3842\n",
      "Epoch 48 | Batch: 2 | Loss: 10.9995\n",
      "Epoch 48 | Batch: 3 | Loss: 11.7038\n",
      "Epoch 48 | Batch: 4 | Loss: 10.4908\n",
      "Epoch 48 | Batch: 5 | Loss: 11.3205\n",
      "Mean of loss / batch 10.979756355285645\n",
      "Epoch 49 | Batch: 1 | Loss: 10.4205\n",
      "Epoch 49 | Batch: 2 | Loss: 11.7289\n",
      "Epoch 49 | Batch: 3 | Loss: 11.4563\n",
      "Epoch 49 | Batch: 4 | Loss: 10.6932\n",
      "Epoch 49 | Batch: 5 | Loss: 10.6981\n",
      "Mean of loss / batch 10.99940299987793\n",
      "Epoch 50 | Batch: 1 | Loss: 11.6014\n",
      "Epoch 50 | Batch: 2 | Loss: 10.5660\n",
      "Epoch 50 | Batch: 3 | Loss: 11.5955\n",
      "Epoch 50 | Batch: 4 | Loss: 10.5706\n",
      "Epoch 50 | Batch: 5 | Loss: 10.6618\n",
      "Mean of loss / batch 10.999044418334961\n",
      "Epoch 51 | Batch: 1 | Loss: 10.2865\n",
      "Epoch 51 | Batch: 2 | Loss: 9.3090\n",
      "Epoch 51 | Batch: 3 | Loss: 10.5982\n",
      "Epoch 51 | Batch: 4 | Loss: 12.9110\n",
      "Epoch 51 | Batch: 5 | Loss: 12.0908\n",
      "Mean of loss / batch 11.039091110229492\n",
      "Epoch 52 | Batch: 1 | Loss: 10.9715\n",
      "Epoch 52 | Batch: 2 | Loss: 10.9692\n",
      "Epoch 52 | Batch: 3 | Loss: 11.1822\n",
      "Epoch 52 | Batch: 4 | Loss: 10.9775\n",
      "Epoch 52 | Batch: 5 | Loss: 10.5982\n",
      "Mean of loss / batch 10.939705848693848\n",
      "Epoch 53 | Batch: 1 | Loss: 10.0695\n",
      "Epoch 53 | Batch: 2 | Loss: 11.0348\n",
      "Epoch 53 | Batch: 3 | Loss: 11.0105\n",
      "Epoch 53 | Batch: 4 | Loss: 11.7428\n",
      "Epoch 53 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 10.964521408081055\n",
      "Epoch 54 | Batch: 1 | Loss: 10.7146\n",
      "Epoch 54 | Batch: 2 | Loss: 11.8715\n",
      "Epoch 54 | Batch: 3 | Loss: 10.5664\n",
      "Epoch 54 | Batch: 4 | Loss: 9.7214\n",
      "Epoch 54 | Batch: 5 | Loss: 13.0888\n",
      "Mean of loss / batch 11.192545890808105\n",
      "Epoch 55 | Batch: 1 | Loss: 10.9650\n",
      "Epoch 55 | Batch: 2 | Loss: 10.9650\n",
      "Epoch 55 | Batch: 3 | Loss: 10.7129\n",
      "Epoch 55 | Batch: 4 | Loss: 10.6681\n",
      "Epoch 55 | Batch: 5 | Loss: 11.3232\n",
      "Mean of loss / batch 10.926846504211426\n",
      "Epoch 56 | Batch: 1 | Loss: 9.8689\n",
      "Epoch 56 | Batch: 2 | Loss: 11.9975\n",
      "Epoch 56 | Batch: 3 | Loss: 11.3039\n",
      "Epoch 56 | Batch: 4 | Loss: 10.4401\n",
      "Epoch 56 | Batch: 5 | Loss: 11.7091\n",
      "Mean of loss / batch 11.063899040222168\n",
      "Epoch 57 | Batch: 1 | Loss: 10.9653\n",
      "Epoch 57 | Batch: 2 | Loss: 10.7237\n",
      "Epoch 57 | Batch: 3 | Loss: 10.9685\n",
      "Epoch 57 | Batch: 4 | Loss: 10.6821\n",
      "Epoch 57 | Batch: 5 | Loss: 11.3052\n",
      "Mean of loss / batch 10.928983688354492\n",
      "Epoch 58 | Batch: 1 | Loss: 12.0189\n",
      "Epoch 58 | Batch: 2 | Loss: 10.6707\n",
      "Epoch 58 | Batch: 3 | Loss: 11.4064\n",
      "Epoch 58 | Batch: 4 | Loss: 10.6542\n",
      "Epoch 58 | Batch: 5 | Loss: 11.3434\n",
      "Mean of loss / batch 11.218706130981445\n",
      "Epoch 59 | Batch: 1 | Loss: 11.2534\n",
      "Epoch 59 | Batch: 2 | Loss: 11.1952\n",
      "Epoch 59 | Batch: 3 | Loss: 11.5248\n",
      "Epoch 59 | Batch: 4 | Loss: 10.9539\n",
      "Epoch 59 | Batch: 5 | Loss: 10.2228\n",
      "Mean of loss / batch 11.03001880645752\n",
      "Epoch 60 | Batch: 1 | Loss: 11.4085\n",
      "Epoch 60 | Batch: 2 | Loss: 10.3322\n",
      "Epoch 60 | Batch: 3 | Loss: 12.2352\n",
      "Epoch 60 | Batch: 4 | Loss: 10.5120\n",
      "Epoch 60 | Batch: 5 | Loss: 10.6459\n",
      "Mean of loss / batch 11.026754379272461\n",
      "Epoch 61 | Batch: 1 | Loss: 10.2586\n",
      "Epoch 61 | Batch: 2 | Loss: 11.4809\n",
      "Epoch 61 | Batch: 3 | Loss: 10.9867\n",
      "Epoch 61 | Batch: 4 | Loss: 11.3149\n",
      "Epoch 61 | Batch: 5 | Loss: 10.6964\n",
      "Mean of loss / batch 10.947484016418457\n",
      "Epoch 62 | Batch: 1 | Loss: 10.9732\n",
      "Epoch 62 | Batch: 2 | Loss: 10.6672\n",
      "Epoch 62 | Batch: 3 | Loss: 12.0104\n",
      "Epoch 62 | Batch: 4 | Loss: 11.1516\n",
      "Epoch 62 | Batch: 5 | Loss: 10.4290\n",
      "Mean of loss / batch 11.046257972717285\n",
      "Epoch 63 | Batch: 1 | Loss: 10.2648\n",
      "Epoch 63 | Batch: 2 | Loss: 11.4753\n",
      "Epoch 63 | Batch: 3 | Loss: 10.9856\n",
      "Epoch 63 | Batch: 4 | Loss: 10.6446\n",
      "Epoch 63 | Batch: 5 | Loss: 11.3591\n",
      "Mean of loss / batch 10.945894241333008\n",
      "Epoch 64 | Batch: 1 | Loss: 11.5586\n",
      "Epoch 64 | Batch: 2 | Loss: 10.4143\n",
      "Epoch 64 | Batch: 3 | Loss: 11.3330\n",
      "Epoch 64 | Batch: 4 | Loss: 10.6866\n",
      "Epoch 64 | Batch: 5 | Loss: 10.9755\n",
      "Mean of loss / batch 10.993597030639648\n",
      "Epoch 65 | Batch: 1 | Loss: 10.6617\n",
      "Epoch 65 | Batch: 2 | Loss: 10.2864\n",
      "Epoch 65 | Batch: 3 | Loss: 11.8861\n",
      "Epoch 65 | Batch: 4 | Loss: 9.7890\n",
      "Epoch 65 | Batch: 5 | Loss: 13.0180\n",
      "Mean of loss / batch 11.128260612487793\n",
      "Epoch 66 | Batch: 1 | Loss: 10.0014\n",
      "Epoch 66 | Batch: 2 | Loss: 11.0367\n",
      "Epoch 66 | Batch: 3 | Loss: 11.4175\n",
      "Epoch 66 | Batch: 4 | Loss: 10.9759\n",
      "Epoch 66 | Batch: 5 | Loss: 11.5944\n",
      "Mean of loss / batch 11.005175590515137\n",
      "Epoch 67 | Batch: 1 | Loss: 11.1698\n",
      "Epoch 67 | Batch: 2 | Loss: 10.8219\n",
      "Epoch 67 | Batch: 3 | Loss: 10.7383\n",
      "Epoch 67 | Batch: 4 | Loss: 11.8143\n",
      "Epoch 67 | Batch: 5 | Loss: 10.6169\n",
      "Mean of loss / batch 11.032241821289062\n",
      "Epoch 68 | Batch: 1 | Loss: 10.9699\n",
      "Epoch 68 | Batch: 2 | Loss: 10.9682\n",
      "Epoch 68 | Batch: 3 | Loss: 10.9671\n",
      "Epoch 68 | Batch: 4 | Loss: 11.2435\n",
      "Epoch 68 | Batch: 5 | Loss: 10.5226\n",
      "Mean of loss / batch 10.934237480163574\n",
      "Epoch 69 | Batch: 1 | Loss: 10.3208\n",
      "Epoch 69 | Batch: 2 | Loss: 11.4289\n",
      "Epoch 69 | Batch: 3 | Loss: 10.6462\n",
      "Epoch 69 | Batch: 4 | Loss: 10.9907\n",
      "Epoch 69 | Batch: 5 | Loss: 11.3251\n",
      "Mean of loss / batch 10.94232177734375\n",
      "Epoch 70 | Batch: 1 | Loss: 10.6908\n",
      "Epoch 70 | Batch: 2 | Loss: 10.9745\n",
      "Epoch 70 | Batch: 3 | Loss: 10.9711\n",
      "Epoch 70 | Batch: 4 | Loss: 11.2651\n",
      "Epoch 70 | Batch: 5 | Loss: 10.7281\n",
      "Mean of loss / batch 10.925911903381348\n",
      "Epoch 71 | Batch: 1 | Loss: 11.2581\n",
      "Epoch 71 | Batch: 2 | Loss: 11.1982\n",
      "Epoch 71 | Batch: 3 | Loss: 11.3458\n",
      "Epoch 71 | Batch: 4 | Loss: 10.7137\n",
      "Epoch 71 | Batch: 5 | Loss: 10.4080\n",
      "Mean of loss / batch 10.984766006469727\n",
      "Epoch 72 | Batch: 1 | Loss: 10.6206\n",
      "Epoch 72 | Batch: 2 | Loss: 10.6083\n",
      "Epoch 72 | Batch: 3 | Loss: 9.3374\n",
      "Epoch 72 | Batch: 4 | Loss: 11.7721\n",
      "Epoch 72 | Batch: 5 | Loss: 12.9559\n",
      "Mean of loss / batch 11.058858871459961\n",
      "Epoch 73 | Batch: 1 | Loss: 11.8885\n",
      "Epoch 73 | Batch: 2 | Loss: 11.0233\n",
      "Epoch 73 | Batch: 3 | Loss: 11.1230\n",
      "Epoch 73 | Batch: 4 | Loss: 10.8045\n",
      "Epoch 73 | Batch: 5 | Loss: 10.2703\n",
      "Mean of loss / batch 11.021913528442383\n",
      "Epoch 74 | Batch: 1 | Loss: 10.6147\n",
      "Epoch 74 | Batch: 2 | Loss: 10.1950\n",
      "Epoch 74 | Batch: 3 | Loss: 11.0657\n",
      "Epoch 74 | Batch: 4 | Loss: 12.3349\n",
      "Epoch 74 | Batch: 5 | Loss: 10.7159\n",
      "Mean of loss / batch 10.985223770141602\n",
      "Epoch 75 | Batch: 1 | Loss: 11.5688\n",
      "Epoch 75 | Batch: 2 | Loss: 10.4021\n",
      "Epoch 75 | Batch: 3 | Loss: 11.6894\n",
      "Epoch 75 | Batch: 4 | Loss: 10.0358\n",
      "Epoch 75 | Batch: 5 | Loss: 11.9041\n",
      "Mean of loss / batch 11.120026588439941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Batch: 1 | Loss: 11.2701\n",
      "Epoch 76 | Batch: 2 | Loss: 10.2432\n",
      "Epoch 76 | Batch: 3 | Loss: 11.0042\n",
      "Epoch 76 | Batch: 4 | Loss: 10.9904\n",
      "Epoch 76 | Batch: 5 | Loss: 11.3245\n",
      "Mean of loss / batch 10.966461181640625\n",
      "Epoch 77 | Batch: 1 | Loss: 11.2412\n",
      "Epoch 77 | Batch: 2 | Loss: 10.7465\n",
      "Epoch 77 | Batch: 3 | Loss: 10.9663\n",
      "Epoch 77 | Batch: 4 | Loss: 10.6943\n",
      "Epoch 77 | Batch: 5 | Loss: 10.9736\n",
      "Mean of loss / batch 10.924383163452148\n",
      "Epoch 78 | Batch: 1 | Loss: 11.2752\n",
      "Epoch 78 | Batch: 2 | Loss: 10.7210\n",
      "Epoch 78 | Batch: 3 | Loss: 10.6733\n",
      "Epoch 78 | Batch: 4 | Loss: 10.9794\n",
      "Epoch 78 | Batch: 5 | Loss: 10.9743\n",
      "Mean of loss / batch 10.924641609191895\n",
      "Epoch 79 | Batch: 1 | Loss: 10.9710\n",
      "Epoch 79 | Batch: 2 | Loss: 12.1521\n",
      "Epoch 79 | Batch: 3 | Loss: 10.6702\n",
      "Epoch 79 | Batch: 4 | Loss: 11.2938\n",
      "Epoch 79 | Batch: 5 | Loss: 10.4525\n",
      "Mean of loss / batch 11.107943534851074\n",
      "Epoch 80 | Batch: 1 | Loss: 10.9862\n",
      "Epoch 80 | Batch: 2 | Loss: 11.9837\n",
      "Epoch 80 | Batch: 3 | Loss: 10.8099\n",
      "Epoch 80 | Batch: 4 | Loss: 10.9656\n",
      "Epoch 80 | Batch: 5 | Loss: 10.2508\n",
      "Mean of loss / batch 10.999238967895508\n",
      "Epoch 81 | Batch: 1 | Loss: 11.3938\n",
      "Epoch 81 | Batch: 2 | Loss: 11.2862\n",
      "Epoch 81 | Batch: 3 | Loss: 10.7136\n",
      "Epoch 81 | Batch: 4 | Loss: 10.3672\n",
      "Epoch 81 | Batch: 5 | Loss: 11.0035\n",
      "Mean of loss / batch 10.952880859375\n",
      "Epoch 82 | Batch: 1 | Loss: 10.9900\n",
      "Epoch 82 | Batch: 2 | Loss: 10.6390\n",
      "Epoch 82 | Batch: 3 | Loss: 9.4971\n",
      "Epoch 82 | Batch: 4 | Loss: 11.1383\n",
      "Epoch 82 | Batch: 5 | Loss: 13.0506\n",
      "Mean of loss / batch 11.063013076782227\n",
      "Epoch 83 | Batch: 1 | Loss: 11.4578\n",
      "Epoch 83 | Batch: 2 | Loss: 10.9864\n",
      "Epoch 83 | Batch: 3 | Loss: 11.1467\n",
      "Epoch 83 | Batch: 4 | Loss: 10.8576\n",
      "Epoch 83 | Batch: 5 | Loss: 10.3461\n",
      "Mean of loss / batch 10.958917617797852\n",
      "Epoch 84 | Batch: 1 | Loss: 10.6247\n",
      "Epoch 84 | Batch: 2 | Loss: 11.7923\n",
      "Epoch 84 | Batch: 3 | Loss: 10.1674\n",
      "Epoch 84 | Batch: 4 | Loss: 11.0162\n",
      "Epoch 84 | Batch: 5 | Loss: 11.3799\n",
      "Mean of loss / batch 10.996084213256836\n",
      "Epoch 85 | Batch: 1 | Loss: 10.9710\n",
      "Epoch 85 | Batch: 2 | Loss: 11.8553\n",
      "Epoch 85 | Batch: 3 | Loss: 11.1278\n",
      "Epoch 85 | Batch: 4 | Loss: 10.6764\n",
      "Epoch 85 | Batch: 5 | Loss: 10.3924\n",
      "Mean of loss / batch 11.004549980163574\n",
      "Epoch 86 | Batch: 1 | Loss: 11.7586\n",
      "Epoch 86 | Batch: 2 | Loss: 11.4756\n",
      "Epoch 86 | Batch: 3 | Loss: 10.9835\n",
      "Epoch 86 | Batch: 4 | Loss: 10.2823\n",
      "Epoch 86 | Batch: 5 | Loss: 10.6131\n",
      "Mean of loss / batch 11.022635459899902\n",
      "Epoch 87 | Batch: 1 | Loss: 11.4278\n",
      "Epoch 87 | Batch: 2 | Loss: 11.9701\n",
      "Epoch 87 | Batch: 3 | Loss: 10.9796\n",
      "Epoch 87 | Batch: 4 | Loss: 10.4274\n",
      "Epoch 87 | Batch: 5 | Loss: 10.2907\n",
      "Mean of loss / batch 11.019129753112793\n",
      "Epoch 88 | Batch: 1 | Loss: 11.4530\n",
      "Epoch 88 | Batch: 2 | Loss: 9.6086\n",
      "Epoch 88 | Batch: 3 | Loss: 11.6359\n",
      "Epoch 88 | Batch: 4 | Loss: 11.4448\n",
      "Epoch 88 | Batch: 5 | Loss: 10.9802\n",
      "Mean of loss / batch 11.02452564239502\n",
      "Epoch 89 | Batch: 1 | Loss: 10.6528\n",
      "Epoch 89 | Batch: 2 | Loss: 10.6292\n",
      "Epoch 89 | Batch: 3 | Loss: 11.3885\n",
      "Epoch 89 | Batch: 4 | Loss: 10.6612\n",
      "Epoch 89 | Batch: 5 | Loss: 11.3329\n",
      "Mean of loss / batch 10.932924270629883\n",
      "Epoch 90 | Batch: 1 | Loss: 10.9666\n",
      "Epoch 90 | Batch: 2 | Loss: 11.2404\n",
      "Epoch 90 | Batch: 3 | Loss: 11.1868\n",
      "Epoch 90 | Batch: 4 | Loss: 10.4481\n",
      "Epoch 90 | Batch: 5 | Loss: 10.9808\n",
      "Mean of loss / batch 10.96455192565918\n",
      "Epoch 91 | Batch: 1 | Loss: 12.2688\n",
      "Epoch 91 | Batch: 2 | Loss: 11.1142\n",
      "Epoch 91 | Batch: 3 | Loss: 10.7559\n",
      "Epoch 91 | Batch: 4 | Loss: 10.6957\n",
      "Epoch 91 | Batch: 5 | Loss: 10.3407\n",
      "Mean of loss / batch 11.035076141357422\n",
      "Epoch 92 | Batch: 1 | Loss: 9.7996\n",
      "Epoch 92 | Batch: 2 | Loss: 10.5853\n",
      "Epoch 92 | Batch: 3 | Loss: 11.6282\n",
      "Epoch 92 | Batch: 4 | Loss: 10.1813\n",
      "Epoch 92 | Batch: 5 | Loss: 13.0201\n",
      "Mean of loss / batch 11.042901992797852\n",
      "Epoch 93 | Batch: 1 | Loss: 11.2065\n",
      "Epoch 93 | Batch: 2 | Loss: 10.7784\n",
      "Epoch 93 | Batch: 3 | Loss: 11.4745\n",
      "Epoch 93 | Batch: 4 | Loss: 10.6756\n",
      "Epoch 93 | Batch: 5 | Loss: 10.6927\n",
      "Mean of loss / batch 10.965540885925293\n",
      "Epoch 94 | Batch: 1 | Loss: 12.5690\n",
      "Epoch 94 | Batch: 2 | Loss: 10.9294\n",
      "Epoch 94 | Batch: 3 | Loss: 10.3876\n",
      "Epoch 94 | Batch: 4 | Loss: 10.9864\n",
      "Epoch 94 | Batch: 5 | Loss: 10.6435\n",
      "Mean of loss / batch 11.103180885314941\n",
      "Epoch 95 | Batch: 1 | Loss: 10.6232\n",
      "Epoch 95 | Batch: 2 | Loss: 12.1938\n",
      "Epoch 95 | Batch: 3 | Loss: 10.0961\n",
      "Epoch 95 | Batch: 4 | Loss: 11.4479\n",
      "Epoch 95 | Batch: 5 | Loss: 10.9807\n",
      "Mean of loss / batch 11.068347930908203\n",
      "Epoch 96 | Batch: 1 | Loss: 10.3286\n",
      "Epoch 96 | Batch: 2 | Loss: 11.0137\n",
      "Epoch 96 | Batch: 3 | Loss: 10.9967\n",
      "Epoch 96 | Batch: 4 | Loss: 10.9856\n",
      "Epoch 96 | Batch: 5 | Loss: 11.3120\n",
      "Mean of loss / batch 10.927312850952148\n",
      "Epoch 97 | Batch: 1 | Loss: 10.4305\n",
      "Epoch 97 | Batch: 2 | Loss: 10.2614\n",
      "Epoch 97 | Batch: 3 | Loss: 11.4784\n",
      "Epoch 97 | Batch: 4 | Loss: 10.9862\n",
      "Epoch 97 | Batch: 5 | Loss: 11.6486\n",
      "Mean of loss / batch 10.961003303527832\n",
      "Epoch 98 | Batch: 1 | Loss: 10.7486\n",
      "Epoch 98 | Batch: 2 | Loss: 10.9661\n",
      "Epoch 98 | Batch: 3 | Loss: 10.6954\n",
      "Epoch 98 | Batch: 4 | Loss: 11.6066\n",
      "Epoch 98 | Batch: 5 | Loss: 10.7657\n",
      "Mean of loss / batch 10.9564790725708\n",
      "Epoch 99 | Batch: 1 | Loss: 10.4389\n",
      "Epoch 99 | Batch: 2 | Loss: 10.6277\n",
      "Epoch 99 | Batch: 3 | Loss: 10.2234\n",
      "Epoch 99 | Batch: 4 | Loss: 10.5894\n",
      "Epoch 99 | Batch: 5 | Loss: 13.4178\n",
      "Mean of loss / batch 11.059439659118652\n",
      "Epoch 100 | Batch: 1 | Loss: 11.1544\n",
      "Epoch 100 | Batch: 2 | Loss: 10.8448\n",
      "Epoch 100 | Batch: 3 | Loss: 11.3971\n",
      "Epoch 100 | Batch: 4 | Loss: 10.7543\n",
      "Epoch 100 | Batch: 5 | Loss: 10.7175\n",
      "Mean of loss / batch 10.973596572875977\n",
      "Epoch 101 | Batch: 1 | Loss: 10.6711\n",
      "Epoch 101 | Batch: 2 | Loss: 9.9629\n",
      "Epoch 101 | Batch: 3 | Loss: 12.0036\n",
      "Epoch 101 | Batch: 4 | Loss: 10.6477\n",
      "Epoch 101 | Batch: 5 | Loss: 11.7179\n",
      "Mean of loss / batch 11.000616073608398\n",
      "Epoch 102 | Batch: 1 | Loss: 10.7232\n",
      "Epoch 102 | Batch: 2 | Loss: 11.2624\n",
      "Epoch 102 | Batch: 3 | Loss: 10.9655\n",
      "Epoch 102 | Batch: 4 | Loss: 10.7268\n",
      "Epoch 102 | Batch: 5 | Loss: 10.9681\n",
      "Mean of loss / batch 10.929204940795898\n",
      "Epoch 103 | Batch: 1 | Loss: 10.6837\n",
      "Epoch 103 | Batch: 2 | Loss: 10.6493\n",
      "Epoch 103 | Batch: 3 | Loss: 9.9026\n",
      "Epoch 103 | Batch: 4 | Loss: 11.0763\n",
      "Epoch 103 | Batch: 5 | Loss: 12.8151\n",
      "Mean of loss / batch 11.02538776397705\n",
      "Epoch 104 | Batch: 1 | Loss: 10.3482\n",
      "Epoch 104 | Batch: 2 | Loss: 10.9906\n",
      "Epoch 104 | Batch: 3 | Loss: 10.2949\n",
      "Epoch 104 | Batch: 4 | Loss: 12.3002\n",
      "Epoch 104 | Batch: 5 | Loss: 11.2067\n",
      "Mean of loss / batch 11.028139114379883\n",
      "Epoch 105 | Batch: 1 | Loss: 11.1651\n",
      "Epoch 105 | Batch: 2 | Loss: 10.5187\n",
      "Epoch 105 | Batch: 3 | Loss: 11.2994\n",
      "Epoch 105 | Batch: 4 | Loss: 11.2249\n",
      "Epoch 105 | Batch: 5 | Loss: 10.7606\n",
      "Mean of loss / batch 10.993744850158691\n",
      "Epoch 106 | Batch: 1 | Loss: 10.6989\n",
      "Epoch 106 | Batch: 2 | Loss: 10.9726\n",
      "Epoch 106 | Batch: 3 | Loss: 10.3672\n",
      "Epoch 106 | Batch: 4 | Loss: 11.0035\n",
      "Epoch 106 | Batch: 5 | Loss: 11.7185\n",
      "Mean of loss / batch 10.952133178710938\n",
      "Epoch 107 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 107 | Batch: 2 | Loss: 11.4531\n",
      "Epoch 107 | Batch: 3 | Loss: 10.8418\n",
      "Epoch 107 | Batch: 4 | Loss: 11.1838\n",
      "Epoch 107 | Batch: 5 | Loss: 10.4572\n",
      "Mean of loss / batch 10.980216979980469\n",
      "Epoch 108 | Batch: 1 | Loss: 10.9800\n",
      "Epoch 108 | Batch: 2 | Loss: 10.6531\n",
      "Epoch 108 | Batch: 3 | Loss: 10.2716\n",
      "Epoch 108 | Batch: 4 | Loss: 11.0323\n",
      "Epoch 108 | Batch: 5 | Loss: 11.8108\n",
      "Mean of loss / batch 10.949560165405273\n",
      "Epoch 109 | Batch: 1 | Loss: 10.9659\n",
      "Epoch 109 | Batch: 2 | Loss: 11.2334\n",
      "Epoch 109 | Batch: 3 | Loss: 10.7531\n",
      "Epoch 109 | Batch: 4 | Loss: 10.6940\n",
      "Epoch 109 | Batch: 5 | Loss: 10.9737\n",
      "Mean of loss / batch 10.924018859863281\n",
      "Epoch 110 | Batch: 1 | Loss: 10.9706\n",
      "Epoch 110 | Batch: 2 | Loss: 10.3801\n",
      "Epoch 110 | Batch: 3 | Loss: 11.0004\n",
      "Epoch 110 | Batch: 4 | Loss: 10.2688\n",
      "Epoch 110 | Batch: 5 | Loss: 12.3487\n",
      "Mean of loss / batch 10.993733406066895\n",
      "Epoch 111 | Batch: 1 | Loss: 11.2172\n",
      "Epoch 111 | Batch: 2 | Loss: 10.7678\n",
      "Epoch 111 | Batch: 3 | Loss: 10.4418\n",
      "Epoch 111 | Batch: 4 | Loss: 11.3477\n",
      "Epoch 111 | Batch: 5 | Loss: 10.9677\n",
      "Mean of loss / batch 10.948453903198242\n",
      "Epoch 112 | Batch: 1 | Loss: 10.9668\n",
      "Epoch 112 | Batch: 2 | Loss: 10.9662\n",
      "Epoch 112 | Batch: 3 | Loss: 10.4245\n",
      "Epoch 112 | Batch: 4 | Loss: 10.9912\n",
      "Epoch 112 | Batch: 5 | Loss: 11.3262\n",
      "Mean of loss / batch 10.93497371673584\n",
      "Epoch 113 | Batch: 1 | Loss: 10.9662\n",
      "Epoch 113 | Batch: 2 | Loss: 11.7794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 | Batch: 3 | Loss: 11.0006\n",
      "Epoch 113 | Batch: 4 | Loss: 10.8440\n",
      "Epoch 113 | Batch: 5 | Loss: 10.3222\n",
      "Mean of loss / batch 10.982478141784668\n",
      "Epoch 114 | Batch: 1 | Loss: 10.6214\n",
      "Epoch 114 | Batch: 2 | Loss: 11.4062\n",
      "Epoch 114 | Batch: 3 | Loss: 11.2943\n",
      "Epoch 114 | Batch: 4 | Loss: 10.1955\n",
      "Epoch 114 | Batch: 5 | Loss: 11.4170\n",
      "Mean of loss / batch 10.986859321594238\n",
      "Epoch 115 | Batch: 1 | Loss: 10.3248\n",
      "Epoch 115 | Batch: 2 | Loss: 11.0148\n",
      "Epoch 115 | Batch: 3 | Loss: 11.3773\n",
      "Epoch 115 | Batch: 4 | Loss: 10.9707\n",
      "Epoch 115 | Batch: 5 | Loss: 10.9687\n",
      "Mean of loss / batch 10.931254386901855\n",
      "Epoch 116 | Batch: 1 | Loss: 10.9674\n",
      "Epoch 116 | Batch: 2 | Loss: 11.2456\n",
      "Epoch 116 | Batch: 3 | Loss: 10.7429\n",
      "Epoch 116 | Batch: 4 | Loss: 10.4084\n",
      "Epoch 116 | Batch: 5 | Loss: 11.3680\n",
      "Mean of loss / batch 10.94644546508789\n",
      "Epoch 117 | Batch: 1 | Loss: 10.6699\n",
      "Epoch 117 | Batch: 2 | Loss: 10.9805\n",
      "Epoch 117 | Batch: 3 | Loss: 10.6522\n",
      "Epoch 117 | Batch: 4 | Loss: 10.9877\n",
      "Epoch 117 | Batch: 5 | Loss: 11.3175\n",
      "Mean of loss / batch 10.921567916870117\n",
      "Epoch 118 | Batch: 1 | Loss: 11.5076\n",
      "Epoch 118 | Batch: 2 | Loss: 10.9791\n",
      "Epoch 118 | Batch: 3 | Loss: 10.7903\n",
      "Epoch 118 | Batch: 4 | Loss: 10.7180\n",
      "Epoch 118 | Batch: 5 | Loss: 10.6714\n",
      "Mean of loss / batch 10.933266639709473\n",
      "Epoch 119 | Batch: 1 | Loss: 11.3188\n",
      "Epoch 119 | Batch: 2 | Loss: 11.5091\n",
      "Epoch 119 | Batch: 3 | Loss: 10.9789\n",
      "Epoch 119 | Batch: 4 | Loss: 10.7897\n",
      "Epoch 119 | Batch: 5 | Loss: 10.2227\n",
      "Mean of loss / batch 10.963833808898926\n",
      "Epoch 120 | Batch: 1 | Loss: 11.4054\n",
      "Epoch 120 | Batch: 2 | Loss: 11.9330\n",
      "Epoch 120 | Batch: 3 | Loss: 11.4516\n",
      "Epoch 120 | Batch: 4 | Loss: 10.9664\n",
      "Epoch 120 | Batch: 5 | Loss: 9.8856\n",
      "Mean of loss / batch 11.128397941589355\n",
      "Epoch 121 | Batch: 1 | Loss: 11.0551\n",
      "Epoch 121 | Batch: 2 | Loss: 11.8732\n",
      "Epoch 121 | Batch: 3 | Loss: 11.2592\n",
      "Epoch 121 | Batch: 4 | Loss: 10.9657\n",
      "Epoch 121 | Batch: 5 | Loss: 10.0182\n",
      "Mean of loss / batch 11.034276008605957\n",
      "Epoch 122 | Batch: 1 | Loss: 9.7152\n",
      "Epoch 122 | Batch: 2 | Loss: 12.8008\n",
      "Epoch 122 | Batch: 3 | Loss: 11.3276\n",
      "Epoch 122 | Batch: 4 | Loss: 10.6894\n",
      "Epoch 122 | Batch: 5 | Loss: 10.6529\n",
      "Mean of loss / batch 11.037203788757324\n",
      "Epoch 123 | Batch: 1 | Loss: 10.6293\n",
      "Epoch 123 | Batch: 2 | Loss: 11.0011\n",
      "Epoch 123 | Batch: 3 | Loss: 10.9885\n",
      "Epoch 123 | Batch: 4 | Loss: 10.6409\n",
      "Epoch 123 | Batch: 5 | Loss: 11.3657\n",
      "Mean of loss / batch 10.925098419189453\n",
      "Epoch 124 | Batch: 1 | Loss: 11.5665\n",
      "Epoch 124 | Batch: 2 | Loss: 10.5941\n",
      "Epoch 124 | Batch: 3 | Loss: 11.5730\n",
      "Epoch 124 | Batch: 4 | Loss: 10.7804\n",
      "Epoch 124 | Batch: 5 | Loss: 10.4581\n",
      "Mean of loss / batch 10.99441909790039\n",
      "Epoch 125 | Batch: 1 | Loss: 9.9262\n",
      "Epoch 125 | Batch: 2 | Loss: 11.0696\n",
      "Epoch 125 | Batch: 3 | Loss: 12.3483\n",
      "Epoch 125 | Batch: 4 | Loss: 10.4609\n",
      "Epoch 125 | Batch: 5 | Loss: 11.3368\n",
      "Mean of loss / batch 11.028366088867188\n",
      "Epoch 126 | Batch: 1 | Loss: 11.5314\n",
      "Epoch 126 | Batch: 2 | Loss: 10.6238\n",
      "Epoch 126 | Batch: 3 | Loss: 10.3861\n",
      "Epoch 126 | Batch: 4 | Loss: 11.3823\n",
      "Epoch 126 | Batch: 5 | Loss: 10.9712\n",
      "Mean of loss / batch 10.978968620300293\n",
      "Epoch 127 | Batch: 1 | Loss: 10.6726\n",
      "Epoch 127 | Batch: 2 | Loss: 10.3044\n",
      "Epoch 127 | Batch: 3 | Loss: 11.4418\n",
      "Epoch 127 | Batch: 4 | Loss: 10.9797\n",
      "Epoch 127 | Batch: 5 | Loss: 11.2954\n",
      "Mean of loss / batch 10.93876838684082\n",
      "Epoch 128 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 128 | Batch: 2 | Loss: 10.4529\n",
      "Epoch 128 | Batch: 3 | Loss: 11.3413\n",
      "Epoch 128 | Batch: 4 | Loss: 10.6824\n",
      "Epoch 128 | Batch: 5 | Loss: 11.3049\n",
      "Mean of loss / batch 10.949319839477539\n",
      "Epoch 129 | Batch: 1 | Loss: 11.2285\n",
      "Epoch 129 | Batch: 2 | Loss: 11.1791\n",
      "Epoch 129 | Batch: 3 | Loss: 10.9785\n",
      "Epoch 129 | Batch: 4 | Loss: 10.9737\n",
      "Epoch 129 | Batch: 5 | Loss: 10.3759\n",
      "Mean of loss / batch 10.947129249572754\n",
      "Epoch 130 | Batch: 1 | Loss: 10.6289\n",
      "Epoch 130 | Batch: 2 | Loss: 10.2260\n",
      "Epoch 130 | Batch: 3 | Loss: 12.8954\n",
      "Epoch 130 | Batch: 4 | Loss: 10.7464\n",
      "Epoch 130 | Batch: 5 | Loss: 10.6897\n",
      "Mean of loss / batch 11.037263870239258\n",
      "Epoch 131 | Batch: 1 | Loss: 11.2963\n",
      "Epoch 131 | Batch: 2 | Loss: 11.4808\n",
      "Epoch 131 | Batch: 3 | Loss: 11.2959\n",
      "Epoch 131 | Batch: 4 | Loss: 10.8758\n",
      "Epoch 131 | Batch: 5 | Loss: 10.1273\n",
      "Mean of loss / batch 11.015225410461426\n",
      "Epoch 132 | Batch: 1 | Loss: 9.7644\n",
      "Epoch 132 | Batch: 2 | Loss: 10.5862\n",
      "Epoch 132 | Batch: 3 | Loss: 12.7106\n",
      "Epoch 132 | Batch: 4 | Loss: 10.6490\n",
      "Epoch 132 | Batch: 5 | Loss: 11.3517\n",
      "Mean of loss / batch 11.01239013671875\n",
      "Epoch 133 | Batch: 1 | Loss: 10.6773\n",
      "Epoch 133 | Batch: 2 | Loss: 9.6460\n",
      "Epoch 133 | Batch: 3 | Loss: 12.1362\n",
      "Epoch 133 | Batch: 4 | Loss: 10.6249\n",
      "Epoch 133 | Batch: 5 | Loss: 12.1851\n",
      "Mean of loss / batch 11.053884506225586\n",
      "Epoch 134 | Batch: 1 | Loss: 10.5359\n",
      "Epoch 134 | Batch: 2 | Loss: 10.6523\n",
      "Epoch 134 | Batch: 3 | Loss: 11.3465\n",
      "Epoch 134 | Batch: 4 | Loss: 10.6798\n",
      "Epoch 134 | Batch: 5 | Loss: 11.6386\n",
      "Mean of loss / batch 10.970621109008789\n",
      "Epoch 135 | Batch: 1 | Loss: 10.9676\n",
      "Epoch 135 | Batch: 2 | Loss: 10.2999\n",
      "Epoch 135 | Batch: 3 | Loss: 10.9964\n",
      "Epoch 135 | Batch: 4 | Loss: 9.9256\n",
      "Epoch 135 | Batch: 5 | Loss: 13.4865\n",
      "Mean of loss / batch 11.135211944580078\n",
      "Epoch 136 | Batch: 1 | Loss: 11.3498\n",
      "Epoch 136 | Batch: 2 | Loss: 10.7070\n",
      "Epoch 136 | Batch: 3 | Loss: 10.4052\n",
      "Epoch 136 | Batch: 4 | Loss: 11.3699\n",
      "Epoch 136 | Batch: 5 | Loss: 11.2707\n",
      "Mean of loss / batch 11.020541191101074\n",
      "Epoch 137 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 137 | Batch: 2 | Loss: 11.2083\n",
      "Epoch 137 | Batch: 3 | Loss: 10.9713\n",
      "Epoch 137 | Batch: 4 | Loss: 10.3513\n",
      "Epoch 137 | Batch: 5 | Loss: 11.3552\n",
      "Mean of loss / batch 10.970273971557617\n",
      "Epoch 138 | Batch: 1 | Loss: 10.9684\n",
      "Epoch 138 | Batch: 2 | Loss: 10.6826\n",
      "Epoch 138 | Batch: 3 | Loss: 10.6485\n",
      "Epoch 138 | Batch: 4 | Loss: 11.7155\n",
      "Epoch 138 | Batch: 5 | Loss: 10.7240\n",
      "Mean of loss / batch 10.947816848754883\n",
      "Epoch 139 | Batch: 1 | Loss: 10.3821\n",
      "Epoch 139 | Batch: 2 | Loss: 12.1549\n",
      "Epoch 139 | Batch: 3 | Loss: 11.5953\n",
      "Epoch 139 | Batch: 4 | Loss: 10.8976\n",
      "Epoch 139 | Batch: 5 | Loss: 10.3580\n",
      "Mean of loss / batch 11.077568054199219\n",
      "Epoch 140 | Batch: 1 | Loss: 9.8999\n",
      "Epoch 140 | Batch: 2 | Loss: 10.5857\n",
      "Epoch 140 | Batch: 3 | Loss: 9.5955\n",
      "Epoch 140 | Batch: 4 | Loss: 12.3931\n",
      "Epoch 140 | Batch: 5 | Loss: 12.7559\n",
      "Mean of loss / batch 11.046026229858398\n",
      "Epoch 141 | Batch: 1 | Loss: 10.3806\n",
      "Epoch 141 | Batch: 2 | Loss: 11.7022\n",
      "Epoch 141 | Batch: 3 | Loss: 10.7286\n",
      "Epoch 141 | Batch: 4 | Loss: 10.6783\n",
      "Epoch 141 | Batch: 5 | Loss: 11.6421\n",
      "Mean of loss / batch 11.026358604431152\n",
      "Epoch 142 | Batch: 1 | Loss: 10.3185\n",
      "Epoch 142 | Batch: 2 | Loss: 10.9941\n",
      "Epoch 142 | Batch: 3 | Loss: 10.2850\n",
      "Epoch 142 | Batch: 4 | Loss: 11.4577\n",
      "Epoch 142 | Batch: 5 | Loss: 12.0189\n",
      "Mean of loss / batch 11.014869689941406\n",
      "Epoch 143 | Batch: 1 | Loss: 10.7988\n",
      "Epoch 143 | Batch: 2 | Loss: 10.7235\n",
      "Epoch 143 | Batch: 3 | Loss: 11.2622\n",
      "Epoch 143 | Batch: 4 | Loss: 11.2009\n",
      "Epoch 143 | Batch: 5 | Loss: 10.7843\n",
      "Mean of loss / batch 10.953933715820312\n",
      "Epoch 144 | Batch: 1 | Loss: 11.4668\n",
      "Epoch 144 | Batch: 2 | Loss: 10.3810\n",
      "Epoch 144 | Batch: 3 | Loss: 10.9930\n",
      "Epoch 144 | Batch: 4 | Loss: 9.9406\n",
      "Epoch 144 | Batch: 5 | Loss: 12.9804\n",
      "Mean of loss / batch 11.15238094329834\n",
      "Epoch 145 | Batch: 1 | Loss: 10.2613\n",
      "Epoch 145 | Batch: 2 | Loss: 10.6136\n",
      "Epoch 145 | Batch: 3 | Loss: 11.0151\n",
      "Epoch 145 | Batch: 4 | Loss: 11.3778\n",
      "Epoch 145 | Batch: 5 | Loss: 11.5809\n",
      "Mean of loss / batch 10.969730377197266\n",
      "Epoch 146 | Batch: 1 | Loss: 10.9714\n",
      "Epoch 146 | Batch: 2 | Loss: 11.5864\n",
      "Epoch 146 | Batch: 3 | Loss: 10.9045\n",
      "Epoch 146 | Batch: 4 | Loss: 10.9699\n",
      "Epoch 146 | Batch: 5 | Loss: 10.5450\n",
      "Mean of loss / batch 10.99542236328125\n",
      "Epoch 147 | Batch: 1 | Loss: 9.3770\n",
      "Epoch 147 | Batch: 2 | Loss: 10.5888\n",
      "Epoch 147 | Batch: 3 | Loss: 11.1352\n",
      "Epoch 147 | Batch: 4 | Loss: 12.5488\n",
      "Epoch 147 | Batch: 5 | Loss: 11.5578\n",
      "Mean of loss / batch 11.041534423828125\n",
      "Epoch 148 | Batch: 1 | Loss: 10.6013\n",
      "Epoch 148 | Batch: 2 | Loss: 11.2684\n",
      "Epoch 148 | Batch: 3 | Loss: 10.7257\n",
      "Epoch 148 | Batch: 4 | Loss: 10.6764\n",
      "Epoch 148 | Batch: 5 | Loss: 11.6463\n",
      "Mean of loss / batch 10.983621597290039\n",
      "Epoch 149 | Batch: 1 | Loss: 10.7495\n",
      "Epoch 149 | Batch: 2 | Loss: 10.4173\n",
      "Epoch 149 | Batch: 3 | Loss: 10.9925\n",
      "Epoch 149 | Batch: 4 | Loss: 11.6763\n",
      "Epoch 149 | Batch: 5 | Loss: 10.9661\n",
      "Mean of loss / batch 10.96034049987793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 | Batch: 1 | Loss: 11.1984\n",
      "Epoch 150 | Batch: 2 | Loss: 10.9734\n",
      "Epoch 150 | Batch: 3 | Loss: 10.9704\n",
      "Epoch 150 | Batch: 4 | Loss: 10.7590\n",
      "Epoch 150 | Batch: 5 | Loss: 10.6978\n",
      "Mean of loss / batch 10.919794082641602\n",
      "Epoch 151 | Batch: 1 | Loss: 10.6584\n",
      "Epoch 151 | Batch: 2 | Loss: 11.3370\n",
      "Epoch 151 | Batch: 3 | Loss: 12.0966\n",
      "Epoch 151 | Batch: 4 | Loss: 10.7205\n",
      "Epoch 151 | Batch: 5 | Loss: 10.6610\n",
      "Mean of loss / batch 11.094693183898926\n",
      "Epoch 152 | Batch: 1 | Loss: 11.3332\n",
      "Epoch 152 | Batch: 2 | Loss: 10.1262\n",
      "Epoch 152 | Batch: 3 | Loss: 10.5991\n",
      "Epoch 152 | Batch: 4 | Loss: 11.0351\n",
      "Epoch 152 | Batch: 5 | Loss: 11.8188\n",
      "Mean of loss / batch 10.982465744018555\n",
      "Epoch 153 | Batch: 1 | Loss: 10.4174\n",
      "Epoch 153 | Batch: 2 | Loss: 10.6227\n",
      "Epoch 153 | Batch: 3 | Loss: 10.6097\n",
      "Epoch 153 | Batch: 4 | Loss: 11.4379\n",
      "Epoch 153 | Batch: 5 | Loss: 11.6509\n",
      "Mean of loss / batch 10.947700500488281\n",
      "Epoch 154 | Batch: 1 | Loss: 10.9670\n",
      "Epoch 154 | Batch: 2 | Loss: 11.4176\n",
      "Epoch 154 | Batch: 3 | Loss: 10.4709\n",
      "Epoch 154 | Batch: 4 | Loss: 11.6951\n",
      "Epoch 154 | Batch: 5 | Loss: 10.7312\n",
      "Mean of loss / batch 11.05638599395752\n",
      "Epoch 155 | Batch: 1 | Loss: 11.2554\n",
      "Epoch 155 | Batch: 2 | Loss: 11.6576\n",
      "Epoch 155 | Batch: 3 | Loss: 10.7660\n",
      "Epoch 155 | Batch: 4 | Loss: 10.6978\n",
      "Epoch 155 | Batch: 5 | Loss: 10.6584\n",
      "Mean of loss / batch 11.007036209106445\n",
      "Epoch 156 | Batch: 1 | Loss: 10.9849\n",
      "Epoch 156 | Batch: 2 | Loss: 10.9779\n",
      "Epoch 156 | Batch: 3 | Loss: 10.3403\n",
      "Epoch 156 | Batch: 4 | Loss: 9.7992\n",
      "Epoch 156 | Batch: 5 | Loss: 13.2058\n",
      "Mean of loss / batch 11.061624526977539\n",
      "Epoch 157 | Batch: 1 | Loss: 10.9658\n",
      "Epoch 157 | Batch: 2 | Loss: 10.4303\n",
      "Epoch 157 | Batch: 3 | Loss: 9.8968\n",
      "Epoch 157 | Batch: 4 | Loss: 11.5703\n",
      "Epoch 157 | Batch: 5 | Loss: 12.1932\n",
      "Mean of loss / batch 11.011311531066895\n",
      "Epoch 158 | Batch: 1 | Loss: 11.1849\n",
      "Epoch 158 | Batch: 2 | Loss: 11.3253\n",
      "Epoch 158 | Batch: 3 | Loss: 10.6587\n",
      "Epoch 158 | Batch: 4 | Loss: 10.6531\n",
      "Epoch 158 | Batch: 5 | Loss: 11.3451\n",
      "Mean of loss / batch 11.03344440460205\n",
      "Epoch 159 | Batch: 1 | Loss: 10.9675\n",
      "Epoch 159 | Batch: 2 | Loss: 11.2467\n",
      "Epoch 159 | Batch: 3 | Loss: 10.9665\n",
      "Epoch 159 | Batch: 4 | Loss: 10.5066\n",
      "Epoch 159 | Batch: 5 | Loss: 10.9784\n",
      "Mean of loss / batch 10.933130264282227\n",
      "Epoch 160 | Batch: 1 | Loss: 11.6093\n",
      "Epoch 160 | Batch: 2 | Loss: 10.9693\n",
      "Epoch 160 | Batch: 3 | Loss: 10.7538\n",
      "Epoch 160 | Batch: 4 | Loss: 10.6945\n",
      "Epoch 160 | Batch: 5 | Loss: 10.6562\n",
      "Mean of loss / batch 10.936620712280273\n",
      "Epoch 161 | Batch: 1 | Loss: 11.3403\n",
      "Epoch 161 | Batch: 2 | Loss: 10.3986\n",
      "Epoch 161 | Batch: 3 | Loss: 11.3741\n",
      "Epoch 161 | Batch: 4 | Loss: 10.3640\n",
      "Epoch 161 | Batch: 5 | Loss: 11.3972\n",
      "Mean of loss / batch 10.974863052368164\n",
      "Epoch 162 | Batch: 1 | Loss: 11.6038\n",
      "Epoch 162 | Batch: 2 | Loss: 10.3612\n",
      "Epoch 162 | Batch: 3 | Loss: 10.9892\n",
      "Epoch 162 | Batch: 4 | Loss: 11.6621\n",
      "Epoch 162 | Batch: 5 | Loss: 10.5202\n",
      "Mean of loss / batch 11.027297973632812\n",
      "Epoch 163 | Batch: 1 | Loss: 10.3193\n",
      "Epoch 163 | Batch: 2 | Loss: 9.7757\n",
      "Epoch 163 | Batch: 3 | Loss: 11.6499\n",
      "Epoch 163 | Batch: 4 | Loss: 12.3102\n",
      "Epoch 163 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 11.004049301147461\n",
      "Epoch 164 | Batch: 1 | Loss: 9.9842\n",
      "Epoch 164 | Batch: 2 | Loss: 11.0393\n",
      "Epoch 164 | Batch: 3 | Loss: 11.4220\n",
      "Epoch 164 | Batch: 4 | Loss: 11.6326\n",
      "Epoch 164 | Batch: 5 | Loss: 10.9679\n",
      "Mean of loss / batch 11.009176254272461\n",
      "Epoch 165 | Batch: 1 | Loss: 10.7464\n",
      "Epoch 165 | Batch: 2 | Loss: 10.4131\n",
      "Epoch 165 | Batch: 3 | Loss: 10.9934\n",
      "Epoch 165 | Batch: 4 | Loss: 11.3316\n",
      "Epoch 165 | Batch: 5 | Loss: 11.2458\n",
      "Mean of loss / batch 10.946024894714355\n",
      "Epoch 166 | Batch: 1 | Loss: 10.9665\n",
      "Epoch 166 | Batch: 2 | Loss: 10.7368\n",
      "Epoch 166 | Batch: 3 | Loss: 11.2506\n",
      "Epoch 166 | Batch: 4 | Loss: 11.1934\n",
      "Epoch 166 | Batch: 5 | Loss: 10.6106\n",
      "Mean of loss / batch 10.95158576965332\n",
      "Epoch 167 | Batch: 1 | Loss: 10.9689\n",
      "Epoch 167 | Batch: 2 | Loss: 11.2545\n",
      "Epoch 167 | Batch: 3 | Loss: 11.1959\n",
      "Epoch 167 | Batch: 4 | Loss: 10.9739\n",
      "Epoch 167 | Batch: 5 | Loss: 10.3784\n",
      "Mean of loss / batch 10.954325675964355\n",
      "Epoch 168 | Batch: 1 | Loss: 10.6293\n",
      "Epoch 168 | Batch: 2 | Loss: 11.3884\n",
      "Epoch 168 | Batch: 3 | Loss: 10.9720\n",
      "Epoch 168 | Batch: 4 | Loss: 10.9695\n",
      "Epoch 168 | Batch: 5 | Loss: 10.6782\n",
      "Mean of loss / batch 10.927469253540039\n",
      "Epoch 169 | Batch: 1 | Loss: 11.9743\n",
      "Epoch 169 | Batch: 2 | Loss: 10.9793\n",
      "Epoch 169 | Batch: 3 | Loss: 10.7911\n",
      "Epoch 169 | Batch: 4 | Loss: 10.7185\n",
      "Epoch 169 | Batch: 5 | Loss: 10.3741\n",
      "Mean of loss / batch 10.96745777130127\n",
      "Epoch 170 | Batch: 1 | Loss: 10.6134\n",
      "Epoch 170 | Batch: 2 | Loss: 11.4270\n",
      "Epoch 170 | Batch: 3 | Loss: 9.9857\n",
      "Epoch 170 | Batch: 4 | Loss: 11.5190\n",
      "Epoch 170 | Batch: 5 | Loss: 11.3680\n",
      "Mean of loss / batch 10.982625007629395\n",
      "Epoch 171 | Batch: 1 | Loss: 11.8690\n",
      "Epoch 171 | Batch: 2 | Loss: 10.8491\n",
      "Epoch 171 | Batch: 3 | Loss: 10.9680\n",
      "Epoch 171 | Batch: 4 | Loss: 10.9670\n",
      "Epoch 171 | Batch: 5 | Loss: 10.2878\n",
      "Mean of loss / batch 10.988188743591309\n",
      "Epoch 172 | Batch: 1 | Loss: 10.2358\n",
      "Epoch 172 | Batch: 2 | Loss: 11.5023\n",
      "Epoch 172 | Batch: 3 | Loss: 9.8923\n",
      "Epoch 172 | Batch: 4 | Loss: 13.0543\n",
      "Epoch 172 | Batch: 5 | Loss: 10.7181\n",
      "Mean of loss / batch 11.080568313598633\n",
      "Epoch 173 | Batch: 1 | Loss: 11.5649\n",
      "Epoch 173 | Batch: 2 | Loss: 10.9728\n",
      "Epoch 173 | Batch: 3 | Loss: 11.1711\n",
      "Epoch 173 | Batch: 4 | Loss: 10.3372\n",
      "Epoch 173 | Batch: 5 | Loss: 10.9969\n",
      "Mean of loss / batch 11.008563995361328\n",
      "Epoch 174 | Batch: 1 | Loss: 12.0476\n",
      "Epoch 174 | Batch: 2 | Loss: 10.9740\n",
      "Epoch 174 | Batch: 3 | Loss: 10.9708\n",
      "Epoch 174 | Batch: 4 | Loss: 10.3450\n",
      "Epoch 174 | Batch: 5 | Loss: 10.6245\n",
      "Mean of loss / batch 10.992384910583496\n",
      "Epoch 175 | Batch: 1 | Loss: 10.2168\n",
      "Epoch 175 | Batch: 2 | Loss: 11.5212\n",
      "Epoch 175 | Batch: 3 | Loss: 10.9948\n",
      "Epoch 175 | Batch: 4 | Loss: 10.9843\n",
      "Epoch 175 | Batch: 5 | Loss: 10.9775\n",
      "Mean of loss / batch 10.938929557800293\n",
      "Epoch 176 | Batch: 1 | Loss: 11.2886\n",
      "Epoch 176 | Batch: 2 | Loss: 9.9533\n",
      "Epoch 176 | Batch: 3 | Loss: 12.8545\n",
      "Epoch 176 | Batch: 4 | Loss: 11.3950\n",
      "Epoch 176 | Batch: 5 | Loss: 10.5144\n",
      "Mean of loss / batch 11.201171875\n",
      "Epoch 177 | Batch: 1 | Loss: 10.9829\n",
      "Epoch 177 | Batch: 2 | Loss: 11.3048\n",
      "Epoch 177 | Batch: 3 | Loss: 11.2284\n",
      "Epoch 177 | Batch: 4 | Loss: 10.7575\n",
      "Epoch 177 | Batch: 5 | Loss: 10.4280\n",
      "Mean of loss / batch 10.940329551696777\n",
      "Epoch 178 | Batch: 1 | Loss: 9.5291\n",
      "Epoch 178 | Batch: 2 | Loss: 12.7593\n",
      "Epoch 178 | Batch: 3 | Loss: 11.3165\n",
      "Epoch 178 | Batch: 4 | Loss: 10.1549\n",
      "Epoch 178 | Batch: 5 | Loss: 11.8515\n",
      "Mean of loss / batch 11.122246742248535\n",
      "Epoch 179 | Batch: 1 | Loss: 11.2516\n",
      "Epoch 179 | Batch: 2 | Loss: 10.9661\n",
      "Epoch 179 | Batch: 3 | Loss: 10.9657\n",
      "Epoch 179 | Batch: 4 | Loss: 10.2568\n",
      "Epoch 179 | Batch: 5 | Loss: 11.3914\n",
      "Mean of loss / batch 10.966326713562012\n",
      "Epoch 180 | Batch: 1 | Loss: 10.6600\n",
      "Epoch 180 | Batch: 2 | Loss: 11.6850\n",
      "Epoch 180 | Batch: 3 | Loss: 11.1968\n",
      "Epoch 180 | Batch: 4 | Loss: 10.6037\n",
      "Epoch 180 | Batch: 5 | Loss: 10.6712\n",
      "Mean of loss / batch 10.963351249694824\n",
      "Epoch 181 | Batch: 1 | Loss: 10.9801\n",
      "Epoch 181 | Batch: 2 | Loss: 10.9748\n",
      "Epoch 181 | Batch: 3 | Loss: 10.6634\n",
      "Epoch 181 | Batch: 4 | Loss: 10.6361\n",
      "Epoch 181 | Batch: 5 | Loss: 11.3747\n",
      "Mean of loss / batch 10.92579460144043\n",
      "Epoch 182 | Batch: 1 | Loss: 10.3635\n",
      "Epoch 182 | Batch: 2 | Loss: 11.3976\n",
      "Epoch 182 | Batch: 3 | Loss: 11.2887\n",
      "Epoch 182 | Batch: 4 | Loss: 10.2061\n",
      "Epoch 182 | Batch: 5 | Loss: 11.8151\n",
      "Mean of loss / batch 11.014199256896973\n",
      "Epoch 183 | Batch: 1 | Loss: 11.7855\n",
      "Epoch 183 | Batch: 2 | Loss: 11.1186\n",
      "Epoch 183 | Batch: 3 | Loss: 11.2987\n",
      "Epoch 183 | Batch: 4 | Loss: 11.2348\n",
      "Epoch 183 | Batch: 5 | Loss: 10.1241\n",
      "Mean of loss / batch 11.112330436706543\n",
      "Epoch 184 | Batch: 1 | Loss: 11.8741\n",
      "Epoch 184 | Batch: 2 | Loss: 11.2595\n",
      "Epoch 184 | Batch: 3 | Loss: 10.2652\n",
      "Epoch 184 | Batch: 4 | Loss: 10.2271\n",
      "Epoch 184 | Batch: 5 | Loss: 11.5109\n",
      "Mean of loss / batch 11.027361869812012\n",
      "Epoch 185 | Batch: 1 | Loss: 10.9926\n",
      "Epoch 185 | Batch: 2 | Loss: 10.2892\n",
      "Epoch 185 | Batch: 3 | Loss: 11.4542\n",
      "Epoch 185 | Batch: 4 | Loss: 11.3256\n",
      "Epoch 185 | Batch: 5 | Loss: 10.6905\n",
      "Mean of loss / batch 10.95043659210205\n",
      "Epoch 186 | Batch: 1 | Loss: 10.3327\n",
      "Epoch 186 | Batch: 2 | Loss: 10.1980\n",
      "Epoch 186 | Batch: 3 | Loss: 11.0641\n",
      "Epoch 186 | Batch: 4 | Loss: 11.0297\n",
      "Epoch 186 | Batch: 5 | Loss: 12.2010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of loss / batch 10.965097427368164\n",
      "Epoch 187 | Batch: 1 | Loss: 11.4059\n",
      "Epoch 187 | Batch: 2 | Loss: 10.8705\n",
      "Epoch 187 | Batch: 3 | Loss: 10.9701\n",
      "Epoch 187 | Batch: 4 | Loss: 10.5471\n",
      "Epoch 187 | Batch: 5 | Loss: 10.9739\n",
      "Mean of loss / batch 10.953495979309082\n",
      "Epoch 188 | Batch: 1 | Loss: 10.6653\n",
      "Epoch 188 | Batch: 2 | Loss: 10.6373\n",
      "Epoch 188 | Batch: 3 | Loss: 11.3723\n",
      "Epoch 188 | Batch: 4 | Loss: 10.9701\n",
      "Epoch 188 | Batch: 5 | Loss: 10.9683\n",
      "Mean of loss / batch 10.922666549682617\n",
      "Epoch 189 | Batch: 1 | Loss: 11.8195\n",
      "Epoch 189 | Batch: 2 | Loss: 10.7399\n",
      "Epoch 189 | Batch: 3 | Loss: 11.2172\n",
      "Epoch 189 | Batch: 4 | Loss: 10.7678\n",
      "Epoch 189 | Batch: 5 | Loss: 10.4418\n",
      "Mean of loss / batch 10.997239112854004\n",
      "Epoch 190 | Batch: 1 | Loss: 10.6283\n",
      "Epoch 190 | Batch: 2 | Loss: 11.3904\n",
      "Epoch 190 | Batch: 3 | Loss: 10.0369\n",
      "Epoch 190 | Batch: 4 | Loss: 11.0419\n",
      "Epoch 190 | Batch: 5 | Loss: 11.8380\n",
      "Mean of loss / batch 10.987093925476074\n",
      "Epoch 191 | Batch: 1 | Loss: 11.5272\n",
      "Epoch 191 | Batch: 2 | Loss: 10.6275\n",
      "Epoch 191 | Batch: 3 | Loss: 10.3884\n",
      "Epoch 191 | Batch: 4 | Loss: 10.6163\n",
      "Epoch 191 | Batch: 5 | Loss: 11.8256\n",
      "Mean of loss / batch 10.997007369995117\n",
      "Epoch 192 | Batch: 1 | Loss: 10.4134\n",
      "Epoch 192 | Batch: 2 | Loss: 10.6218\n",
      "Epoch 192 | Batch: 3 | Loss: 12.5993\n",
      "Epoch 192 | Batch: 4 | Loss: 10.6393\n",
      "Epoch 192 | Batch: 5 | Loss: 10.9673\n",
      "Mean of loss / batch 11.048229217529297\n",
      "Epoch 193 | Batch: 1 | Loss: 10.6876\n",
      "Epoch 193 | Batch: 2 | Loss: 9.6813\n",
      "Epoch 193 | Batch: 3 | Loss: 11.0944\n",
      "Epoch 193 | Batch: 4 | Loss: 11.9688\n",
      "Epoch 193 | Batch: 5 | Loss: 11.6127\n",
      "Mean of loss / batch 11.008954048156738\n",
      "Epoch 194 | Batch: 1 | Loss: 10.5572\n",
      "Epoch 194 | Batch: 2 | Loss: 10.6581\n",
      "Epoch 194 | Batch: 3 | Loss: 10.6326\n",
      "Epoch 194 | Batch: 4 | Loss: 10.9988\n",
      "Epoch 194 | Batch: 5 | Loss: 12.0581\n",
      "Mean of loss / batch 10.980950355529785\n",
      "Epoch 195 | Batch: 1 | Loss: 11.5325\n",
      "Epoch 195 | Batch: 2 | Loss: 11.0460\n",
      "Epoch 195 | Batch: 3 | Loss: 10.8382\n",
      "Epoch 195 | Batch: 4 | Loss: 10.9668\n",
      "Epoch 195 | Batch: 5 | Loss: 10.5114\n",
      "Mean of loss / batch 10.978965759277344\n",
      "Epoch 196 | Batch: 1 | Loss: 11.9742\n",
      "Epoch 196 | Batch: 2 | Loss: 11.1456\n",
      "Epoch 196 | Batch: 3 | Loss: 10.9927\n",
      "Epoch 196 | Batch: 4 | Loss: 10.5132\n",
      "Epoch 196 | Batch: 5 | Loss: 10.3252\n",
      "Mean of loss / batch 10.99016284942627\n",
      "Epoch 197 | Batch: 1 | Loss: 11.0147\n",
      "Epoch 197 | Batch: 2 | Loss: 10.2378\n",
      "Epoch 197 | Batch: 3 | Loss: 11.0457\n",
      "Epoch 197 | Batch: 4 | Loss: 11.4329\n",
      "Epoch 197 | Batch: 5 | Loss: 10.9783\n",
      "Mean of loss / batch 10.941854476928711\n",
      "Epoch 198 | Batch: 1 | Loss: 11.6083\n",
      "Epoch 198 | Batch: 2 | Loss: 10.7650\n",
      "Epoch 198 | Batch: 3 | Loss: 10.7017\n",
      "Epoch 198 | Batch: 4 | Loss: 11.2833\n",
      "Epoch 198 | Batch: 5 | Loss: 10.4661\n",
      "Mean of loss / batch 10.964856147766113\n",
      "Epoch 199 | Batch: 1 | Loss: 10.9841\n",
      "Epoch 199 | Batch: 2 | Loss: 9.9856\n",
      "Epoch 199 | Batch: 3 | Loss: 11.9841\n",
      "Epoch 199 | Batch: 4 | Loss: 11.2990\n",
      "Epoch 199 | Batch: 5 | Loss: 10.7056\n",
      "Mean of loss / batch 10.99168872833252\n",
      "Epoch 200 | Batch: 1 | Loss: 10.6634\n",
      "Epoch 200 | Batch: 2 | Loss: 10.6361\n",
      "Epoch 200 | Batch: 3 | Loss: 10.9965\n",
      "Epoch 200 | Batch: 4 | Loss: 11.6922\n",
      "Epoch 200 | Batch: 5 | Loss: 10.7322\n",
      "Mean of loss / batch 10.944092750549316\n",
      "Epoch 201 | Batch: 1 | Loss: 10.9675\n",
      "Epoch 201 | Batch: 2 | Loss: 10.1268\n",
      "Epoch 201 | Batch: 3 | Loss: 12.2965\n",
      "Epoch 201 | Batch: 4 | Loss: 11.2060\n",
      "Epoch 201 | Batch: 5 | Loss: 10.5862\n",
      "Mean of loss / batch 11.036577224731445\n",
      "Epoch 202 | Batch: 1 | Loss: 10.9706\n",
      "Epoch 202 | Batch: 2 | Loss: 11.8505\n",
      "Epoch 202 | Batch: 3 | Loss: 10.8559\n",
      "Epoch 202 | Batch: 4 | Loss: 10.7601\n",
      "Epoch 202 | Batch: 5 | Loss: 10.4316\n",
      "Mean of loss / batch 10.973733901977539\n",
      "Epoch 203 | Batch: 1 | Loss: 11.3537\n",
      "Epoch 203 | Batch: 2 | Loss: 11.2602\n",
      "Epoch 203 | Batch: 3 | Loss: 11.1996\n",
      "Epoch 203 | Batch: 4 | Loss: 10.5984\n",
      "Epoch 203 | Batch: 5 | Loss: 10.3697\n",
      "Mean of loss / batch 10.956306457519531\n",
      "Epoch 204 | Batch: 1 | Loss: 11.0029\n",
      "Epoch 204 | Batch: 2 | Loss: 11.3529\n",
      "Epoch 204 | Batch: 3 | Loss: 10.6767\n",
      "Epoch 204 | Batch: 4 | Loss: 11.6454\n",
      "Epoch 204 | Batch: 5 | Loss: 10.3149\n",
      "Mean of loss / batch 10.998575210571289\n",
      "Epoch 205 | Batch: 1 | Loss: 12.1170\n",
      "Epoch 205 | Batch: 2 | Loss: 10.5698\n",
      "Epoch 205 | Batch: 3 | Loss: 10.9719\n",
      "Epoch 205 | Batch: 4 | Loss: 10.3720\n",
      "Epoch 205 | Batch: 5 | Loss: 11.0023\n",
      "Mean of loss / batch 11.006606101989746\n",
      "Epoch 206 | Batch: 1 | Loss: 10.9892\n",
      "Epoch 206 | Batch: 2 | Loss: 11.3215\n",
      "Epoch 206 | Batch: 3 | Loss: 11.7858\n",
      "Epoch 206 | Batch: 4 | Loss: 10.7618\n",
      "Epoch 206 | Batch: 5 | Loss: 10.2295\n",
      "Mean of loss / batch 11.017565727233887\n",
      "Epoch 207 | Batch: 1 | Loss: 10.6098\n",
      "Epoch 207 | Batch: 2 | Loss: 9.7650\n",
      "Epoch 207 | Batch: 3 | Loss: 12.7290\n",
      "Epoch 207 | Batch: 4 | Loss: 10.9775\n",
      "Epoch 207 | Batch: 5 | Loss: 10.9731\n",
      "Mean of loss / batch 11.010871887207031\n",
      "Epoch 208 | Batch: 1 | Loss: 10.6674\n",
      "Epoch 208 | Batch: 2 | Loss: 11.6669\n",
      "Epoch 208 | Batch: 3 | Loss: 10.5167\n",
      "Epoch 208 | Batch: 4 | Loss: 10.9772\n",
      "Epoch 208 | Batch: 5 | Loss: 10.9729\n",
      "Mean of loss / batch 10.960217475891113\n",
      "Epoch 209 | Batch: 1 | Loss: 10.6679\n",
      "Epoch 209 | Batch: 2 | Loss: 10.9812\n",
      "Epoch 209 | Batch: 3 | Loss: 10.6511\n",
      "Epoch 209 | Batch: 4 | Loss: 10.9882\n",
      "Epoch 209 | Batch: 5 | Loss: 11.3189\n",
      "Mean of loss / batch 10.921468734741211\n",
      "Epoch 210 | Batch: 1 | Loss: 11.2376\n",
      "Epoch 210 | Batch: 2 | Loss: 10.9673\n",
      "Epoch 210 | Batch: 3 | Loss: 11.1908\n",
      "Epoch 210 | Batch: 4 | Loss: 10.9752\n",
      "Epoch 210 | Batch: 5 | Loss: 10.3901\n",
      "Mean of loss / batch 10.952173233032227\n",
      "Epoch 211 | Batch: 1 | Loss: 10.9862\n",
      "Epoch 211 | Batch: 2 | Loss: 10.6438\n",
      "Epoch 211 | Batch: 3 | Loss: 11.3605\n",
      "Epoch 211 | Batch: 4 | Loss: 10.9689\n",
      "Epoch 211 | Batch: 5 | Loss: 10.6806\n",
      "Mean of loss / batch 10.927986145019531\n",
      "Epoch 212 | Batch: 1 | Loss: 11.3071\n",
      "Epoch 212 | Batch: 2 | Loss: 10.7008\n",
      "Epoch 212 | Batch: 3 | Loss: 10.6603\n",
      "Epoch 212 | Batch: 4 | Loss: 10.6341\n",
      "Epoch 212 | Batch: 5 | Loss: 11.3786\n",
      "Mean of loss / batch 10.936174392700195\n",
      "Epoch 213 | Batch: 1 | Loss: 10.9708\n",
      "Epoch 213 | Batch: 2 | Loss: 11.2636\n",
      "Epoch 213 | Batch: 3 | Loss: 10.7291\n",
      "Epoch 213 | Batch: 4 | Loss: 10.9679\n",
      "Epoch 213 | Batch: 5 | Loss: 10.6850\n",
      "Mean of loss / batch 10.923294067382812\n",
      "Epoch 214 | Batch: 1 | Loss: 10.9759\n",
      "Epoch 214 | Batch: 2 | Loss: 10.9721\n",
      "Epoch 214 | Batch: 3 | Loss: 10.9696\n",
      "Epoch 214 | Batch: 4 | Loss: 10.3879\n",
      "Epoch 214 | Batch: 5 | Loss: 11.3811\n",
      "Mean of loss / batch 10.937317848205566\n",
      "Epoch 215 | Batch: 1 | Loss: 10.3574\n",
      "Epoch 215 | Batch: 2 | Loss: 11.7979\n",
      "Epoch 215 | Batch: 3 | Loss: 10.9656\n",
      "Epoch 215 | Batch: 4 | Loss: 10.9654\n",
      "Epoch 215 | Batch: 5 | Loss: 10.7033\n",
      "Mean of loss / batch 10.957894325256348\n",
      "Epoch 216 | Batch: 1 | Loss: 10.6619\n",
      "Epoch 216 | Batch: 2 | Loss: 11.6802\n",
      "Epoch 216 | Batch: 3 | Loss: 10.7366\n",
      "Epoch 216 | Batch: 4 | Loss: 10.3997\n",
      "Epoch 216 | Batch: 5 | Loss: 11.3735\n",
      "Mean of loss / batch 10.970369338989258\n",
      "Epoch 217 | Batch: 1 | Loss: 10.9702\n",
      "Epoch 217 | Batch: 2 | Loss: 10.6757\n",
      "Epoch 217 | Batch: 3 | Loss: 10.9786\n",
      "Epoch 217 | Batch: 4 | Loss: 11.2921\n",
      "Epoch 217 | Batch: 5 | Loss: 10.7099\n",
      "Mean of loss / batch 10.925312042236328\n",
      "Epoch 218 | Batch: 1 | Loss: 11.5793\n",
      "Epoch 218 | Batch: 2 | Loss: 10.7775\n",
      "Epoch 218 | Batch: 3 | Loss: 9.6886\n",
      "Epoch 218 | Batch: 4 | Loss: 11.5941\n",
      "Epoch 218 | Batch: 5 | Loss: 11.8230\n",
      "Mean of loss / batch 11.092510223388672\n",
      "Epoch 219 | Batch: 1 | Loss: 11.2418\n",
      "Epoch 219 | Batch: 2 | Loss: 10.7460\n",
      "Epoch 219 | Batch: 3 | Loss: 10.6894\n",
      "Epoch 219 | Batch: 4 | Loss: 11.2966\n",
      "Epoch 219 | Batch: 5 | Loss: 10.7071\n",
      "Mean of loss / batch 10.936198234558105\n",
      "Epoch 220 | Batch: 1 | Loss: 10.9711\n",
      "Epoch 220 | Batch: 2 | Loss: 10.9689\n",
      "Epoch 220 | Batch: 3 | Loss: 10.6804\n",
      "Epoch 220 | Batch: 4 | Loss: 10.9772\n",
      "Epoch 220 | Batch: 5 | Loss: 10.9729\n",
      "Mean of loss / batch 10.914103507995605\n",
      "Epoch 221 | Batch: 1 | Loss: 11.2724\n",
      "Epoch 221 | Batch: 2 | Loss: 10.9652\n",
      "Epoch 221 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 221 | Batch: 4 | Loss: 10.7196\n",
      "Epoch 221 | Batch: 5 | Loss: 10.6724\n",
      "Mean of loss / batch 10.91894817352295\n",
      "Epoch 222 | Batch: 1 | Loss: 11.3174\n",
      "Epoch 222 | Batch: 2 | Loss: 11.2366\n",
      "Epoch 222 | Batch: 3 | Loss: 10.5334\n",
      "Epoch 222 | Batch: 4 | Loss: 10.0041\n",
      "Epoch 222 | Batch: 5 | Loss: 11.9686\n",
      "Mean of loss / batch 11.012018203735352\n",
      "Epoch 223 | Batch: 1 | Loss: 10.3356\n",
      "Epoch 223 | Batch: 2 | Loss: 11.8236\n",
      "Epoch 223 | Batch: 3 | Loss: 10.9662\n",
      "Epoch 223 | Batch: 4 | Loss: 10.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 | Batch: 5 | Loss: 10.9735\n",
      "Mean of loss / batch 10.958744049072266\n",
      "Epoch 224 | Batch: 1 | Loss: 10.3621\n",
      "Epoch 224 | Batch: 2 | Loss: 11.0048\n",
      "Epoch 224 | Batch: 3 | Loss: 10.2586\n",
      "Epoch 224 | Batch: 4 | Loss: 11.9245\n",
      "Epoch 224 | Batch: 5 | Loss: 11.2773\n",
      "Mean of loss / batch 10.965470314025879\n",
      "Epoch 225 | Batch: 1 | Loss: 10.7195\n",
      "Epoch 225 | Batch: 2 | Loss: 10.6724\n",
      "Epoch 225 | Batch: 3 | Loss: 10.6419\n",
      "Epoch 225 | Batch: 4 | Loss: 11.3639\n",
      "Epoch 225 | Batch: 5 | Loss: 11.2668\n",
      "Mean of loss / batch 10.93288803100586\n",
      "Epoch 226 | Batch: 1 | Loss: 10.4884\n",
      "Epoch 226 | Batch: 2 | Loss: 10.2988\n",
      "Epoch 226 | Batch: 3 | Loss: 12.2932\n",
      "Epoch 226 | Batch: 4 | Loss: 10.9653\n",
      "Epoch 226 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 11.002184867858887\n",
      "Epoch 227 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 227 | Batch: 2 | Loss: 11.2106\n",
      "Epoch 227 | Batch: 3 | Loss: 10.7743\n",
      "Epoch 227 | Batch: 4 | Loss: 10.9651\n",
      "Epoch 227 | Batch: 5 | Loss: 10.7089\n",
      "Mean of loss / batch 10.924792289733887\n",
      "Epoch 228 | Batch: 1 | Loss: 11.2760\n",
      "Epoch 228 | Batch: 2 | Loss: 11.2098\n",
      "Epoch 228 | Batch: 3 | Loss: 10.7751\n",
      "Epoch 228 | Batch: 4 | Loss: 10.4513\n",
      "Epoch 228 | Batch: 5 | Loss: 10.9864\n",
      "Mean of loss / batch 10.93971061706543\n",
      "Epoch 229 | Batch: 1 | Loss: 10.6435\n",
      "Epoch 229 | Batch: 2 | Loss: 10.6232\n",
      "Epoch 229 | Batch: 3 | Loss: 10.6100\n",
      "Epoch 229 | Batch: 4 | Loss: 11.8547\n",
      "Epoch 229 | Batch: 5 | Loss: 10.9673\n",
      "Mean of loss / batch 10.939743041992188\n",
      "Epoch 230 | Batch: 1 | Loss: 11.2452\n",
      "Epoch 230 | Batch: 2 | Loss: 11.6366\n",
      "Epoch 230 | Batch: 3 | Loss: 10.9451\n",
      "Epoch 230 | Batch: 4 | Loss: 10.6542\n",
      "Epoch 230 | Batch: 5 | Loss: 10.4056\n",
      "Mean of loss / batch 10.97734546661377\n",
      "Epoch 231 | Batch: 1 | Loss: 10.6201\n",
      "Epoch 231 | Batch: 2 | Loss: 9.0051\n",
      "Epoch 231 | Batch: 3 | Loss: 12.4727\n",
      "Epoch 231 | Batch: 4 | Loss: 11.4940\n",
      "Epoch 231 | Batch: 5 | Loss: 11.7141\n",
      "Mean of loss / batch 11.061185836791992\n",
      "Epoch 232 | Batch: 1 | Loss: 10.7245\n",
      "Epoch 232 | Batch: 2 | Loss: 10.9684\n",
      "Epoch 232 | Batch: 3 | Loss: 10.6826\n",
      "Epoch 232 | Batch: 4 | Loss: 10.6485\n",
      "Epoch 232 | Batch: 5 | Loss: 11.7156\n",
      "Mean of loss / batch 10.947921752929688\n",
      "Epoch 233 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 233 | Batch: 2 | Loss: 10.7219\n",
      "Epoch 233 | Batch: 3 | Loss: 11.8532\n",
      "Epoch 233 | Batch: 4 | Loss: 10.7186\n",
      "Epoch 233 | Batch: 5 | Loss: 10.7061\n",
      "Mean of loss / batch 10.99301528930664\n",
      "Epoch 234 | Batch: 1 | Loss: 10.9712\n",
      "Epoch 234 | Batch: 2 | Loss: 11.8586\n",
      "Epoch 234 | Batch: 3 | Loss: 10.8529\n",
      "Epoch 234 | Batch: 4 | Loss: 10.9684\n",
      "Epoch 234 | Batch: 5 | Loss: 10.3123\n",
      "Mean of loss / batch 10.992691040039062\n",
      "Epoch 235 | Batch: 1 | Loss: 11.3697\n",
      "Epoch 235 | Batch: 2 | Loss: 10.3684\n",
      "Epoch 235 | Batch: 3 | Loss: 11.0032\n",
      "Epoch 235 | Batch: 4 | Loss: 11.3536\n",
      "Epoch 235 | Batch: 5 | Loss: 10.6764\n",
      "Mean of loss / batch 10.954259872436523\n",
      "Epoch 236 | Batch: 1 | Loss: 11.3123\n",
      "Epoch 236 | Batch: 2 | Loss: 11.2333\n",
      "Epoch 236 | Batch: 3 | Loss: 10.9677\n",
      "Epoch 236 | Batch: 4 | Loss: 10.7450\n",
      "Epoch 236 | Batch: 5 | Loss: 10.4112\n",
      "Mean of loss / batch 10.933891296386719\n",
      "Epoch 237 | Batch: 1 | Loss: 11.3662\n",
      "Epoch 237 | Batch: 2 | Loss: 11.2682\n",
      "Epoch 237 | Batch: 3 | Loss: 10.7258\n",
      "Epoch 237 | Batch: 4 | Loss: 10.6764\n",
      "Epoch 237 | Batch: 5 | Loss: 10.6445\n",
      "Mean of loss / batch 10.936243057250977\n",
      "Epoch 238 | Batch: 1 | Loss: 10.6239\n",
      "Epoch 238 | Batch: 2 | Loss: 11.7953\n",
      "Epoch 238 | Batch: 3 | Loss: 10.4315\n",
      "Epoch 238 | Batch: 4 | Loss: 12.0816\n",
      "Epoch 238 | Batch: 5 | Loss: 10.3962\n",
      "Mean of loss / batch 11.065705299377441\n",
      "Epoch 239 | Batch: 1 | Loss: 10.9855\n",
      "Epoch 239 | Batch: 2 | Loss: 11.3120\n",
      "Epoch 239 | Batch: 3 | Loss: 10.6980\n",
      "Epoch 239 | Batch: 4 | Loss: 10.6585\n",
      "Epoch 239 | Batch: 5 | Loss: 10.9849\n",
      "Mean of loss / batch 10.92778205871582\n",
      "Epoch 240 | Batch: 1 | Loss: 10.9779\n",
      "Epoch 240 | Batch: 2 | Loss: 11.6063\n",
      "Epoch 240 | Batch: 3 | Loss: 10.5621\n",
      "Epoch 240 | Batch: 4 | Loss: 10.3463\n",
      "Epoch 240 | Batch: 5 | Loss: 11.4098\n",
      "Mean of loss / batch 10.980483055114746\n",
      "Epoch 241 | Batch: 1 | Loss: 10.3311\n",
      "Epoch 241 | Batch: 2 | Loss: 10.6050\n",
      "Epoch 241 | Batch: 3 | Loss: 10.5981\n",
      "Epoch 241 | Batch: 4 | Loss: 11.4802\n",
      "Epoch 241 | Batch: 5 | Loss: 11.6987\n",
      "Mean of loss / batch 10.942617416381836\n",
      "Epoch 242 | Batch: 1 | Loss: 10.4943\n",
      "Epoch 242 | Batch: 2 | Loss: 11.3187\n",
      "Epoch 242 | Batch: 3 | Loss: 10.9658\n",
      "Epoch 242 | Batch: 4 | Loss: 11.2332\n",
      "Epoch 242 | Batch: 5 | Loss: 10.7533\n",
      "Mean of loss / batch 10.95306396484375\n",
      "Epoch 243 | Batch: 1 | Loss: 10.1508\n",
      "Epoch 243 | Batch: 2 | Loss: 11.4368\n",
      "Epoch 243 | Batch: 3 | Loss: 10.9789\n",
      "Epoch 243 | Batch: 4 | Loss: 11.2929\n",
      "Epoch 243 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 10.964874267578125\n",
      "Epoch 244 | Batch: 1 | Loss: 11.9842\n",
      "Epoch 244 | Batch: 2 | Loss: 11.0962\n",
      "Epoch 244 | Batch: 3 | Loss: 10.9642\n",
      "Epoch 244 | Batch: 4 | Loss: 10.6045\n",
      "Epoch 244 | Batch: 5 | Loss: 10.3737\n",
      "Mean of loss / batch 11.004571914672852\n",
      "Epoch 245 | Batch: 1 | Loss: 11.0019\n",
      "Epoch 245 | Batch: 2 | Loss: 10.9890\n",
      "Epoch 245 | Batch: 3 | Loss: 11.6612\n",
      "Epoch 245 | Batch: 4 | Loss: 10.5208\n",
      "Epoch 245 | Batch: 5 | Loss: 10.6482\n",
      "Mean of loss / batch 10.964227676391602\n",
      "Epoch 246 | Batch: 1 | Loss: 10.6262\n",
      "Epoch 246 | Batch: 2 | Loss: 10.2205\n",
      "Epoch 246 | Batch: 3 | Loss: 11.0533\n",
      "Epoch 246 | Batch: 4 | Loss: 11.8685\n",
      "Epoch 246 | Batch: 5 | Loss: 10.9679\n",
      "Mean of loss / batch 10.947283744812012\n",
      "Epoch 247 | Batch: 1 | Loss: 10.6848\n",
      "Epoch 247 | Batch: 2 | Loss: 11.3020\n",
      "Epoch 247 | Batch: 3 | Loss: 10.9652\n",
      "Epoch 247 | Batch: 4 | Loss: 10.1869\n",
      "Epoch 247 | Batch: 5 | Loss: 11.8286\n",
      "Mean of loss / batch 10.993497848510742\n",
      "Epoch 248 | Batch: 1 | Loss: 10.6890\n",
      "Epoch 248 | Batch: 2 | Loss: 11.6194\n",
      "Epoch 248 | Batch: 3 | Loss: 10.7603\n",
      "Epoch 248 | Batch: 4 | Loss: 10.9655\n",
      "Epoch 248 | Batch: 5 | Loss: 10.7016\n",
      "Mean of loss / batch 10.947153091430664\n",
      "Epoch 249 | Batch: 1 | Loss: 10.6608\n",
      "Epoch 249 | Batch: 2 | Loss: 11.3335\n",
      "Epoch 249 | Batch: 3 | Loss: 10.4060\n",
      "Epoch 249 | Batch: 4 | Loss: 12.1187\n",
      "Epoch 249 | Batch: 5 | Loss: 10.5689\n",
      "Mean of loss / batch 11.017587661743164\n",
      "Epoch 250 | Batch: 1 | Loss: 11.2825\n",
      "Epoch 250 | Batch: 2 | Loss: 11.2140\n",
      "Epoch 250 | Batch: 3 | Loss: 11.3692\n",
      "Epoch 250 | Batch: 4 | Loss: 10.7854\n",
      "Epoch 250 | Batch: 5 | Loss: 10.2521\n",
      "Mean of loss / batch 10.98064136505127\n",
      "Epoch 251 | Batch: 1 | Loss: 9.8316\n",
      "Epoch 251 | Batch: 2 | Loss: 11.0983\n",
      "Epoch 251 | Batch: 3 | Loss: 11.9779\n",
      "Epoch 251 | Batch: 4 | Loss: 10.6529\n",
      "Epoch 251 | Batch: 5 | Loss: 11.3454\n",
      "Mean of loss / batch 10.981233596801758\n",
      "Epoch 252 | Batch: 1 | Loss: 11.2548\n",
      "Epoch 252 | Batch: 2 | Loss: 10.9659\n",
      "Epoch 252 | Batch: 3 | Loss: 10.7313\n",
      "Epoch 252 | Batch: 4 | Loss: 11.5430\n",
      "Epoch 252 | Batch: 5 | Loss: 10.4333\n",
      "Mean of loss / batch 10.98564624786377\n",
      "Epoch 253 | Batch: 1 | Loss: 11.3266\n",
      "Epoch 253 | Batch: 2 | Loss: 11.2425\n",
      "Epoch 253 | Batch: 3 | Loss: 10.5240\n",
      "Epoch 253 | Batch: 4 | Loss: 10.9764\n",
      "Epoch 253 | Batch: 5 | Loss: 10.6599\n",
      "Mean of loss / batch 10.945891380310059\n",
      "Epoch 254 | Batch: 1 | Loss: 11.6851\n",
      "Epoch 254 | Batch: 2 | Loss: 10.7348\n",
      "Epoch 254 | Batch: 3 | Loss: 10.6822\n",
      "Epoch 254 | Batch: 4 | Loss: 10.6483\n",
      "Epoch 254 | Batch: 5 | Loss: 10.9896\n",
      "Mean of loss / batch 10.948001861572266\n",
      "Epoch 255 | Batch: 1 | Loss: 11.6638\n",
      "Epoch 255 | Batch: 2 | Loss: 11.4141\n",
      "Epoch 255 | Batch: 3 | Loss: 11.2530\n",
      "Epoch 255 | Batch: 4 | Loss: 10.9358\n",
      "Epoch 255 | Batch: 5 | Loss: 10.0081\n",
      "Mean of loss / batch 11.054966926574707\n",
      "Epoch 256 | Batch: 1 | Loss: 9.2281\n",
      "Epoch 256 | Batch: 2 | Loss: 11.8351\n",
      "Epoch 256 | Batch: 3 | Loss: 10.5854\n",
      "Epoch 256 | Batch: 4 | Loss: 12.5795\n",
      "Epoch 256 | Batch: 5 | Loss: 10.9698\n",
      "Mean of loss / batch 11.039608001708984\n",
      "Epoch 257 | Batch: 1 | Loss: 10.3859\n",
      "Epoch 257 | Batch: 2 | Loss: 10.6158\n",
      "Epoch 257 | Batch: 3 | Loss: 11.0127\n",
      "Epoch 257 | Batch: 4 | Loss: 11.7504\n",
      "Epoch 257 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 10.945963859558105\n",
      "Epoch 258 | Batch: 1 | Loss: 11.2174\n",
      "Epoch 258 | Batch: 2 | Loss: 10.5655\n",
      "Epoch 258 | Batch: 3 | Loss: 10.9722\n",
      "Epoch 258 | Batch: 4 | Loss: 11.5697\n",
      "Epoch 258 | Batch: 5 | Loss: 10.5915\n",
      "Mean of loss / batch 10.983243942260742\n",
      "Epoch 259 | Batch: 1 | Loss: 10.9702\n",
      "Epoch 259 | Batch: 2 | Loss: 11.2608\n",
      "Epoch 259 | Batch: 3 | Loss: 10.7312\n",
      "Epoch 259 | Batch: 4 | Loss: 11.5430\n",
      "Epoch 259 | Batch: 5 | Loss: 10.4333\n",
      "Mean of loss / batch 10.987691879272461\n",
      "Epoch 260 | Batch: 1 | Loss: 10.2930\n",
      "Epoch 260 | Batch: 2 | Loss: 12.3037\n",
      "Epoch 260 | Batch: 3 | Loss: 10.7229\n",
      "Epoch 260 | Batch: 4 | Loss: 10.9686\n",
      "Epoch 260 | Batch: 5 | Loss: 10.6817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of loss / batch 10.993971824645996\n",
      "Epoch 261 | Batch: 1 | Loss: 10.6479\n",
      "Epoch 261 | Batch: 2 | Loss: 10.6260\n",
      "Epoch 261 | Batch: 3 | Loss: 10.6118\n",
      "Epoch 261 | Batch: 4 | Loss: 11.0170\n",
      "Epoch 261 | Batch: 5 | Loss: 11.7642\n",
      "Mean of loss / batch 10.933393478393555\n",
      "Epoch 262 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 262 | Batch: 2 | Loss: 10.7091\n",
      "Epoch 262 | Batch: 3 | Loss: 10.6657\n",
      "Epoch 262 | Batch: 4 | Loss: 11.3265\n",
      "Epoch 262 | Batch: 5 | Loss: 10.9663\n",
      "Mean of loss / batch 10.926534652709961\n",
      "Epoch 263 | Batch: 1 | Loss: 11.2372\n",
      "Epoch 263 | Batch: 2 | Loss: 10.9673\n",
      "Epoch 263 | Batch: 3 | Loss: 10.7424\n",
      "Epoch 263 | Batch: 4 | Loss: 10.9666\n",
      "Epoch 263 | Batch: 5 | Loss: 10.6921\n",
      "Mean of loss / batch 10.921106338500977\n",
      "Epoch 264 | Batch: 1 | Loss: 10.6547\n",
      "Epoch 264 | Batch: 2 | Loss: 10.6304\n",
      "Epoch 264 | Batch: 3 | Loss: 11.7716\n",
      "Epoch 264 | Batch: 4 | Loss: 10.9652\n",
      "Epoch 264 | Batch: 5 | Loss: 10.7073\n",
      "Mean of loss / batch 10.945823669433594\n",
      "Epoch 265 | Batch: 1 | Loss: 11.8907\n",
      "Epoch 265 | Batch: 2 | Loss: 11.2785\n",
      "Epoch 265 | Batch: 3 | Loss: 10.6994\n",
      "Epoch 265 | Batch: 4 | Loss: 10.2788\n",
      "Epoch 265 | Batch: 5 | Loss: 11.4631\n",
      "Mean of loss / batch 11.122106552124023\n",
      "Epoch 266 | Batch: 1 | Loss: 10.6353\n",
      "Epoch 266 | Batch: 2 | Loss: 10.9970\n",
      "Epoch 266 | Batch: 3 | Loss: 10.6316\n",
      "Epoch 266 | Batch: 4 | Loss: 10.9995\n",
      "Epoch 266 | Batch: 5 | Loss: 11.3456\n",
      "Mean of loss / batch 10.921804428100586\n",
      "Epoch 267 | Batch: 1 | Loss: 10.6803\n",
      "Epoch 267 | Batch: 2 | Loss: 10.6470\n",
      "Epoch 267 | Batch: 3 | Loss: 10.9902\n",
      "Epoch 267 | Batch: 4 | Loss: 10.6387\n",
      "Epoch 267 | Batch: 5 | Loss: 11.7444\n",
      "Mean of loss / batch 10.940129280090332\n",
      "Epoch 268 | Batch: 1 | Loss: 10.2130\n",
      "Epoch 268 | Batch: 2 | Loss: 11.4095\n",
      "Epoch 268 | Batch: 3 | Loss: 11.6181\n",
      "Epoch 268 | Batch: 4 | Loss: 11.1767\n",
      "Epoch 268 | Batch: 5 | Loss: 10.6463\n",
      "Mean of loss / batch 11.012720108032227\n",
      "Epoch 269 | Batch: 1 | Loss: 11.5335\n",
      "Epoch 269 | Batch: 2 | Loss: 10.9759\n",
      "Epoch 269 | Batch: 3 | Loss: 11.3554\n",
      "Epoch 269 | Batch: 4 | Loss: 10.6979\n",
      "Epoch 269 | Batch: 5 | Loss: 10.4014\n",
      "Mean of loss / batch 10.992840766906738\n",
      "Epoch 270 | Batch: 1 | Loss: 9.8659\n",
      "Epoch 270 | Batch: 2 | Loss: 13.0960\n",
      "Epoch 270 | Batch: 3 | Loss: 11.2188\n",
      "Epoch 270 | Batch: 4 | Loss: 10.5630\n",
      "Epoch 270 | Batch: 5 | Loss: 10.6597\n",
      "Mean of loss / batch 11.080673217773438\n",
      "Epoch 271 | Batch: 1 | Loss: 10.2829\n",
      "Epoch 271 | Batch: 2 | Loss: 11.0282\n",
      "Epoch 271 | Batch: 3 | Loss: 10.6098\n",
      "Epoch 271 | Batch: 4 | Loss: 11.0194\n",
      "Epoch 271 | Batch: 5 | Loss: 11.7717\n",
      "Mean of loss / batch 10.942407608032227\n",
      "Epoch 272 | Batch: 1 | Loss: 9.9272\n",
      "Epoch 272 | Batch: 2 | Loss: 10.5903\n",
      "Epoch 272 | Batch: 3 | Loss: 11.5242\n",
      "Epoch 272 | Batch: 4 | Loss: 11.3714\n",
      "Epoch 272 | Batch: 5 | Loss: 11.5733\n",
      "Mean of loss / batch 10.997286796569824\n",
      "Epoch 273 | Batch: 1 | Loss: 10.7803\n",
      "Epoch 273 | Batch: 2 | Loss: 10.7115\n",
      "Epoch 273 | Batch: 3 | Loss: 10.0610\n",
      "Epoch 273 | Batch: 4 | Loss: 11.9225\n",
      "Epoch 273 | Batch: 5 | Loss: 11.5824\n",
      "Mean of loss / batch 11.011533737182617\n",
      "Epoch 274 | Batch: 1 | Loss: 11.1664\n",
      "Epoch 274 | Batch: 2 | Loss: 10.8267\n",
      "Epoch 274 | Batch: 3 | Loss: 11.4164\n",
      "Epoch 274 | Batch: 4 | Loss: 10.9940\n",
      "Epoch 274 | Batch: 5 | Loss: 10.5211\n",
      "Mean of loss / batch 10.984918594360352\n",
      "Epoch 275 | Batch: 1 | Loss: 11.9455\n",
      "Epoch 275 | Batch: 2 | Loss: 11.1411\n",
      "Epoch 275 | Batch: 3 | Loss: 11.1228\n",
      "Epoch 275 | Batch: 4 | Loss: 10.7030\n",
      "Epoch 275 | Batch: 5 | Loss: 10.1219\n",
      "Mean of loss / batch 11.006861686706543\n",
      "Epoch 276 | Batch: 1 | Loss: 11.8758\n",
      "Epoch 276 | Batch: 2 | Loss: 10.0928\n",
      "Epoch 276 | Batch: 3 | Loss: 11.0301\n",
      "Epoch 276 | Batch: 4 | Loss: 10.2105\n",
      "Epoch 276 | Batch: 5 | Loss: 11.9975\n",
      "Mean of loss / batch 11.0413236618042\n",
      "Epoch 277 | Batch: 1 | Loss: 10.6489\n",
      "Epoch 277 | Batch: 2 | Loss: 12.8022\n",
      "Epoch 277 | Batch: 3 | Loss: 10.5617\n",
      "Epoch 277 | Batch: 4 | Loss: 10.2485\n",
      "Epoch 277 | Batch: 5 | Loss: 11.9392\n",
      "Mean of loss / batch 11.24011516571045\n",
      "Epoch 278 | Batch: 1 | Loss: 10.6613\n",
      "Epoch 278 | Batch: 2 | Loss: 11.6818\n",
      "Epoch 278 | Batch: 3 | Loss: 10.2761\n",
      "Epoch 278 | Batch: 4 | Loss: 10.6154\n",
      "Epoch 278 | Batch: 5 | Loss: 11.8297\n",
      "Mean of loss / batch 11.012853622436523\n",
      "Epoch 279 | Batch: 1 | Loss: 11.2441\n",
      "Epoch 279 | Batch: 2 | Loss: 10.9667\n",
      "Epoch 279 | Batch: 3 | Loss: 10.7379\n",
      "Epoch 279 | Batch: 4 | Loss: 10.4014\n",
      "Epoch 279 | Batch: 5 | Loss: 11.3723\n",
      "Mean of loss / batch 10.944483757019043\n",
      "Epoch 280 | Batch: 1 | Loss: 10.9701\n",
      "Epoch 280 | Batch: 2 | Loss: 11.5526\n",
      "Epoch 280 | Batch: 3 | Loss: 10.7898\n",
      "Epoch 280 | Batch: 4 | Loss: 11.4599\n",
      "Epoch 280 | Batch: 5 | Loss: 10.3933\n",
      "Mean of loss / batch 11.033145904541016\n",
      "Epoch 281 | Batch: 1 | Loss: 9.8861\n",
      "Epoch 281 | Batch: 2 | Loss: 12.5683\n",
      "Epoch 281 | Batch: 3 | Loss: 10.3723\n",
      "Epoch 281 | Batch: 4 | Loss: 11.0023\n",
      "Epoch 281 | Batch: 5 | Loss: 11.3516\n",
      "Mean of loss / batch 11.036114692687988\n",
      "Epoch 282 | Batch: 1 | Loss: 10.9681\n",
      "Epoch 282 | Batch: 2 | Loss: 11.8159\n",
      "Epoch 282 | Batch: 3 | Loss: 10.3620\n",
      "Epoch 282 | Batch: 4 | Loss: 11.4105\n",
      "Epoch 282 | Batch: 5 | Loss: 10.9749\n",
      "Mean of loss / batch 11.106268882751465\n",
      "Epoch 283 | Batch: 1 | Loss: 10.6631\n",
      "Epoch 283 | Batch: 2 | Loss: 9.9416\n",
      "Epoch 283 | Batch: 3 | Loss: 11.5438\n",
      "Epoch 283 | Batch: 4 | Loss: 10.9997\n",
      "Epoch 283 | Batch: 5 | Loss: 11.7046\n",
      "Mean of loss / batch 10.970568656921387\n",
      "Epoch 284 | Batch: 1 | Loss: 10.4902\n",
      "Epoch 284 | Batch: 2 | Loss: 10.9806\n",
      "Epoch 284 | Batch: 3 | Loss: 11.6208\n",
      "Epoch 284 | Batch: 4 | Loss: 10.9686\n",
      "Epoch 284 | Batch: 5 | Loss: 10.7501\n",
      "Mean of loss / batch 10.962056159973145\n",
      "Epoch 285 | Batch: 1 | Loss: 10.9660\n",
      "Epoch 285 | Batch: 2 | Loss: 10.6962\n",
      "Epoch 285 | Batch: 3 | Loss: 10.3414\n",
      "Epoch 285 | Batch: 4 | Loss: 11.0102\n",
      "Epoch 285 | Batch: 5 | Loss: 11.7417\n",
      "Mean of loss / batch 10.95108699798584\n",
      "Epoch 286 | Batch: 1 | Loss: 11.2148\n",
      "Epoch 286 | Batch: 2 | Loss: 10.7701\n",
      "Epoch 286 | Batch: 3 | Loss: 10.4447\n",
      "Epoch 286 | Batch: 4 | Loss: 11.7045\n",
      "Epoch 286 | Batch: 5 | Loss: 10.7279\n",
      "Mean of loss / batch 10.972400665283203\n",
      "Epoch 287 | Batch: 1 | Loss: 11.8387\n",
      "Epoch 287 | Batch: 2 | Loss: 10.8603\n",
      "Epoch 287 | Batch: 3 | Loss: 10.7629\n",
      "Epoch 287 | Batch: 4 | Loss: 10.1703\n",
      "Epoch 287 | Batch: 5 | Loss: 11.4280\n",
      "Mean of loss / batch 11.012052536010742\n",
      "Epoch 288 | Batch: 1 | Loss: 11.6395\n",
      "Epoch 288 | Batch: 2 | Loss: 10.9676\n",
      "Epoch 288 | Batch: 3 | Loss: 10.7442\n",
      "Epoch 288 | Batch: 4 | Loss: 10.1319\n",
      "Epoch 288 | Batch: 5 | Loss: 11.4454\n",
      "Mean of loss / batch 10.985716819763184\n",
      "Epoch 289 | Batch: 1 | Loss: 11.6594\n",
      "Epoch 289 | Batch: 2 | Loss: 10.9667\n",
      "Epoch 289 | Batch: 3 | Loss: 10.9661\n",
      "Epoch 289 | Batch: 4 | Loss: 10.9657\n",
      "Epoch 289 | Batch: 5 | Loss: 10.2566\n",
      "Mean of loss / batch 10.962900161743164\n",
      "Epoch 290 | Batch: 1 | Loss: 10.6130\n",
      "Epoch 290 | Batch: 2 | Loss: 9.7786\n",
      "Epoch 290 | Batch: 3 | Loss: 11.6479\n",
      "Epoch 290 | Batch: 4 | Loss: 12.3073\n",
      "Epoch 290 | Batch: 5 | Loss: 10.7221\n",
      "Mean of loss / batch 11.013753890991211\n",
      "Epoch 291 | Batch: 1 | Loss: 10.6740\n",
      "Epoch 291 | Batch: 2 | Loss: 11.9877\n",
      "Epoch 291 | Batch: 3 | Loss: 10.8086\n",
      "Epoch 291 | Batch: 4 | Loss: 10.7298\n",
      "Epoch 291 | Batch: 5 | Loss: 10.6790\n",
      "Mean of loss / batch 10.975825309753418\n",
      "Epoch 292 | Batch: 1 | Loss: 10.6462\n",
      "Epoch 292 | Batch: 2 | Loss: 10.6249\n",
      "Epoch 292 | Batch: 3 | Loss: 11.3979\n",
      "Epoch 292 | Batch: 4 | Loss: 10.9732\n",
      "Epoch 292 | Batch: 5 | Loss: 10.9703\n",
      "Mean of loss / batch 10.922496795654297\n",
      "Epoch 293 | Batch: 1 | Loss: 9.7967\n",
      "Epoch 293 | Batch: 2 | Loss: 11.5558\n",
      "Epoch 293 | Batch: 3 | Loss: 11.7818\n",
      "Epoch 293 | Batch: 4 | Loss: 10.7026\n",
      "Epoch 293 | Batch: 5 | Loss: 11.2824\n",
      "Mean of loss / batch 11.023847579956055\n",
      "Epoch 294 | Batch: 1 | Loss: 10.7162\n",
      "Epoch 294 | Batch: 2 | Loss: 11.2689\n",
      "Epoch 294 | Batch: 3 | Loss: 10.9653\n",
      "Epoch 294 | Batch: 4 | Loss: 10.7230\n",
      "Epoch 294 | Batch: 5 | Loss: 10.9686\n",
      "Mean of loss / batch 10.928398132324219\n",
      "Epoch 295 | Batch: 1 | Loss: 10.3961\n",
      "Epoch 295 | Batch: 2 | Loss: 11.3757\n",
      "Epoch 295 | Batch: 3 | Loss: 10.6665\n",
      "Epoch 295 | Batch: 4 | Loss: 10.6381\n",
      "Epoch 295 | Batch: 5 | Loss: 11.7464\n",
      "Mean of loss / batch 10.964578628540039\n",
      "Epoch 296 | Batch: 1 | Loss: 10.9650\n",
      "Epoch 296 | Batch: 2 | Loss: 10.4624\n",
      "Epoch 296 | Batch: 3 | Loss: 11.3360\n",
      "Epoch 296 | Batch: 4 | Loss: 10.9669\n",
      "Epoch 296 | Batch: 5 | Loss: 10.9662\n",
      "Mean of loss / batch 10.939282417297363\n",
      "Epoch 297 | Batch: 1 | Loss: 11.5078\n",
      "Epoch 297 | Batch: 2 | Loss: 10.8119\n",
      "Epoch 297 | Batch: 3 | Loss: 10.7319\n",
      "Epoch 297 | Batch: 4 | Loss: 10.3931\n",
      "Epoch 297 | Batch: 5 | Loss: 11.3777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of loss / batch 10.96446704864502\n",
      "Epoch 298 | Batch: 1 | Loss: 10.6657\n",
      "Epoch 298 | Batch: 2 | Loss: 11.3266\n",
      "Epoch 298 | Batch: 3 | Loss: 12.0714\n",
      "Epoch 298 | Batch: 4 | Loss: 10.8864\n",
      "Epoch 298 | Batch: 5 | Loss: 10.3476\n",
      "Mean of loss / batch 11.059514999389648\n",
      "Epoch 299 | Batch: 1 | Loss: 10.2591\n",
      "Epoch 299 | Batch: 2 | Loss: 9.7066\n",
      "Epoch 299 | Batch: 3 | Loss: 11.7013\n",
      "Epoch 299 | Batch: 4 | Loss: 11.4880\n",
      "Epoch 299 | Batch: 5 | Loss: 11.7073\n",
      "Mean of loss / batch 10.972455024719238\n",
      "Epoch 300 | Batch: 1 | Loss: 10.0114\n",
      "Epoch 300 | Batch: 2 | Loss: 10.1532\n",
      "Epoch 300 | Batch: 3 | Loss: 10.5851\n",
      "Epoch 300 | Batch: 4 | Loss: 13.1124\n",
      "Epoch 300 | Batch: 5 | Loss: 11.4780\n",
      "Mean of loss / batch 11.06800365447998\n",
      "Epoch 301 | Batch: 1 | Loss: 10.5168\n",
      "Epoch 301 | Batch: 2 | Loss: 9.6778\n",
      "Epoch 301 | Batch: 3 | Loss: 11.0951\n",
      "Epoch 301 | Batch: 4 | Loss: 12.4308\n",
      "Epoch 301 | Batch: 5 | Loss: 11.7750\n",
      "Mean of loss / batch 11.099117279052734\n",
      "Epoch 302 | Batch: 1 | Loss: 11.0012\n",
      "Epoch 302 | Batch: 2 | Loss: 10.8453\n",
      "Epoch 302 | Batch: 3 | Loss: 10.9677\n",
      "Epoch 302 | Batch: 4 | Loss: 10.7451\n",
      "Epoch 302 | Batch: 5 | Loss: 11.2439\n",
      "Mean of loss / batch 10.960634231567383\n",
      "Epoch 303 | Batch: 1 | Loss: 10.7443\n",
      "Epoch 303 | Batch: 2 | Loss: 10.1322\n",
      "Epoch 303 | Batch: 3 | Loss: 12.7138\n",
      "Epoch 303 | Batch: 4 | Loss: 10.5936\n",
      "Epoch 303 | Batch: 5 | Loss: 11.2717\n",
      "Mean of loss / batch 11.091108322143555\n",
      "Epoch 304 | Batch: 1 | Loss: 10.4816\n",
      "Epoch 304 | Batch: 2 | Loss: 12.0128\n",
      "Epoch 304 | Batch: 3 | Loss: 10.9763\n",
      "Epoch 304 | Batch: 4 | Loss: 10.9723\n",
      "Epoch 304 | Batch: 5 | Loss: 10.5645\n",
      "Mean of loss / batch 11.001514434814453\n",
      "Epoch 305 | Batch: 1 | Loss: 10.3479\n",
      "Epoch 305 | Batch: 2 | Loss: 11.0084\n",
      "Epoch 305 | Batch: 3 | Loss: 11.3645\n",
      "Epoch 305 | Batch: 4 | Loss: 10.6714\n",
      "Epoch 305 | Batch: 5 | Loss: 11.3187\n",
      "Mean of loss / batch 10.942182540893555\n",
      "Epoch 306 | Batch: 1 | Loss: 10.9658\n",
      "Epoch 306 | Batch: 2 | Loss: 10.6979\n",
      "Epoch 306 | Batch: 3 | Loss: 11.6017\n",
      "Epoch 306 | Batch: 4 | Loss: 10.5657\n",
      "Epoch 306 | Batch: 5 | Loss: 10.9722\n",
      "Mean of loss / batch 10.960673332214355\n",
      "Epoch 307 | Batch: 1 | Loss: 10.3698\n",
      "Epoch 307 | Batch: 2 | Loss: 11.0029\n",
      "Epoch 307 | Batch: 3 | Loss: 11.7161\n",
      "Epoch 307 | Batch: 4 | Loss: 10.9652\n",
      "Epoch 307 | Batch: 5 | Loss: 10.7218\n",
      "Mean of loss / batch 10.955166816711426\n",
      "Epoch 308 | Batch: 1 | Loss: 10.6738\n",
      "Epoch 308 | Batch: 2 | Loss: 10.9792\n",
      "Epoch 308 | Batch: 3 | Loss: 11.2939\n",
      "Epoch 308 | Batch: 4 | Loss: 11.4777\n",
      "Epoch 308 | Batch: 5 | Loss: 10.5172\n",
      "Mean of loss / batch 10.988386154174805\n",
      "Epoch 309 | Batch: 1 | Loss: 10.6512\n",
      "Epoch 309 | Batch: 2 | Loss: 11.3482\n",
      "Epoch 309 | Batch: 3 | Loss: 11.8342\n",
      "Epoch 309 | Batch: 4 | Loss: 10.7306\n",
      "Epoch 309 | Batch: 5 | Loss: 10.4547\n",
      "Mean of loss / batch 11.00376033782959\n",
      "Epoch 310 | Batch: 1 | Loss: 10.2770\n",
      "Epoch 310 | Batch: 2 | Loss: 10.1618\n",
      "Epoch 310 | Batch: 3 | Loss: 10.0865\n",
      "Epoch 310 | Batch: 4 | Loss: 12.7921\n",
      "Epoch 310 | Batch: 5 | Loss: 11.6687\n",
      "Mean of loss / batch 10.99724292755127\n",
      "Epoch 311 | Batch: 1 | Loss: 10.2899\n",
      "Epoch 311 | Batch: 2 | Loss: 11.3783\n",
      "Epoch 311 | Batch: 3 | Loss: 11.2761\n",
      "Epoch 311 | Batch: 4 | Loss: 10.4756\n",
      "Epoch 311 | Batch: 5 | Loss: 11.6747\n",
      "Mean of loss / batch 11.018927574157715\n",
      "Epoch 312 | Batch: 1 | Loss: 10.5111\n",
      "Epoch 312 | Batch: 2 | Loss: 11.9745\n",
      "Epoch 312 | Batch: 3 | Loss: 10.8129\n",
      "Epoch 312 | Batch: 4 | Loss: 10.9657\n",
      "Epoch 312 | Batch: 5 | Loss: 10.7287\n",
      "Mean of loss / batch 10.998575210571289\n",
      "Epoch 313 | Batch: 1 | Loss: 11.5472\n",
      "Epoch 313 | Batch: 2 | Loss: 10.9745\n",
      "Epoch 313 | Batch: 3 | Loss: 10.9711\n",
      "Epoch 313 | Batch: 4 | Loss: 10.1419\n",
      "Epoch 313 | Batch: 5 | Loss: 11.4333\n",
      "Mean of loss / batch 11.013590812683105\n",
      "Epoch 314 | Batch: 1 | Loss: 9.9775\n",
      "Epoch 314 | Batch: 2 | Loss: 11.0560\n",
      "Epoch 314 | Batch: 3 | Loss: 11.4500\n",
      "Epoch 314 | Batch: 4 | Loss: 12.0065\n",
      "Epoch 314 | Batch: 5 | Loss: 10.6286\n",
      "Mean of loss / batch 11.023728370666504\n",
      "Epoch 315 | Batch: 1 | Loss: 11.2572\n",
      "Epoch 315 | Batch: 2 | Loss: 10.7339\n",
      "Epoch 315 | Batch: 3 | Loss: 10.6816\n",
      "Epoch 315 | Batch: 4 | Loss: 10.6479\n",
      "Epoch 315 | Batch: 5 | Loss: 11.3535\n",
      "Mean of loss / batch 10.934839248657227\n",
      "Epoch 316 | Batch: 1 | Loss: 10.9682\n",
      "Epoch 316 | Batch: 2 | Loss: 10.3994\n",
      "Epoch 316 | Batch: 3 | Loss: 10.6187\n",
      "Epoch 316 | Batch: 4 | Loss: 11.8156\n",
      "Epoch 316 | Batch: 5 | Loss: 10.9660\n",
      "Mean of loss / batch 10.953592300415039\n",
      "Epoch 317 | Batch: 1 | Loss: 12.0417\n",
      "Epoch 317 | Batch: 2 | Loss: 10.9679\n",
      "Epoch 317 | Batch: 3 | Loss: 10.0697\n",
      "Epoch 317 | Batch: 4 | Loss: 11.5319\n",
      "Epoch 317 | Batch: 5 | Loss: 11.3764\n",
      "Mean of loss / batch 11.19752025604248\n",
      "Epoch 318 | Batch: 1 | Loss: 10.6662\n",
      "Epoch 318 | Batch: 2 | Loss: 10.2940\n",
      "Epoch 318 | Batch: 3 | Loss: 10.1728\n",
      "Epoch 318 | Batch: 4 | Loss: 12.0615\n",
      "Epoch 318 | Batch: 5 | Loss: 11.6734\n",
      "Mean of loss / batch 10.97356128692627\n",
      "Epoch 319 | Batch: 1 | Loss: 11.1932\n",
      "Epoch 319 | Batch: 2 | Loss: 11.1564\n",
      "Epoch 319 | Batch: 3 | Loss: 10.5504\n",
      "Epoch 319 | Batch: 4 | Loss: 10.9734\n",
      "Epoch 319 | Batch: 5 | Loss: 10.9704\n",
      "Mean of loss / batch 10.968769073486328\n",
      "Epoch 320 | Batch: 1 | Loss: 10.9685\n",
      "Epoch 320 | Batch: 2 | Loss: 11.5376\n",
      "Epoch 320 | Batch: 3 | Loss: 10.9755\n",
      "Epoch 320 | Batch: 4 | Loss: 10.7788\n",
      "Epoch 320 | Batch: 5 | Loss: 10.4561\n",
      "Mean of loss / batch 10.943325996398926\n",
      "Epoch 321 | Batch: 1 | Loss: 9.5703\n",
      "Epoch 321 | Batch: 2 | Loss: 12.7212\n",
      "Epoch 321 | Batch: 3 | Loss: 10.6475\n",
      "Epoch 321 | Batch: 4 | Loss: 10.9900\n",
      "Epoch 321 | Batch: 5 | Loss: 11.3234\n",
      "Mean of loss / batch 11.050463676452637\n",
      "Epoch 322 | Batch: 1 | Loss: 10.6917\n",
      "Epoch 322 | Batch: 2 | Loss: 10.9742\n",
      "Epoch 322 | Batch: 3 | Loss: 11.8902\n",
      "Epoch 322 | Batch: 4 | Loss: 10.9871\n",
      "Epoch 322 | Batch: 5 | Loss: 10.4796\n",
      "Mean of loss / batch 11.0045804977417\n",
      "Epoch 323 | Batch: 1 | Loss: 10.9782\n",
      "Epoch 323 | Batch: 2 | Loss: 10.9736\n",
      "Epoch 323 | Batch: 3 | Loss: 10.6662\n",
      "Epoch 323 | Batch: 4 | Loss: 10.2940\n",
      "Epoch 323 | Batch: 5 | Loss: 11.8761\n",
      "Mean of loss / batch 10.957612991333008\n",
      "Epoch 324 | Batch: 1 | Loss: 10.9683\n",
      "Epoch 324 | Batch: 2 | Loss: 10.9671\n",
      "Epoch 324 | Batch: 3 | Loss: 10.6888\n",
      "Epoch 324 | Batch: 4 | Loss: 11.2973\n",
      "Epoch 324 | Batch: 5 | Loss: 10.7067\n",
      "Mean of loss / batch 10.92564582824707\n",
      "Epoch 325 | Batch: 1 | Loss: 10.3570\n",
      "Epoch 325 | Batch: 2 | Loss: 11.4021\n",
      "Epoch 325 | Batch: 3 | Loss: 10.9737\n",
      "Epoch 325 | Batch: 4 | Loss: 11.5804\n",
      "Epoch 325 | Batch: 5 | Loss: 10.5827\n",
      "Mean of loss / batch 10.97920036315918\n",
      "Epoch 326 | Batch: 1 | Loss: 9.7484\n",
      "Epoch 326 | Batch: 2 | Loss: 10.5855\n",
      "Epoch 326 | Batch: 3 | Loss: 12.0791\n",
      "Epoch 326 | Batch: 4 | Loss: 9.9332\n",
      "Epoch 326 | Batch: 5 | Loss: 13.4727\n",
      "Mean of loss / batch 11.16376781463623\n",
      "Epoch 327 | Batch: 1 | Loss: 10.9733\n",
      "Epoch 327 | Batch: 2 | Loss: 10.7710\n",
      "Epoch 327 | Batch: 3 | Loss: 10.9652\n",
      "Epoch 327 | Batch: 4 | Loss: 11.2231\n",
      "Epoch 327 | Batch: 5 | Loss: 10.7623\n",
      "Mean of loss / batch 10.938959121704102\n",
      "Epoch 328 | Batch: 1 | Loss: 10.6999\n",
      "Epoch 328 | Batch: 2 | Loss: 10.6597\n",
      "Epoch 328 | Batch: 3 | Loss: 11.6857\n",
      "Epoch 328 | Batch: 4 | Loss: 10.7346\n",
      "Epoch 328 | Batch: 5 | Loss: 10.9673\n",
      "Mean of loss / batch 10.949444770812988\n",
      "Epoch 329 | Batch: 1 | Loss: 10.6879\n",
      "Epoch 329 | Batch: 2 | Loss: 11.2984\n",
      "Epoch 329 | Batch: 3 | Loss: 11.2243\n",
      "Epoch 329 | Batch: 4 | Loss: 10.9688\n",
      "Epoch 329 | Batch: 5 | Loss: 10.5350\n",
      "Mean of loss / batch 10.942880630493164\n",
      "Epoch 330 | Batch: 1 | Loss: 11.6214\n",
      "Epoch 330 | Batch: 2 | Loss: 10.7595\n",
      "Epoch 330 | Batch: 3 | Loss: 10.6981\n",
      "Epoch 330 | Batch: 4 | Loss: 10.0301\n",
      "Epoch 330 | Batch: 5 | Loss: 11.9473\n",
      "Mean of loss / batch 11.01127815246582\n",
      "Epoch 331 | Batch: 1 | Loss: 10.3464\n",
      "Epoch 331 | Batch: 2 | Loss: 12.2116\n",
      "Epoch 331 | Batch: 3 | Loss: 10.7449\n",
      "Epoch 331 | Batch: 4 | Loss: 10.9664\n",
      "Epoch 331 | Batch: 5 | Loss: 10.6935\n",
      "Mean of loss / batch 10.992561340332031\n",
      "Epoch 332 | Batch: 1 | Loss: 11.2921\n",
      "Epoch 332 | Batch: 2 | Loss: 10.7099\n",
      "Epoch 332 | Batch: 3 | Loss: 11.2750\n",
      "Epoch 332 | Batch: 4 | Loss: 10.4771\n",
      "Epoch 332 | Batch: 5 | Loss: 10.9824\n",
      "Mean of loss / batch 10.947305679321289\n",
      "Epoch 333 | Batch: 1 | Loss: 10.3222\n",
      "Epoch 333 | Batch: 2 | Loss: 11.4278\n",
      "Epoch 333 | Batch: 3 | Loss: 11.3084\n",
      "Epoch 333 | Batch: 4 | Loss: 10.7001\n",
      "Epoch 333 | Batch: 5 | Loss: 10.9724\n",
      "Mean of loss / batch 10.946170806884766\n",
      "Epoch 334 | Batch: 1 | Loss: 9.7676\n",
      "Epoch 334 | Batch: 2 | Loss: 10.5858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334 | Batch: 3 | Loss: 11.0801\n",
      "Epoch 334 | Batch: 4 | Loss: 11.4879\n",
      "Epoch 334 | Batch: 5 | Loss: 12.0668\n",
      "Mean of loss / batch 10.997636795043945\n",
      "Epoch 335 | Batch: 1 | Loss: 10.9728\n",
      "Epoch 335 | Batch: 2 | Loss: 10.9700\n",
      "Epoch 335 | Batch: 3 | Loss: 10.7574\n",
      "Epoch 335 | Batch: 4 | Loss: 10.9656\n",
      "Epoch 335 | Batch: 5 | Loss: 10.9654\n",
      "Mean of loss / batch 10.926268577575684\n",
      "Epoch 336 | Batch: 1 | Loss: 10.7027\n",
      "Epoch 336 | Batch: 2 | Loss: 10.3511\n",
      "Epoch 336 | Batch: 3 | Loss: 11.0076\n",
      "Epoch 336 | Batch: 4 | Loss: 11.3627\n",
      "Epoch 336 | Batch: 5 | Loss: 11.2660\n",
      "Mean of loss / batch 10.938013076782227\n",
      "Epoch 337 | Batch: 1 | Loss: 10.9654\n",
      "Epoch 337 | Batch: 2 | Loss: 10.9653\n",
      "Epoch 337 | Batch: 3 | Loss: 11.4506\n",
      "Epoch 337 | Batch: 4 | Loss: 10.6988\n",
      "Epoch 337 | Batch: 5 | Loss: 10.6999\n",
      "Mean of loss / batch 10.955978393554688\n",
      "Epoch 338 | Batch: 1 | Loss: 10.6597\n",
      "Epoch 338 | Batch: 2 | Loss: 10.6337\n",
      "Epoch 338 | Batch: 3 | Loss: 12.9045\n",
      "Epoch 338 | Batch: 4 | Loss: 10.9009\n",
      "Epoch 338 | Batch: 5 | Loss: 10.4195\n",
      "Mean of loss / batch 11.103645324707031\n",
      "Epoch 339 | Batch: 1 | Loss: 10.9833\n",
      "Epoch 339 | Batch: 2 | Loss: 10.9769\n",
      "Epoch 339 | Batch: 3 | Loss: 10.9727\n",
      "Epoch 339 | Batch: 4 | Loss: 10.6684\n",
      "Epoch 339 | Batch: 5 | Loss: 10.9810\n",
      "Mean of loss / batch 10.916472434997559\n",
      "Epoch 340 | Batch: 1 | Loss: 11.6234\n",
      "Epoch 340 | Batch: 2 | Loss: 10.7587\n",
      "Epoch 340 | Batch: 3 | Loss: 10.9656\n",
      "Epoch 340 | Batch: 4 | Loss: 10.1713\n",
      "Epoch 340 | Batch: 5 | Loss: 11.4276\n",
      "Mean of loss / batch 10.98930549621582\n",
      "Epoch 341 | Batch: 1 | Loss: 9.9850\n",
      "Epoch 341 | Batch: 2 | Loss: 12.4499\n",
      "Epoch 341 | Batch: 3 | Loss: 10.6922\n",
      "Epoch 341 | Batch: 4 | Loss: 11.6129\n",
      "Epoch 341 | Batch: 5 | Loss: 10.5569\n",
      "Mean of loss / batch 11.059393882751465\n",
      "Epoch 342 | Batch: 1 | Loss: 10.3430\n",
      "Epoch 342 | Batch: 2 | Loss: 12.2172\n",
      "Epoch 342 | Batch: 3 | Loss: 10.5204\n",
      "Epoch 342 | Batch: 4 | Loss: 10.9768\n",
      "Epoch 342 | Batch: 5 | Loss: 10.9726\n",
      "Mean of loss / batch 11.006013870239258\n",
      "Epoch 343 | Batch: 1 | Loss: 10.6686\n",
      "Epoch 343 | Batch: 2 | Loss: 11.6640\n",
      "Epoch 343 | Batch: 3 | Loss: 10.7427\n",
      "Epoch 343 | Batch: 4 | Loss: 10.1288\n",
      "Epoch 343 | Batch: 5 | Loss: 11.8707\n",
      "Mean of loss / batch 11.014932632446289\n",
      "Epoch 344 | Batch: 1 | Loss: 11.2583\n",
      "Epoch 344 | Batch: 2 | Loss: 10.7331\n",
      "Epoch 344 | Batch: 3 | Loss: 10.9674\n",
      "Epoch 344 | Batch: 4 | Loss: 10.6872\n",
      "Epoch 344 | Batch: 5 | Loss: 10.9754\n",
      "Mean of loss / batch 10.924264907836914\n",
      "Epoch 345 | Batch: 1 | Loss: 10.3523\n",
      "Epoch 345 | Batch: 2 | Loss: 11.0072\n",
      "Epoch 345 | Batch: 3 | Loss: 10.6228\n",
      "Epoch 345 | Batch: 4 | Loss: 11.7993\n",
      "Epoch 345 | Batch: 5 | Loss: 10.9656\n",
      "Mean of loss / batch 10.94946002960205\n",
      "Epoch 346 | Batch: 1 | Loss: 10.9654\n",
      "Epoch 346 | Batch: 2 | Loss: 11.4897\n",
      "Epoch 346 | Batch: 3 | Loss: 10.6613\n",
      "Epoch 346 | Batch: 4 | Loss: 10.9664\n",
      "Epoch 346 | Batch: 5 | Loss: 10.6931\n",
      "Mean of loss / batch 10.95518684387207\n",
      "Epoch 347 | Batch: 1 | Loss: 11.6112\n",
      "Epoch 347 | Batch: 2 | Loss: 10.1474\n",
      "Epoch 347 | Batch: 3 | Loss: 10.6025\n",
      "Epoch 347 | Batch: 4 | Loss: 11.0293\n",
      "Epoch 347 | Batch: 5 | Loss: 11.8019\n",
      "Mean of loss / batch 11.03846549987793\n",
      "Epoch 348 | Batch: 1 | Loss: 10.4275\n",
      "Epoch 348 | Batch: 2 | Loss: 11.7217\n",
      "Epoch 348 | Batch: 3 | Loss: 10.7219\n",
      "Epoch 348 | Batch: 4 | Loss: 10.9688\n",
      "Epoch 348 | Batch: 5 | Loss: 10.9674\n",
      "Mean of loss / batch 10.961468696594238\n",
      "Epoch 349 | Batch: 1 | Loss: 10.9666\n",
      "Epoch 349 | Batch: 2 | Loss: 10.6921\n",
      "Epoch 349 | Batch: 3 | Loss: 11.9325\n",
      "Epoch 349 | Batch: 4 | Loss: 10.5146\n",
      "Epoch 349 | Batch: 5 | Loss: 10.9757\n",
      "Mean of loss / batch 11.016303062438965\n",
      "Epoch 350 | Batch: 1 | Loss: 10.9719\n",
      "Epoch 350 | Batch: 2 | Loss: 10.9695\n",
      "Epoch 350 | Batch: 3 | Loss: 11.2575\n",
      "Epoch 350 | Batch: 4 | Loss: 10.7337\n",
      "Epoch 350 | Batch: 5 | Loss: 10.6815\n",
      "Mean of loss / batch 10.922816276550293\n",
      "Epoch 351 | Batch: 1 | Loss: 9.6606\n",
      "Epoch 351 | Batch: 2 | Loss: 11.6127\n",
      "Epoch 351 | Batch: 3 | Loss: 11.0163\n",
      "Epoch 351 | Batch: 4 | Loss: 12.1437\n",
      "Epoch 351 | Batch: 5 | Loss: 10.7627\n",
      "Mean of loss / batch 11.039189338684082\n",
      "Epoch 352 | Batch: 1 | Loss: 11.7611\n",
      "Epoch 352 | Batch: 2 | Loss: 11.0032\n",
      "Epoch 352 | Batch: 3 | Loss: 10.9895\n",
      "Epoch 352 | Batch: 4 | Loss: 10.4946\n",
      "Epoch 352 | Batch: 5 | Loss: 10.6474\n",
      "Mean of loss / batch 10.979145050048828\n",
      "Epoch 353 | Batch: 1 | Loss: 10.6257\n",
      "Epoch 353 | Batch: 2 | Loss: 11.3962\n",
      "Epoch 353 | Batch: 3 | Loss: 10.6581\n",
      "Epoch 353 | Batch: 4 | Loss: 10.2803\n",
      "Epoch 353 | Batch: 5 | Loss: 11.8944\n",
      "Mean of loss / batch 10.970939636230469\n",
      "Epoch 354 | Batch: 1 | Loss: 11.5640\n",
      "Epoch 354 | Batch: 2 | Loss: 11.3496\n",
      "Epoch 354 | Batch: 3 | Loss: 10.8083\n",
      "Epoch 354 | Batch: 4 | Loss: 10.2739\n",
      "Epoch 354 | Batch: 5 | Loss: 10.9999\n",
      "Mean of loss / batch 10.999122619628906\n",
      "Epoch 355 | Batch: 1 | Loss: 10.9876\n",
      "Epoch 355 | Batch: 2 | Loss: 10.6419\n",
      "Epoch 355 | Batch: 3 | Loss: 12.1055\n",
      "Epoch 355 | Batch: 4 | Loss: 10.7732\n",
      "Epoch 355 | Batch: 5 | Loss: 10.4489\n",
      "Mean of loss / batch 10.991427421569824\n",
      "Epoch 356 | Batch: 1 | Loss: 10.6300\n",
      "Epoch 356 | Batch: 2 | Loss: 9.8421\n",
      "Epoch 356 | Batch: 3 | Loss: 11.6048\n",
      "Epoch 356 | Batch: 4 | Loss: 11.0143\n",
      "Epoch 356 | Batch: 5 | Loss: 11.7554\n",
      "Mean of loss / batch 10.969311714172363\n",
      "Epoch 357 | Batch: 1 | Loss: 10.7108\n",
      "Epoch 357 | Batch: 2 | Loss: 10.6667\n",
      "Epoch 357 | Batch: 3 | Loss: 10.2949\n",
      "Epoch 357 | Batch: 4 | Loss: 11.0242\n",
      "Epoch 357 | Batch: 5 | Loss: 12.1782\n",
      "Mean of loss / batch 10.974957466125488\n",
      "Epoch 358 | Batch: 1 | Loss: 10.7535\n",
      "Epoch 358 | Batch: 2 | Loss: 10.6943\n",
      "Epoch 358 | Batch: 3 | Loss: 11.9264\n",
      "Epoch 358 | Batch: 4 | Loss: 10.6743\n",
      "Epoch 358 | Batch: 5 | Loss: 10.9660\n",
      "Mean of loss / batch 11.002900123596191\n",
      "Epoch 359 | Batch: 1 | Loss: 11.5043\n",
      "Epoch 359 | Batch: 2 | Loss: 11.3110\n",
      "Epoch 359 | Batch: 3 | Loss: 10.8559\n",
      "Epoch 359 | Batch: 4 | Loss: 10.7513\n",
      "Epoch 359 | Batch: 5 | Loss: 10.4198\n",
      "Mean of loss / batch 10.968465805053711\n",
      "Epoch 360 | Batch: 1 | Loss: 10.2544\n",
      "Epoch 360 | Batch: 2 | Loss: 9.7012\n",
      "Epoch 360 | Batch: 3 | Loss: 11.7055\n",
      "Epoch 360 | Batch: 4 | Loss: 11.9401\n",
      "Epoch 360 | Batch: 5 | Loss: 11.2830\n",
      "Mean of loss / batch 10.97684383392334\n",
      "Epoch 361 | Batch: 1 | Loss: 10.7158\n",
      "Epoch 361 | Batch: 2 | Loss: 10.9696\n",
      "Epoch 361 | Batch: 3 | Loss: 11.2582\n",
      "Epoch 361 | Batch: 4 | Loss: 10.9657\n",
      "Epoch 361 | Batch: 5 | Loss: 10.7292\n",
      "Mean of loss / batch 10.927703857421875\n",
      "Epoch 362 | Batch: 1 | Loss: 10.6786\n",
      "Epoch 362 | Batch: 2 | Loss: 10.6460\n",
      "Epoch 362 | Batch: 3 | Loss: 11.7228\n",
      "Epoch 362 | Batch: 4 | Loss: 11.2088\n",
      "Epoch 362 | Batch: 5 | Loss: 10.5810\n",
      "Mean of loss / batch 10.967432975769043\n",
      "Epoch 363 | Batch: 1 | Loss: 10.3585\n",
      "Epoch 363 | Batch: 2 | Loss: 10.2147\n",
      "Epoch 363 | Batch: 3 | Loss: 12.4581\n",
      "Epoch 363 | Batch: 4 | Loss: 11.7929\n",
      "Epoch 363 | Batch: 5 | Loss: 10.6363\n",
      "Mean of loss / batch 11.0921049118042\n",
      "Epoch 364 | Batch: 1 | Loss: 10.6724\n",
      "Epoch 364 | Batch: 2 | Loss: 10.9797\n",
      "Epoch 364 | Batch: 3 | Loss: 10.6537\n",
      "Epoch 364 | Batch: 4 | Loss: 12.0587\n",
      "Epoch 364 | Batch: 5 | Loss: 10.6003\n",
      "Mean of loss / batch 10.992935180664062\n",
      "Epoch 365 | Batch: 1 | Loss: 11.5682\n",
      "Epoch 365 | Batch: 2 | Loss: 10.5927\n",
      "Epoch 365 | Batch: 3 | Loss: 11.2721\n",
      "Epoch 365 | Batch: 4 | Loss: 10.9652\n",
      "Epoch 365 | Batch: 5 | Loss: 10.4773\n",
      "Mean of loss / batch 10.975103378295898\n",
      "Epoch 366 | Batch: 1 | Loss: 11.6731\n",
      "Epoch 366 | Batch: 2 | Loss: 11.1932\n",
      "Epoch 366 | Batch: 3 | Loss: 11.1563\n",
      "Epoch 366 | Batch: 4 | Loss: 10.1141\n",
      "Epoch 366 | Batch: 5 | Loss: 11.5216\n",
      "Mean of loss / batch 11.131662368774414\n",
      "Epoch 367 | Batch: 1 | Loss: 10.9949\n",
      "Epoch 367 | Batch: 2 | Loss: 10.6337\n",
      "Epoch 367 | Batch: 3 | Loss: 10.9981\n",
      "Epoch 367 | Batch: 4 | Loss: 10.9865\n",
      "Epoch 367 | Batch: 5 | Loss: 10.9789\n",
      "Mean of loss / batch 10.91840934753418\n",
      "Epoch 368 | Batch: 1 | Loss: 10.9740\n",
      "Epoch 368 | Batch: 2 | Loss: 10.9708\n",
      "Epoch 368 | Batch: 3 | Loss: 11.2639\n",
      "Epoch 368 | Batch: 4 | Loss: 10.2560\n",
      "Epoch 368 | Batch: 5 | Loss: 11.3917\n",
      "Mean of loss / batch 10.971294403076172\n",
      "Epoch 369 | Batch: 1 | Loss: 10.6599\n",
      "Epoch 369 | Batch: 2 | Loss: 10.6338\n",
      "Epoch 369 | Batch: 3 | Loss: 11.7602\n",
      "Epoch 369 | Batch: 4 | Loss: 10.4535\n",
      "Epoch 369 | Batch: 5 | Loss: 11.3410\n",
      "Mean of loss / batch 10.9696683883667\n",
      "Epoch 370 | Batch: 1 | Loss: 11.2519\n",
      "Epoch 370 | Batch: 2 | Loss: 10.7380\n",
      "Epoch 370 | Batch: 3 | Loss: 10.6843\n",
      "Epoch 370 | Batch: 4 | Loss: 10.6496\n",
      "Epoch 370 | Batch: 5 | Loss: 11.3507\n",
      "Mean of loss / batch 10.934892654418945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371 | Batch: 1 | Loss: 9.8071\n",
      "Epoch 371 | Batch: 2 | Loss: 10.5865\n",
      "Epoch 371 | Batch: 3 | Loss: 11.5618\n",
      "Epoch 371 | Batch: 4 | Loss: 11.3961\n",
      "Epoch 371 | Batch: 5 | Loss: 11.6024\n",
      "Mean of loss / batch 10.99078369140625\n",
      "Epoch 372 | Batch: 1 | Loss: 10.5651\n",
      "Epoch 372 | Batch: 2 | Loss: 10.6603\n",
      "Epoch 372 | Batch: 3 | Loss: 10.6341\n",
      "Epoch 372 | Batch: 4 | Loss: 11.7594\n",
      "Epoch 372 | Batch: 5 | Loss: 11.2206\n",
      "Mean of loss / batch 10.967885971069336\n",
      "Epoch 373 | Batch: 1 | Loss: 11.1740\n",
      "Epoch 373 | Batch: 2 | Loss: 10.4884\n",
      "Epoch 373 | Batch: 3 | Loss: 10.6463\n",
      "Epoch 373 | Batch: 4 | Loss: 10.9906\n",
      "Epoch 373 | Batch: 5 | Loss: 11.6681\n",
      "Mean of loss / batch 10.993490219116211\n",
      "Epoch 374 | Batch: 1 | Loss: 10.2906\n",
      "Epoch 374 | Batch: 2 | Loss: 12.5192\n",
      "Epoch 374 | Batch: 3 | Loss: 10.9833\n",
      "Epoch 374 | Batch: 4 | Loss: 10.6283\n",
      "Epoch 374 | Batch: 5 | Loss: 10.9679\n",
      "Mean of loss / batch 11.077848434448242\n",
      "Epoch 375 | Batch: 1 | Loss: 11.8128\n",
      "Epoch 375 | Batch: 2 | Loss: 10.6182\n",
      "Epoch 375 | Batch: 3 | Loss: 10.3682\n",
      "Epoch 375 | Batch: 4 | Loss: 10.2211\n",
      "Epoch 375 | Batch: 5 | Loss: 12.4446\n",
      "Mean of loss / batch 11.092987060546875\n",
      "Epoch 376 | Batch: 1 | Loss: 11.7841\n",
      "Epoch 376 | Batch: 2 | Loss: 10.8814\n",
      "Epoch 376 | Batch: 3 | Loss: 10.1920\n",
      "Epoch 376 | Batch: 4 | Loss: 10.6058\n",
      "Epoch 376 | Batch: 5 | Loss: 11.8763\n",
      "Mean of loss / batch 11.067912101745605\n",
      "Epoch 377 | Batch: 1 | Loss: 11.8442\n",
      "Epoch 377 | Batch: 2 | Loss: 10.8583\n",
      "Epoch 377 | Batch: 3 | Loss: 10.5544\n",
      "Epoch 377 | Batch: 4 | Loss: 10.0254\n",
      "Epoch 377 | Batch: 5 | Loss: 11.9511\n",
      "Mean of loss / batch 11.046666145324707\n",
      "Epoch 378 | Batch: 1 | Loss: 10.3445\n",
      "Epoch 378 | Batch: 2 | Loss: 11.0093\n",
      "Epoch 378 | Batch: 3 | Loss: 11.3663\n",
      "Epoch 378 | Batch: 4 | Loss: 10.6706\n",
      "Epoch 378 | Batch: 5 | Loss: 11.3198\n",
      "Mean of loss / batch 10.942107200622559\n",
      "Epoch 379 | Batch: 1 | Loss: 11.2382\n",
      "Epoch 379 | Batch: 2 | Loss: 10.3127\n",
      "Epoch 379 | Batch: 3 | Loss: 10.9948\n",
      "Epoch 379 | Batch: 4 | Loss: 10.9844\n",
      "Epoch 379 | Batch: 5 | Loss: 11.3088\n",
      "Mean of loss / batch 10.967767715454102\n",
      "Epoch 380 | Batch: 1 | Loss: 10.6999\n",
      "Epoch 380 | Batch: 2 | Loss: 11.5980\n",
      "Epoch 380 | Batch: 3 | Loss: 11.1708\n",
      "Epoch 380 | Batch: 4 | Loss: 10.3384\n",
      "Epoch 380 | Batch: 5 | Loss: 11.3754\n",
      "Mean of loss / batch 11.03648567199707\n",
      "Epoch 381 | Batch: 1 | Loss: 10.3628\n",
      "Epoch 381 | Batch: 2 | Loss: 11.3981\n",
      "Epoch 381 | Batch: 3 | Loss: 10.9732\n",
      "Epoch 381 | Batch: 4 | Loss: 10.9703\n",
      "Epoch 381 | Batch: 5 | Loss: 10.9684\n",
      "Mean of loss / batch 10.934568405151367\n",
      "Epoch 382 | Batch: 1 | Loss: 10.6824\n",
      "Epoch 382 | Batch: 2 | Loss: 10.6484\n",
      "Epoch 382 | Batch: 3 | Loss: 10.9895\n",
      "Epoch 382 | Batch: 4 | Loss: 11.6636\n",
      "Epoch 382 | Batch: 5 | Loss: 10.7428\n",
      "Mean of loss / batch 10.94534683227539\n",
      "Epoch 383 | Batch: 1 | Loss: 10.6874\n",
      "Epoch 383 | Batch: 2 | Loss: 12.5937\n",
      "Epoch 383 | Batch: 3 | Loss: 10.9189\n",
      "Epoch 383 | Batch: 4 | Loss: 10.7731\n",
      "Epoch 383 | Batch: 5 | Loss: 10.4487\n",
      "Mean of loss / batch 11.084367752075195\n",
      "Epoch 384 | Batch: 1 | Loss: 11.3437\n",
      "Epoch 384 | Batch: 2 | Loss: 10.3950\n",
      "Epoch 384 | Batch: 3 | Loss: 11.7559\n",
      "Epoch 384 | Batch: 4 | Loss: 10.7106\n",
      "Epoch 384 | Batch: 5 | Loss: 10.6666\n",
      "Mean of loss / batch 10.974366188049316\n",
      "Epoch 385 | Batch: 1 | Loss: 10.2947\n",
      "Epoch 385 | Batch: 2 | Loss: 11.0242\n",
      "Epoch 385 | Batch: 3 | Loss: 11.3952\n",
      "Epoch 385 | Batch: 4 | Loss: 10.3442\n",
      "Epoch 385 | Batch: 5 | Loss: 11.8133\n",
      "Mean of loss / batch 10.974319458007812\n",
      "Epoch 386 | Batch: 1 | Loss: 10.9659\n",
      "Epoch 386 | Batch: 2 | Loss: 10.4287\n",
      "Epoch 386 | Batch: 3 | Loss: 11.7205\n",
      "Epoch 386 | Batch: 4 | Loss: 10.4795\n",
      "Epoch 386 | Batch: 5 | Loss: 11.3266\n",
      "Mean of loss / batch 10.98423957824707\n",
      "Epoch 387 | Batch: 1 | Loss: 11.5188\n",
      "Epoch 387 | Batch: 2 | Loss: 10.2921\n",
      "Epoch 387 | Batch: 3 | Loss: 11.3883\n",
      "Epoch 387 | Batch: 4 | Loss: 10.9720\n",
      "Epoch 387 | Batch: 5 | Loss: 10.9695\n",
      "Mean of loss / batch 11.028149604797363\n",
      "Epoch 388 | Batch: 1 | Loss: 10.9679\n",
      "Epoch 388 | Batch: 2 | Loss: 10.1204\n",
      "Epoch 388 | Batch: 3 | Loss: 11.4508\n",
      "Epoch 388 | Batch: 4 | Loss: 11.3233\n",
      "Epoch 388 | Batch: 5 | Loss: 10.9661\n",
      "Mean of loss / batch 10.965705871582031\n",
      "Epoch 389 | Batch: 1 | Loss: 10.9657\n",
      "Epoch 389 | Batch: 2 | Loss: 10.1669\n",
      "Epoch 389 | Batch: 3 | Loss: 10.6030\n",
      "Epoch 389 | Batch: 4 | Loss: 12.3239\n",
      "Epoch 389 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 11.004905700683594\n",
      "Epoch 390 | Batch: 1 | Loss: 10.7174\n",
      "Epoch 390 | Batch: 2 | Loss: 10.6710\n",
      "Epoch 390 | Batch: 3 | Loss: 10.6410\n",
      "Epoch 390 | Batch: 4 | Loss: 11.7374\n",
      "Epoch 390 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 10.946380615234375\n",
      "Epoch 391 | Batch: 1 | Loss: 11.2140\n",
      "Epoch 391 | Batch: 2 | Loss: 11.1698\n",
      "Epoch 391 | Batch: 3 | Loss: 10.9816\n",
      "Epoch 391 | Batch: 4 | Loss: 10.6201\n",
      "Epoch 391 | Batch: 5 | Loss: 10.6760\n",
      "Mean of loss / batch 10.932292938232422\n",
      "Epoch 392 | Batch: 1 | Loss: 10.6442\n",
      "Epoch 392 | Batch: 2 | Loss: 11.3598\n",
      "Epoch 392 | Batch: 3 | Loss: 10.9688\n",
      "Epoch 392 | Batch: 4 | Loss: 10.6808\n",
      "Epoch 392 | Batch: 5 | Loss: 10.9771\n",
      "Mean of loss / batch 10.926148414611816\n",
      "Epoch 393 | Batch: 1 | Loss: 11.6015\n",
      "Epoch 393 | Batch: 2 | Loss: 9.7579\n",
      "Epoch 393 | Batch: 3 | Loss: 11.0967\n",
      "Epoch 393 | Batch: 4 | Loss: 11.0511\n",
      "Epoch 393 | Batch: 5 | Loss: 12.2837\n",
      "Mean of loss / batch 11.15820026397705\n",
      "Epoch 394 | Batch: 1 | Loss: 11.2033\n",
      "Epoch 394 | Batch: 2 | Loss: 10.9723\n",
      "Epoch 394 | Batch: 3 | Loss: 11.1723\n",
      "Epoch 394 | Batch: 4 | Loss: 10.8185\n",
      "Epoch 394 | Batch: 5 | Loss: 10.5063\n",
      "Mean of loss / batch 10.934544563293457\n",
      "Epoch 395 | Batch: 1 | Loss: 10.6444\n",
      "Epoch 395 | Batch: 2 | Loss: 10.9916\n",
      "Epoch 395 | Batch: 3 | Loss: 11.3274\n",
      "Epoch 395 | Batch: 4 | Loss: 10.9663\n",
      "Epoch 395 | Batch: 5 | Loss: 10.6941\n",
      "Mean of loss / batch 10.92475700378418\n",
      "Epoch 396 | Batch: 1 | Loss: 10.6559\n",
      "Epoch 396 | Batch: 2 | Loss: 10.6313\n",
      "Epoch 396 | Batch: 3 | Loss: 11.7688\n",
      "Epoch 396 | Batch: 4 | Loss: 10.7066\n",
      "Epoch 396 | Batch: 5 | Loss: 10.9711\n",
      "Mean of loss / batch 10.946741104125977\n",
      "Epoch 397 | Batch: 1 | Loss: 10.0805\n",
      "Epoch 397 | Batch: 2 | Loss: 9.7205\n",
      "Epoch 397 | Batch: 3 | Loss: 10.5881\n",
      "Epoch 397 | Batch: 4 | Loss: 12.2182\n",
      "Epoch 397 | Batch: 5 | Loss: 12.5517\n",
      "Mean of loss / batch 11.031765937805176\n",
      "Epoch 398 | Batch: 1 | Loss: 10.8201\n",
      "Epoch 398 | Batch: 2 | Loss: 10.7371\n",
      "Epoch 398 | Batch: 3 | Loss: 10.6837\n",
      "Epoch 398 | Batch: 4 | Loss: 11.3033\n",
      "Epoch 398 | Batch: 5 | Loss: 11.2275\n",
      "Mean of loss / batch 10.954347610473633\n",
      "Epoch 399 | Batch: 1 | Loss: 10.9684\n",
      "Epoch 399 | Batch: 2 | Loss: 11.4036\n",
      "Epoch 399 | Batch: 3 | Loss: 10.9967\n",
      "Epoch 399 | Batch: 4 | Loss: 10.6858\n",
      "Epoch 399 | Batch: 5 | Loss: 10.6958\n",
      "Mean of loss / batch 10.950048446655273\n",
      "Epoch 400 | Batch: 1 | Loss: 11.2896\n",
      "Epoch 400 | Batch: 2 | Loss: 10.4580\n",
      "Epoch 400 | Batch: 3 | Loss: 10.9853\n",
      "Epoch 400 | Batch: 4 | Loss: 10.6450\n",
      "Epoch 400 | Batch: 5 | Loss: 11.3585\n",
      "Mean of loss / batch 10.947265625\n",
      "Epoch 401 | Batch: 1 | Loss: 10.6742\n",
      "Epoch 401 | Batch: 2 | Loss: 10.6431\n",
      "Epoch 401 | Batch: 3 | Loss: 10.6229\n",
      "Epoch 401 | Batch: 4 | Loss: 11.0062\n",
      "Epoch 401 | Batch: 5 | Loss: 11.7281\n",
      "Mean of loss / batch 10.934868812561035\n",
      "Epoch 402 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 402 | Batch: 2 | Loss: 10.4720\n",
      "Epoch 402 | Batch: 3 | Loss: 10.6357\n",
      "Epoch 402 | Batch: 4 | Loss: 12.1327\n",
      "Epoch 402 | Batch: 5 | Loss: 10.7657\n",
      "Mean of loss / batch 10.994244575500488\n",
      "Epoch 403 | Batch: 1 | Loss: 11.4917\n",
      "Epoch 403 | Batch: 2 | Loss: 11.1421\n",
      "Epoch 403 | Batch: 3 | Loss: 10.9947\n",
      "Epoch 403 | Batch: 4 | Loss: 10.2189\n",
      "Epoch 403 | Batch: 5 | Loss: 11.4447\n",
      "Mean of loss / batch 11.05842399597168\n",
      "Epoch 404 | Batch: 1 | Loss: 10.6410\n",
      "Epoch 404 | Batch: 2 | Loss: 11.3656\n",
      "Epoch 404 | Batch: 3 | Loss: 10.9694\n",
      "Epoch 404 | Batch: 4 | Loss: 10.6786\n",
      "Epoch 404 | Batch: 5 | Loss: 10.9777\n",
      "Mean of loss / batch 10.926458358764648\n",
      "Epoch 405 | Batch: 1 | Loss: 10.6572\n",
      "Epoch 405 | Batch: 2 | Loss: 11.3388\n",
      "Epoch 405 | Batch: 3 | Loss: 10.4003\n",
      "Epoch 405 | Batch: 4 | Loss: 11.3731\n",
      "Epoch 405 | Batch: 5 | Loss: 10.9702\n",
      "Mean of loss / batch 10.947903633117676\n",
      "Epoch 406 | Batch: 1 | Loss: 11.5534\n",
      "Epoch 406 | Batch: 2 | Loss: 11.3427\n",
      "Epoch 406 | Batch: 3 | Loss: 10.9141\n",
      "Epoch 406 | Batch: 4 | Loss: 10.9756\n",
      "Epoch 406 | Batch: 5 | Loss: 10.2015\n",
      "Mean of loss / batch 10.997450828552246\n",
      "Epoch 407 | Batch: 1 | Loss: 10.6065\n",
      "Epoch 407 | Batch: 2 | Loss: 10.1747\n",
      "Epoch 407 | Batch: 3 | Loss: 13.0398\n",
      "Epoch 407 | Batch: 4 | Loss: 11.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407 | Batch: 5 | Loss: 10.3834\n",
      "Mean of loss / batch 11.082806587219238\n",
      "Epoch 408 | Batch: 1 | Loss: 10.9868\n",
      "Epoch 408 | Batch: 2 | Loss: 11.6516\n",
      "Epoch 408 | Batch: 3 | Loss: 10.0886\n",
      "Epoch 408 | Batch: 4 | Loss: 10.5986\n",
      "Epoch 408 | Batch: 5 | Loss: 11.9198\n",
      "Mean of loss / batch 11.049099922180176\n",
      "Epoch 409 | Batch: 1 | Loss: 10.6657\n",
      "Epoch 409 | Batch: 2 | Loss: 10.9820\n",
      "Epoch 409 | Batch: 3 | Loss: 10.3236\n",
      "Epoch 409 | Batch: 4 | Loss: 11.8383\n",
      "Epoch 409 | Batch: 5 | Loss: 10.9667\n",
      "Mean of loss / batch 10.955263137817383\n",
      "Epoch 410 | Batch: 1 | Loss: 10.9661\n",
      "Epoch 410 | Batch: 2 | Loss: 11.5059\n",
      "Epoch 410 | Batch: 3 | Loss: 10.9793\n",
      "Epoch 410 | Batch: 4 | Loss: 10.6078\n",
      "Epoch 410 | Batch: 5 | Loss: 10.6724\n",
      "Mean of loss / batch 10.946297645568848\n",
      "Epoch 411 | Batch: 1 | Loss: 10.9797\n",
      "Epoch 411 | Batch: 2 | Loss: 10.9745\n",
      "Epoch 411 | Batch: 3 | Loss: 10.9712\n",
      "Epoch 411 | Batch: 4 | Loss: 10.6727\n",
      "Epoch 411 | Batch: 5 | Loss: 10.9796\n",
      "Mean of loss / batch 10.915533065795898\n",
      "Epoch 412 | Batch: 1 | Loss: 11.9362\n",
      "Epoch 412 | Batch: 2 | Loss: 10.1976\n",
      "Epoch 412 | Batch: 3 | Loss: 11.0244\n",
      "Epoch 412 | Batch: 4 | Loss: 11.3954\n",
      "Epoch 412 | Batch: 5 | Loss: 10.9728\n",
      "Mean of loss / batch 11.105278015136719\n",
      "Epoch 413 | Batch: 1 | Loss: 10.3660\n",
      "Epoch 413 | Batch: 2 | Loss: 10.2196\n",
      "Epoch 413 | Batch: 3 | Loss: 11.9830\n",
      "Epoch 413 | Batch: 4 | Loss: 10.6518\n",
      "Epoch 413 | Batch: 5 | Loss: 11.7064\n",
      "Mean of loss / batch 10.985361099243164\n",
      "Epoch 414 | Batch: 1 | Loss: 10.2509\n",
      "Epoch 414 | Batch: 2 | Loss: 11.3938\n",
      "Epoch 414 | Batch: 3 | Loss: 10.9726\n",
      "Epoch 414 | Batch: 4 | Loss: 11.2713\n",
      "Epoch 414 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 10.970773696899414\n",
      "Epoch 415 | Batch: 1 | Loss: 11.2086\n",
      "Epoch 415 | Batch: 2 | Loss: 11.7514\n",
      "Epoch 415 | Batch: 3 | Loss: 11.0659\n",
      "Epoch 415 | Batch: 4 | Loss: 10.9693\n",
      "Epoch 415 | Batch: 5 | Loss: 10.3255\n",
      "Mean of loss / batch 11.06413459777832\n",
      "Epoch 416 | Batch: 1 | Loss: 10.2504\n",
      "Epoch 416 | Batch: 2 | Loss: 10.1445\n",
      "Epoch 416 | Batch: 3 | Loss: 11.0949\n",
      "Epoch 416 | Batch: 4 | Loss: 10.1298\n",
      "Epoch 416 | Batch: 5 | Loss: 13.7029\n",
      "Mean of loss / batch 11.064493179321289\n",
      "Epoch 417 | Batch: 1 | Loss: 10.7492\n",
      "Epoch 417 | Batch: 2 | Loss: 11.2406\n",
      "Epoch 417 | Batch: 3 | Loss: 11.4069\n",
      "Epoch 417 | Batch: 4 | Loss: 10.8698\n",
      "Epoch 417 | Batch: 5 | Loss: 10.5681\n",
      "Mean of loss / batch 10.966951370239258\n",
      "Epoch 418 | Batch: 1 | Loss: 11.5938\n",
      "Epoch 418 | Batch: 2 | Loss: 10.5719\n",
      "Epoch 418 | Batch: 3 | Loss: 9.4241\n",
      "Epoch 418 | Batch: 4 | Loss: 11.6838\n",
      "Epoch 418 | Batch: 5 | Loss: 12.3587\n",
      "Mean of loss / batch 11.126484870910645\n",
      "Epoch 419 | Batch: 1 | Loss: 11.2194\n",
      "Epoch 419 | Batch: 2 | Loss: 10.9695\n",
      "Epoch 419 | Batch: 3 | Loss: 10.5417\n",
      "Epoch 419 | Batch: 4 | Loss: 10.9745\n",
      "Epoch 419 | Batch: 5 | Loss: 10.9711\n",
      "Mean of loss / batch 10.935223579406738\n",
      "Epoch 420 | Batch: 1 | Loss: 11.2651\n",
      "Epoch 420 | Batch: 2 | Loss: 11.2027\n",
      "Epoch 420 | Batch: 3 | Loss: 10.5922\n",
      "Epoch 420 | Batch: 4 | Loss: 11.2723\n",
      "Epoch 420 | Batch: 5 | Loss: 10.4808\n",
      "Mean of loss / batch 10.962636947631836\n",
      "Epoch 421 | Batch: 1 | Loss: 12.0139\n",
      "Epoch 421 | Batch: 2 | Loss: 10.8004\n",
      "Epoch 421 | Batch: 3 | Loss: 10.7245\n",
      "Epoch 421 | Batch: 4 | Loss: 10.0898\n",
      "Epoch 421 | Batch: 5 | Loss: 11.4654\n",
      "Mean of loss / batch 11.018781661987305\n",
      "Epoch 422 | Batch: 1 | Loss: 12.0311\n",
      "Epoch 422 | Batch: 2 | Loss: 11.5150\n",
      "Epoch 422 | Batch: 3 | Loss: 10.9179\n",
      "Epoch 422 | Batch: 4 | Loss: 10.7303\n",
      "Epoch 422 | Batch: 5 | Loss: 10.1024\n",
      "Mean of loss / batch 11.059345245361328\n",
      "Epoch 423 | Batch: 1 | Loss: 11.0281\n",
      "Epoch 423 | Batch: 2 | Loss: 11.4023\n",
      "Epoch 423 | Batch: 3 | Loss: 10.0198\n",
      "Epoch 423 | Batch: 4 | Loss: 13.3205\n",
      "Epoch 423 | Batch: 5 | Loss: 10.3176\n",
      "Mean of loss / batch 11.217666625976562\n",
      "Epoch 424 | Batch: 1 | Loss: 10.6162\n",
      "Epoch 424 | Batch: 2 | Loss: 11.8261\n",
      "Epoch 424 | Batch: 3 | Loss: 10.6897\n",
      "Epoch 424 | Batch: 4 | Loss: 10.9747\n",
      "Epoch 424 | Batch: 5 | Loss: 10.6634\n",
      "Mean of loss / batch 10.954032897949219\n",
      "Epoch 425 | Batch: 1 | Loss: 11.3297\n",
      "Epoch 425 | Batch: 2 | Loss: 10.9664\n",
      "Epoch 425 | Batch: 3 | Loss: 10.1474\n",
      "Epoch 425 | Batch: 4 | Loss: 11.0197\n",
      "Epoch 425 | Batch: 5 | Loss: 11.3866\n",
      "Mean of loss / batch 10.969970703125\n",
      "Epoch 426 | Batch: 1 | Loss: 11.2816\n",
      "Epoch 426 | Batch: 2 | Loss: 10.7167\n",
      "Epoch 426 | Batch: 3 | Loss: 10.9695\n",
      "Epoch 426 | Batch: 4 | Loss: 10.3887\n",
      "Epoch 426 | Batch: 5 | Loss: 11.3805\n",
      "Mean of loss / batch 10.947405815124512\n",
      "Epoch 427 | Batch: 1 | Loss: 10.3579\n",
      "Epoch 427 | Batch: 2 | Loss: 10.2143\n",
      "Epoch 427 | Batch: 3 | Loss: 11.0561\n",
      "Epoch 427 | Batch: 4 | Loss: 12.3017\n",
      "Epoch 427 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 10.979046821594238\n",
      "Epoch 428 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 428 | Batch: 2 | Loss: 10.2294\n",
      "Epoch 428 | Batch: 3 | Loss: 11.0062\n",
      "Epoch 428 | Batch: 4 | Loss: 11.3599\n",
      "Epoch 428 | Batch: 5 | Loss: 11.2642\n",
      "Mean of loss / batch 10.96497631072998\n",
      "Epoch 429 | Batch: 1 | Loss: 10.7287\n",
      "Epoch 429 | Batch: 2 | Loss: 10.3887\n",
      "Epoch 429 | Batch: 3 | Loss: 11.3805\n",
      "Epoch 429 | Batch: 4 | Loss: 10.9710\n",
      "Epoch 429 | Batch: 5 | Loss: 11.2646\n",
      "Mean of loss / batch 10.946737289428711\n",
      "Epoch 430 | Batch: 1 | Loss: 10.7284\n",
      "Epoch 430 | Batch: 2 | Loss: 10.6781\n",
      "Epoch 430 | Batch: 3 | Loss: 11.3102\n",
      "Epoch 430 | Batch: 4 | Loss: 10.9655\n",
      "Epoch 430 | Batch: 5 | Loss: 10.9653\n",
      "Mean of loss / batch 10.929494857788086\n",
      "Epoch 431 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 431 | Batch: 2 | Loss: 10.4469\n",
      "Epoch 431 | Batch: 3 | Loss: 10.2720\n",
      "Epoch 431 | Batch: 4 | Loss: 11.9058\n",
      "Epoch 431 | Batch: 5 | Loss: 11.2707\n",
      "Mean of loss / batch 10.972108840942383\n",
      "Epoch 432 | Batch: 1 | Loss: 11.6886\n",
      "Epoch 432 | Batch: 2 | Loss: 10.6421\n",
      "Epoch 432 | Batch: 3 | Loss: 11.6246\n",
      "Epoch 432 | Batch: 4 | Loss: 10.5480\n",
      "Epoch 432 | Batch: 5 | Loss: 10.9738\n",
      "Mean of loss / batch 11.095412254333496\n",
      "Epoch 433 | Batch: 1 | Loss: 10.6656\n",
      "Epoch 433 | Batch: 2 | Loss: 9.6037\n",
      "Epoch 433 | Batch: 3 | Loss: 12.1645\n",
      "Epoch 433 | Batch: 4 | Loss: 11.3677\n",
      "Epoch 433 | Batch: 5 | Loss: 11.2692\n",
      "Mean of loss / batch 11.014134407043457\n",
      "Epoch 434 | Batch: 1 | Loss: 10.4850\n",
      "Epoch 434 | Batch: 2 | Loss: 11.6660\n",
      "Epoch 434 | Batch: 3 | Loss: 11.1910\n",
      "Epoch 434 | Batch: 4 | Loss: 10.7953\n",
      "Epoch 434 | Batch: 5 | Loss: 10.7212\n",
      "Mean of loss / batch 10.971684455871582\n",
      "Epoch 435 | Batch: 1 | Loss: 10.6734\n",
      "Epoch 435 | Batch: 2 | Loss: 10.6426\n",
      "Epoch 435 | Batch: 3 | Loss: 12.1027\n",
      "Epoch 435 | Batch: 4 | Loss: 11.3646\n",
      "Epoch 435 | Batch: 5 | Loss: 10.5755\n",
      "Mean of loss / batch 11.071756362915039\n",
      "Epoch 436 | Batch: 1 | Loss: 9.9708\n",
      "Epoch 436 | Batch: 2 | Loss: 11.5272\n",
      "Epoch 436 | Batch: 3 | Loss: 10.2415\n",
      "Epoch 436 | Batch: 4 | Loss: 10.1386\n",
      "Epoch 436 | Batch: 5 | Loss: 13.6672\n",
      "Mean of loss / batch 11.109075546264648\n",
      "Epoch 437 | Batch: 1 | Loss: 11.1811\n",
      "Epoch 437 | Batch: 2 | Loss: 12.0020\n",
      "Epoch 437 | Batch: 3 | Loss: 11.6829\n",
      "Epoch 437 | Batch: 4 | Loss: 10.6632\n",
      "Epoch 437 | Batch: 5 | Loss: 10.4114\n",
      "Mean of loss / batch 11.188102722167969\n",
      "Epoch 438 | Batch: 1 | Loss: 10.6214\n",
      "Epoch 438 | Batch: 2 | Loss: 10.6088\n",
      "Epoch 438 | Batch: 3 | Loss: 11.8606\n",
      "Epoch 438 | Batch: 4 | Loss: 11.2548\n",
      "Epoch 438 | Batch: 5 | Loss: 10.5056\n",
      "Mean of loss / batch 10.970227241516113\n",
      "Epoch 439 | Batch: 1 | Loss: 11.3129\n",
      "Epoch 439 | Batch: 2 | Loss: 10.4294\n",
      "Epoch 439 | Batch: 3 | Loss: 10.9902\n",
      "Epoch 439 | Batch: 4 | Loss: 10.9814\n",
      "Epoch 439 | Batch: 5 | Loss: 10.9756\n",
      "Mean of loss / batch 10.937906265258789\n",
      "Epoch 440 | Batch: 1 | Loss: 10.6615\n",
      "Epoch 440 | Batch: 2 | Loss: 9.9373\n",
      "Epoch 440 | Batch: 3 | Loss: 11.5463\n",
      "Epoch 440 | Batch: 4 | Loss: 11.0003\n",
      "Epoch 440 | Batch: 5 | Loss: 11.7067\n",
      "Mean of loss / batch 10.970418930053711\n",
      "Epoch 441 | Batch: 1 | Loss: 10.9654\n",
      "Epoch 441 | Batch: 2 | Loss: 10.4835\n",
      "Epoch 441 | Batch: 3 | Loss: 10.9815\n",
      "Epoch 441 | Batch: 4 | Loss: 11.9507\n",
      "Epoch 441 | Batch: 5 | Loss: 10.6602\n",
      "Mean of loss / batch 11.008241653442383\n",
      "Epoch 442 | Batch: 1 | Loss: 10.9665\n",
      "Epoch 442 | Batch: 2 | Loss: 10.4196\n",
      "Epoch 442 | Batch: 3 | Loss: 12.0987\n",
      "Epoch 442 | Batch: 4 | Loss: 10.9711\n",
      "Epoch 442 | Batch: 5 | Loss: 10.5552\n",
      "Mean of loss / batch 11.002218246459961\n",
      "Epoch 443 | Batch: 1 | Loss: 10.9732\n",
      "Epoch 443 | Batch: 2 | Loss: 10.0612\n",
      "Epoch 443 | Batch: 3 | Loss: 10.5937\n",
      "Epoch 443 | Batch: 4 | Loss: 11.5022\n",
      "Epoch 443 | Batch: 5 | Loss: 11.7231\n",
      "Mean of loss / batch 10.970666885375977\n",
      "Epoch 444 | Batch: 1 | Loss: 10.7214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444 | Batch: 2 | Loss: 10.3784\n",
      "Epoch 444 | Batch: 3 | Loss: 10.6142\n",
      "Epoch 444 | Batch: 4 | Loss: 11.4246\n",
      "Epoch 444 | Batch: 5 | Loss: 11.6356\n",
      "Mean of loss / batch 10.954845428466797\n",
      "Epoch 445 | Batch: 1 | Loss: 10.3257\n",
      "Epoch 445 | Batch: 2 | Loss: 10.9933\n",
      "Epoch 445 | Batch: 3 | Loss: 10.9833\n",
      "Epoch 445 | Batch: 4 | Loss: 11.6350\n",
      "Epoch 445 | Batch: 5 | Loss: 10.9678\n",
      "Mean of loss / batch 10.981010437011719\n",
      "Epoch 446 | Batch: 1 | Loss: 10.9668\n",
      "Epoch 446 | Batch: 2 | Loss: 11.1933\n",
      "Epoch 446 | Batch: 3 | Loss: 10.9745\n",
      "Epoch 446 | Batch: 4 | Loss: 10.3842\n",
      "Epoch 446 | Batch: 5 | Loss: 11.3434\n",
      "Mean of loss / batch 10.972461700439453\n",
      "Epoch 447 | Batch: 1 | Loss: 10.3953\n",
      "Epoch 447 | Batch: 2 | Loss: 11.3763\n",
      "Epoch 447 | Batch: 3 | Loss: 10.3620\n",
      "Epoch 447 | Batch: 4 | Loss: 11.7926\n",
      "Epoch 447 | Batch: 5 | Loss: 10.9655\n",
      "Mean of loss / batch 10.978311538696289\n",
      "Epoch 448 | Batch: 1 | Loss: 10.9653\n",
      "Epoch 448 | Batch: 2 | Loss: 10.7043\n",
      "Epoch 448 | Batch: 3 | Loss: 10.9716\n",
      "Epoch 448 | Batch: 4 | Loss: 10.6716\n",
      "Epoch 448 | Batch: 5 | Loss: 11.3185\n",
      "Mean of loss / batch 10.926262855529785\n",
      "Epoch 449 | Batch: 1 | Loss: 11.5088\n",
      "Epoch 449 | Batch: 2 | Loss: 10.9789\n",
      "Epoch 449 | Batch: 3 | Loss: 10.6057\n",
      "Epoch 449 | Batch: 4 | Loss: 10.6718\n",
      "Epoch 449 | Batch: 5 | Loss: 10.9799\n",
      "Mean of loss / batch 10.949030876159668\n",
      "Epoch 450 | Batch: 1 | Loss: 10.9746\n",
      "Epoch 450 | Batch: 2 | Loss: 10.9712\n",
      "Epoch 450 | Batch: 3 | Loss: 10.9690\n",
      "Epoch 450 | Batch: 4 | Loss: 11.2553\n",
      "Epoch 450 | Batch: 5 | Loss: 10.5048\n",
      "Mean of loss / batch 10.93501091003418\n",
      "Epoch 451 | Batch: 1 | Loss: 11.3133\n",
      "Epoch 451 | Batch: 2 | Loss: 10.9656\n",
      "Epoch 451 | Batch: 3 | Loss: 10.7004\n",
      "Epoch 451 | Batch: 4 | Loss: 10.6600\n",
      "Epoch 451 | Batch: 5 | Loss: 10.9842\n",
      "Mean of loss / batch 10.924715042114258\n",
      "Epoch 452 | Batch: 1 | Loss: 11.6394\n",
      "Epoch 452 | Batch: 2 | Loss: 10.3214\n",
      "Epoch 452 | Batch: 3 | Loss: 10.2488\n",
      "Epoch 452 | Batch: 4 | Loss: 11.9387\n",
      "Epoch 452 | Batch: 5 | Loss: 10.9719\n",
      "Mean of loss / batch 11.024066925048828\n",
      "Epoch 453 | Batch: 1 | Loss: 10.6706\n",
      "Epoch 453 | Batch: 2 | Loss: 10.6407\n",
      "Epoch 453 | Batch: 3 | Loss: 11.3660\n",
      "Epoch 453 | Batch: 4 | Loss: 10.6707\n",
      "Epoch 453 | Batch: 5 | Loss: 11.3196\n",
      "Mean of loss / batch 10.933530807495117\n",
      "Epoch 454 | Batch: 1 | Loss: 11.2380\n",
      "Epoch 454 | Batch: 2 | Loss: 10.5311\n",
      "Epoch 454 | Batch: 3 | Loss: 10.9756\n",
      "Epoch 454 | Batch: 4 | Loss: 11.2821\n",
      "Epoch 454 | Batch: 5 | Loss: 10.7163\n",
      "Mean of loss / batch 10.948629379272461\n",
      "Epoch 455 | Batch: 1 | Loss: 9.4734\n",
      "Epoch 455 | Batch: 2 | Loss: 12.7458\n",
      "Epoch 455 | Batch: 3 | Loss: 10.6442\n",
      "Epoch 455 | Batch: 4 | Loss: 10.6236\n",
      "Epoch 455 | Batch: 5 | Loss: 12.1916\n",
      "Mean of loss / batch 11.135729789733887\n",
      "Epoch 456 | Batch: 1 | Loss: 10.9673\n",
      "Epoch 456 | Batch: 2 | Loss: 10.9665\n",
      "Epoch 456 | Batch: 3 | Loss: 10.7366\n",
      "Epoch 456 | Batch: 4 | Loss: 11.2508\n",
      "Epoch 456 | Batch: 5 | Loss: 10.7388\n",
      "Mean of loss / batch 10.932003021240234\n",
      "Epoch 457 | Batch: 1 | Loss: 11.8131\n",
      "Epoch 457 | Batch: 2 | Loss: 10.7440\n",
      "Epoch 457 | Batch: 3 | Loss: 10.9650\n",
      "Epoch 457 | Batch: 4 | Loss: 10.2122\n",
      "Epoch 457 | Batch: 5 | Loss: 11.4099\n",
      "Mean of loss / batch 11.028837203979492\n",
      "Epoch 458 | Batch: 1 | Loss: 11.6185\n",
      "Epoch 458 | Batch: 2 | Loss: 10.7607\n",
      "Epoch 458 | Batch: 3 | Loss: 10.6989\n",
      "Epoch 458 | Batch: 4 | Loss: 10.3455\n",
      "Epoch 458 | Batch: 5 | Loss: 11.4104\n",
      "Mean of loss / batch 10.966801643371582\n",
      "Epoch 459 | Batch: 1 | Loss: 10.9749\n",
      "Epoch 459 | Batch: 2 | Loss: 10.3548\n",
      "Epoch 459 | Batch: 3 | Loss: 10.2124\n",
      "Epoch 459 | Batch: 4 | Loss: 11.9945\n",
      "Epoch 459 | Batch: 5 | Loss: 11.3028\n",
      "Mean of loss / batch 10.967878341674805\n",
      "Epoch 460 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 460 | Batch: 2 | Loss: 10.9652\n",
      "Epoch 460 | Batch: 3 | Loss: 11.2233\n",
      "Epoch 460 | Batch: 4 | Loss: 10.5553\n",
      "Epoch 460 | Batch: 5 | Loss: 10.9731\n",
      "Mean of loss / batch 10.936429977416992\n",
      "Epoch 461 | Batch: 1 | Loss: 10.6673\n",
      "Epoch 461 | Batch: 2 | Loss: 11.3243\n",
      "Epoch 461 | Batch: 3 | Loss: 11.2411\n",
      "Epoch 461 | Batch: 4 | Loss: 10.9669\n",
      "Epoch 461 | Batch: 5 | Loss: 10.5134\n",
      "Mean of loss / batch 10.942598342895508\n",
      "Epoch 462 | Batch: 1 | Loss: 10.9776\n",
      "Epoch 462 | Batch: 2 | Loss: 10.6575\n",
      "Epoch 462 | Batch: 3 | Loss: 11.3384\n",
      "Epoch 462 | Batch: 4 | Loss: 11.2502\n",
      "Epoch 462 | Batch: 5 | Loss: 10.5124\n",
      "Mean of loss / batch 10.9472017288208\n",
      "Epoch 463 | Batch: 1 | Loss: 11.3094\n",
      "Epoch 463 | Batch: 2 | Loss: 10.9655\n",
      "Epoch 463 | Batch: 3 | Loss: 10.9653\n",
      "Epoch 463 | Batch: 4 | Loss: 10.7044\n",
      "Epoch 463 | Batch: 5 | Loss: 10.6626\n",
      "Mean of loss / batch 10.921445846557617\n",
      "Epoch 464 | Batch: 1 | Loss: 11.3308\n",
      "Epoch 464 | Batch: 2 | Loss: 10.4089\n",
      "Epoch 464 | Batch: 3 | Loss: 10.9942\n",
      "Epoch 464 | Batch: 4 | Loss: 11.3335\n",
      "Epoch 464 | Batch: 5 | Loss: 10.6863\n",
      "Mean of loss / batch 10.950760841369629\n",
      "Epoch 465 | Batch: 1 | Loss: 9.6770\n",
      "Epoch 465 | Batch: 2 | Loss: 11.6056\n",
      "Epoch 465 | Batch: 3 | Loss: 11.0145\n",
      "Epoch 465 | Batch: 4 | Loss: 11.7560\n",
      "Epoch 465 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 11.003622055053711\n",
      "Epoch 466 | Batch: 1 | Loss: 10.4574\n",
      "Epoch 466 | Batch: 2 | Loss: 10.2787\n",
      "Epoch 466 | Batch: 3 | Loss: 12.7633\n",
      "Epoch 466 | Batch: 4 | Loss: 10.5745\n",
      "Epoch 466 | Batch: 5 | Loss: 11.2800\n",
      "Mean of loss / batch 11.07079792022705\n",
      "Epoch 467 | Batch: 1 | Loss: 11.4597\n",
      "Epoch 467 | Batch: 2 | Loss: 10.6898\n",
      "Epoch 467 | Batch: 3 | Loss: 11.2342\n",
      "Epoch 467 | Batch: 4 | Loss: 10.3221\n",
      "Epoch 467 | Batch: 5 | Loss: 11.3660\n",
      "Mean of loss / batch 11.014364242553711\n",
      "Epoch 468 | Batch: 1 | Loss: 10.6708\n",
      "Epoch 468 | Batch: 2 | Loss: 10.6409\n",
      "Epoch 468 | Batch: 3 | Loss: 11.3658\n",
      "Epoch 468 | Batch: 4 | Loss: 11.2680\n",
      "Epoch 468 | Batch: 5 | Loss: 10.7260\n",
      "Mean of loss / batch 10.934274673461914\n",
      "Epoch 469 | Batch: 1 | Loss: 11.5516\n",
      "Epoch 469 | Batch: 2 | Loss: 10.4228\n",
      "Epoch 469 | Batch: 3 | Loss: 10.2888\n",
      "Epoch 469 | Batch: 4 | Loss: 11.0262\n",
      "Epoch 469 | Batch: 5 | Loss: 11.7928\n",
      "Mean of loss / batch 11.016437530517578\n",
      "Epoch 470 | Batch: 1 | Loss: 10.6993\n",
      "Epoch 470 | Batch: 2 | Loss: 11.5991\n",
      "Epoch 470 | Batch: 3 | Loss: 11.1711\n",
      "Epoch 470 | Batch: 4 | Loss: 10.3370\n",
      "Epoch 470 | Batch: 5 | Loss: 11.3758\n",
      "Mean of loss / batch 11.036452293395996\n",
      "Epoch 471 | Batch: 1 | Loss: 11.2745\n",
      "Epoch 471 | Batch: 2 | Loss: 10.4778\n",
      "Epoch 471 | Batch: 3 | Loss: 10.9823\n",
      "Epoch 471 | Batch: 4 | Loss: 11.3030\n",
      "Epoch 471 | Batch: 5 | Loss: 10.7032\n",
      "Mean of loss / batch 10.948169708251953\n",
      "Epoch 472 | Batch: 1 | Loss: 10.6619\n",
      "Epoch 472 | Batch: 2 | Loss: 10.2867\n",
      "Epoch 472 | Batch: 3 | Loss: 10.1681\n",
      "Epoch 472 | Batch: 4 | Loss: 11.0803\n",
      "Epoch 472 | Batch: 5 | Loss: 12.8317\n",
      "Mean of loss / batch 11.005731582641602\n",
      "Epoch 473 | Batch: 1 | Loss: 11.1782\n",
      "Epoch 473 | Batch: 2 | Loss: 11.1467\n",
      "Epoch 473 | Batch: 3 | Loss: 10.7232\n",
      "Epoch 473 | Batch: 4 | Loss: 11.2227\n",
      "Epoch 473 | Batch: 5 | Loss: 10.5563\n",
      "Mean of loss / batch 10.965409278869629\n",
      "Epoch 474 | Batch: 1 | Loss: 10.6578\n",
      "Epoch 474 | Batch: 2 | Loss: 9.9271\n",
      "Epoch 474 | Batch: 3 | Loss: 12.5180\n",
      "Epoch 474 | Batch: 4 | Loss: 10.3914\n",
      "Epoch 474 | Batch: 5 | Loss: 11.7597\n",
      "Mean of loss / batch 11.050803184509277\n",
      "Epoch 475 | Batch: 1 | Loss: 10.7094\n",
      "Epoch 475 | Batch: 2 | Loss: 10.6659\n",
      "Epoch 475 | Batch: 3 | Loss: 10.6377\n",
      "Epoch 475 | Batch: 4 | Loss: 11.3716\n",
      "Epoch 475 | Batch: 5 | Loss: 11.2718\n",
      "Mean of loss / batch 10.9312744140625\n",
      "Epoch 476 | Batch: 1 | Loss: 11.2071\n",
      "Epoch 476 | Batch: 2 | Loss: 10.9716\n",
      "Epoch 476 | Batch: 3 | Loss: 10.5590\n",
      "Epoch 476 | Batch: 4 | Loss: 10.9728\n",
      "Epoch 476 | Batch: 5 | Loss: 10.9701\n",
      "Mean of loss / batch 10.936105728149414\n",
      "Epoch 477 | Batch: 1 | Loss: 11.2602\n",
      "Epoch 477 | Batch: 2 | Loss: 10.2637\n",
      "Epoch 477 | Batch: 3 | Loss: 10.2265\n",
      "Epoch 477 | Batch: 4 | Loss: 13.3550\n",
      "Epoch 477 | Batch: 5 | Loss: 10.6374\n",
      "Mean of loss / batch 11.148542404174805\n",
      "Epoch 478 | Batch: 1 | Loss: 11.8264\n",
      "Epoch 478 | Batch: 2 | Loss: 10.6061\n",
      "Epoch 478 | Batch: 3 | Loss: 10.3632\n",
      "Epoch 478 | Batch: 4 | Loss: 11.3978\n",
      "Epoch 478 | Batch: 5 | Loss: 10.9732\n",
      "Mean of loss / batch 11.03332805633545\n",
      "Epoch 479 | Batch: 1 | Loss: 10.9703\n",
      "Epoch 479 | Batch: 2 | Loss: 11.5542\n",
      "Epoch 479 | Batch: 3 | Loss: 11.1585\n",
      "Epoch 479 | Batch: 4 | Loss: 10.8383\n",
      "Epoch 479 | Batch: 5 | Loss: 10.3121\n",
      "Mean of loss / batch 10.966672897338867\n",
      "Epoch 480 | Batch: 1 | Loss: 10.9949\n",
      "Epoch 480 | Batch: 2 | Loss: 11.3352\n",
      "Epoch 480 | Batch: 3 | Loss: 11.8108\n",
      "Epoch 480 | Batch: 4 | Loss: 10.7455\n",
      "Epoch 480 | Batch: 5 | Loss: 10.2139\n",
      "Mean of loss / batch 11.020054817199707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481 | Batch: 1 | Loss: 9.8069\n",
      "Epoch 481 | Batch: 2 | Loss: 11.1067\n",
      "Epoch 481 | Batch: 3 | Loss: 11.0577\n",
      "Epoch 481 | Batch: 4 | Loss: 12.3073\n",
      "Epoch 481 | Batch: 5 | Loss: 10.7220\n",
      "Mean of loss / batch 11.000146865844727\n",
      "Epoch 482 | Batch: 1 | Loss: 11.2635\n",
      "Epoch 482 | Batch: 2 | Loss: 11.2017\n",
      "Epoch 482 | Batch: 3 | Loss: 10.9726\n",
      "Epoch 482 | Batch: 4 | Loss: 10.7685\n",
      "Epoch 482 | Batch: 5 | Loss: 10.4426\n",
      "Mean of loss / batch 10.929774284362793\n",
      "Epoch 483 | Batch: 1 | Loss: 10.6286\n",
      "Epoch 483 | Batch: 2 | Loss: 11.3899\n",
      "Epoch 483 | Batch: 3 | Loss: 11.9068\n",
      "Epoch 483 | Batch: 4 | Loss: 10.5362\n",
      "Epoch 483 | Batch: 5 | Loss: 10.6544\n",
      "Mean of loss / batch 11.023176193237305\n",
      "Epoch 484 | Batch: 1 | Loss: 10.9867\n",
      "Epoch 484 | Batch: 2 | Loss: 11.3149\n",
      "Epoch 484 | Batch: 3 | Loss: 10.4270\n",
      "Epoch 484 | Batch: 4 | Loss: 11.3565\n",
      "Epoch 484 | Batch: 5 | Loss: 10.6751\n",
      "Mean of loss / batch 10.952033042907715\n",
      "Epoch 485 | Batch: 1 | Loss: 11.3140\n",
      "Epoch 485 | Batch: 2 | Loss: 11.7719\n",
      "Epoch 485 | Batch: 3 | Loss: 10.6556\n",
      "Epoch 485 | Batch: 4 | Loss: 10.0915\n",
      "Epoch 485 | Batch: 5 | Loss: 11.4646\n",
      "Mean of loss / batch 11.059508323669434\n",
      "Epoch 486 | Batch: 1 | Loss: 10.6349\n",
      "Epoch 486 | Batch: 2 | Loss: 10.9973\n",
      "Epoch 486 | Batch: 3 | Loss: 10.2767\n",
      "Epoch 486 | Batch: 4 | Loss: 11.0305\n",
      "Epoch 486 | Batch: 5 | Loss: 11.8054\n",
      "Mean of loss / batch 10.948943138122559\n",
      "Epoch 487 | Batch: 1 | Loss: 10.9657\n",
      "Epoch 487 | Batch: 2 | Loss: 10.9655\n",
      "Epoch 487 | Batch: 3 | Loss: 10.7018\n",
      "Epoch 487 | Batch: 4 | Loss: 11.5942\n",
      "Epoch 487 | Batch: 5 | Loss: 10.5716\n",
      "Mean of loss / batch 10.959775924682617\n",
      "Epoch 488 | Batch: 1 | Loss: 11.5910\n",
      "Epoch 488 | Batch: 2 | Loss: 10.3760\n",
      "Epoch 488 | Batch: 3 | Loss: 11.3463\n",
      "Epoch 488 | Batch: 4 | Loss: 10.6799\n",
      "Epoch 488 | Batch: 5 | Loss: 10.9773\n",
      "Mean of loss / batch 10.994108200073242\n",
      "Epoch 489 | Batch: 1 | Loss: 10.9730\n",
      "Epoch 489 | Batch: 2 | Loss: 10.3651\n",
      "Epoch 489 | Batch: 3 | Loss: 10.6115\n",
      "Epoch 489 | Batch: 4 | Loss: 11.8473\n",
      "Epoch 489 | Batch: 5 | Loss: 10.9670\n",
      "Mean of loss / batch 10.952789306640625\n",
      "Epoch 490 | Batch: 1 | Loss: 11.7970\n",
      "Epoch 490 | Batch: 2 | Loss: 10.7544\n",
      "Epoch 490 | Batch: 3 | Loss: 9.9749\n",
      "Epoch 490 | Batch: 4 | Loss: 11.4889\n",
      "Epoch 490 | Batch: 5 | Loss: 11.3483\n",
      "Mean of loss / batch 11.072721481323242\n",
      "Epoch 491 | Batch: 1 | Loss: 10.9678\n",
      "Epoch 491 | Batch: 2 | Loss: 11.5298\n",
      "Epoch 491 | Batch: 3 | Loss: 10.9764\n",
      "Epoch 491 | Batch: 4 | Loss: 10.7818\n",
      "Epoch 491 | Batch: 5 | Loss: 10.4600\n",
      "Mean of loss / batch 10.943133354187012\n",
      "Epoch 492 | Batch: 1 | Loss: 11.3373\n",
      "Epoch 492 | Batch: 2 | Loss: 12.0972\n",
      "Epoch 492 | Batch: 3 | Loss: 10.8728\n",
      "Epoch 492 | Batch: 4 | Loss: 10.3348\n",
      "Epoch 492 | Batch: 5 | Loss: 10.6231\n",
      "Mean of loss / batch 11.053028106689453\n",
      "Epoch 493 | Batch: 1 | Loss: 10.6099\n",
      "Epoch 493 | Batch: 2 | Loss: 11.0192\n",
      "Epoch 493 | Batch: 3 | Loss: 10.2292\n",
      "Epoch 493 | Batch: 4 | Loss: 10.5900\n",
      "Epoch 493 | Batch: 5 | Loss: 12.4645\n",
      "Mean of loss / batch 10.982582092285156\n",
      "Epoch 494 | Batch: 1 | Loss: 10.4125\n",
      "Epoch 494 | Batch: 2 | Loss: 11.3654\n",
      "Epoch 494 | Batch: 3 | Loss: 10.6710\n",
      "Epoch 494 | Batch: 4 | Loss: 11.6584\n",
      "Epoch 494 | Batch: 5 | Loss: 10.7448\n",
      "Mean of loss / batch 10.970410346984863\n",
      "Epoch 495 | Batch: 1 | Loss: 11.2441\n",
      "Epoch 495 | Batch: 2 | Loss: 10.5216\n",
      "Epoch 495 | Batch: 3 | Loss: 10.3202\n",
      "Epoch 495 | Batch: 4 | Loss: 12.2557\n",
      "Epoch 495 | Batch: 5 | Loss: 10.7341\n",
      "Mean of loss / batch 11.01513671875\n",
      "Epoch 496 | Batch: 1 | Loss: 10.6818\n",
      "Epoch 496 | Batch: 2 | Loss: 10.9768\n",
      "Epoch 496 | Batch: 3 | Loss: 11.2863\n",
      "Epoch 496 | Batch: 4 | Loss: 10.7136\n",
      "Epoch 496 | Batch: 5 | Loss: 10.9700\n",
      "Mean of loss / batch 10.925691604614258\n",
      "Epoch 497 | Batch: 1 | Loss: 9.8019\n",
      "Epoch 497 | Batch: 2 | Loss: 12.5211\n",
      "Epoch 497 | Batch: 3 | Loss: 10.6790\n",
      "Epoch 497 | Batch: 4 | Loss: 11.3090\n",
      "Epoch 497 | Batch: 5 | Loss: 10.9654\n",
      "Mean of loss / batch 11.055293083190918\n",
      "Epoch 498 | Batch: 1 | Loss: 11.4911\n",
      "Epoch 498 | Batch: 2 | Loss: 11.1419\n",
      "Epoch 498 | Batch: 3 | Loss: 10.6091\n",
      "Epoch 498 | Batch: 4 | Loss: 11.2731\n",
      "Epoch 498 | Batch: 5 | Loss: 10.4796\n",
      "Mean of loss / batch 10.998977661132812\n",
      "Epoch 499 | Batch: 1 | Loss: 9.9487\n",
      "Epoch 499 | Batch: 2 | Loss: 12.0160\n",
      "Epoch 499 | Batch: 3 | Loss: 10.6453\n",
      "Epoch 499 | Batch: 4 | Loss: 11.7248\n",
      "Epoch 499 | Batch: 5 | Loss: 10.7209\n",
      "Mean of loss / batch 11.011112213134766\n",
      "Epoch 500 | Batch: 1 | Loss: 10.9689\n",
      "Epoch 500 | Batch: 2 | Loss: 11.8284\n",
      "Epoch 500 | Batch: 3 | Loss: 10.6043\n",
      "Epoch 500 | Batch: 4 | Loss: 10.6665\n",
      "Epoch 500 | Batch: 5 | Loss: 10.9817\n",
      "Mean of loss / batch 11.009960174560547\n",
      "Epoch 501 | Batch: 1 | Loss: 9.9991\n",
      "Epoch 501 | Batch: 2 | Loss: 12.4339\n",
      "Epoch 501 | Batch: 3 | Loss: 10.9657\n",
      "Epoch 501 | Batch: 4 | Loss: 10.6988\n",
      "Epoch 501 | Batch: 5 | Loss: 10.9727\n",
      "Mean of loss / batch 11.014028549194336\n",
      "Epoch 502 | Batch: 1 | Loss: 11.5728\n",
      "Epoch 502 | Batch: 2 | Loss: 10.9721\n",
      "Epoch 502 | Batch: 3 | Loss: 10.7662\n",
      "Epoch 502 | Batch: 4 | Loss: 10.4396\n",
      "Epoch 502 | Batch: 5 | Loss: 10.9884\n",
      "Mean of loss / batch 10.947810173034668\n",
      "Epoch 503 | Batch: 1 | Loss: 10.9802\n",
      "Epoch 503 | Batch: 2 | Loss: 11.2969\n",
      "Epoch 503 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 503 | Batch: 4 | Loss: 10.9651\n",
      "Epoch 503 | Batch: 5 | Loss: 10.4536\n",
      "Mean of loss / batch 10.932169914245605\n",
      "Epoch 504 | Batch: 1 | Loss: 10.6312\n",
      "Epoch 504 | Batch: 2 | Loss: 10.9998\n",
      "Epoch 504 | Batch: 3 | Loss: 10.6290\n",
      "Epoch 504 | Batch: 4 | Loss: 11.7767\n",
      "Epoch 504 | Batch: 5 | Loss: 10.7041\n",
      "Mean of loss / batch 10.94815731048584\n",
      "Epoch 505 | Batch: 1 | Loss: 12.2083\n",
      "Epoch 505 | Batch: 2 | Loss: 11.0117\n",
      "Epoch 505 | Batch: 3 | Loss: 10.9950\n",
      "Epoch 505 | Batch: 4 | Loss: 10.8316\n",
      "Epoch 505 | Batch: 5 | Loss: 10.0780\n",
      "Mean of loss / batch 11.024896621704102\n",
      "Epoch 506 | Batch: 1 | Loss: 11.0259\n",
      "Epoch 506 | Batch: 2 | Loss: 10.6110\n",
      "Epoch 506 | Batch: 3 | Loss: 11.4338\n",
      "Epoch 506 | Batch: 4 | Loss: 10.6445\n",
      "Epoch 506 | Batch: 5 | Loss: 10.9916\n",
      "Mean of loss / batch 10.941364288330078\n",
      "Epoch 507 | Batch: 1 | Loss: 10.6372\n",
      "Epoch 507 | Batch: 2 | Loss: 10.9958\n",
      "Epoch 507 | Batch: 3 | Loss: 10.6328\n",
      "Epoch 507 | Batch: 4 | Loss: 11.3812\n",
      "Epoch 507 | Batch: 5 | Loss: 10.9711\n",
      "Mean of loss / batch 10.923614501953125\n",
      "Epoch 508 | Batch: 1 | Loss: 11.5610\n",
      "Epoch 508 | Batch: 2 | Loss: 10.5987\n",
      "Epoch 508 | Batch: 3 | Loss: 10.6698\n",
      "Epoch 508 | Batch: 4 | Loss: 12.0017\n",
      "Epoch 508 | Batch: 5 | Loss: 10.4583\n",
      "Mean of loss / batch 11.057879447937012\n",
      "Epoch 509 | Batch: 1 | Loss: 10.9799\n",
      "Epoch 509 | Batch: 2 | Loss: 10.6533\n",
      "Epoch 509 | Batch: 3 | Loss: 10.9872\n",
      "Epoch 509 | Batch: 4 | Loss: 10.6425\n",
      "Epoch 509 | Batch: 5 | Loss: 11.3628\n",
      "Mean of loss / batch 10.925135612487793\n",
      "Epoch 510 | Batch: 1 | Loss: 11.2661\n",
      "Epoch 510 | Batch: 2 | Loss: 10.9654\n",
      "Epoch 510 | Batch: 3 | Loss: 11.4465\n",
      "Epoch 510 | Batch: 4 | Loss: 10.7029\n",
      "Epoch 510 | Batch: 5 | Loss: 10.4369\n",
      "Mean of loss / batch 10.963544845581055\n",
      "Epoch 511 | Batch: 1 | Loss: 10.9889\n",
      "Epoch 511 | Batch: 2 | Loss: 10.9805\n",
      "Epoch 511 | Batch: 3 | Loss: 11.6205\n",
      "Epoch 511 | Batch: 4 | Loss: 10.5511\n",
      "Epoch 511 | Batch: 5 | Loss: 10.6564\n",
      "Mean of loss / batch 10.959479331970215\n",
      "Epoch 512 | Batch: 1 | Loss: 10.9858\n",
      "Epoch 512 | Batch: 2 | Loss: 10.3102\n",
      "Epoch 512 | Batch: 3 | Loss: 11.8551\n",
      "Epoch 512 | Batch: 4 | Loss: 11.2529\n",
      "Epoch 512 | Batch: 5 | Loss: 10.5084\n",
      "Mean of loss / batch 10.98246955871582\n",
      "Epoch 513 | Batch: 1 | Loss: 10.6449\n",
      "Epoch 513 | Batch: 2 | Loss: 12.0930\n",
      "Epoch 513 | Batch: 3 | Loss: 10.9714\n",
      "Epoch 513 | Batch: 4 | Loss: 11.1749\n",
      "Epoch 513 | Batch: 5 | Loss: 10.3207\n",
      "Mean of loss / batch 11.04098129272461\n",
      "Epoch 514 | Batch: 1 | Loss: 11.3803\n",
      "Epoch 514 | Batch: 2 | Loss: 10.9710\n",
      "Epoch 514 | Batch: 3 | Loss: 10.3776\n",
      "Epoch 514 | Batch: 4 | Loss: 10.2272\n",
      "Epoch 514 | Batch: 5 | Loss: 11.9712\n",
      "Mean of loss / batch 10.985466003417969\n",
      "Epoch 515 | Batch: 1 | Loss: 10.6543\n",
      "Epoch 515 | Batch: 2 | Loss: 10.2737\n",
      "Epoch 515 | Batch: 3 | Loss: 11.4675\n",
      "Epoch 515 | Batch: 4 | Loss: 10.6340\n",
      "Epoch 515 | Batch: 5 | Loss: 11.7595\n",
      "Mean of loss / batch 10.957794189453125\n",
      "Epoch 516 | Batch: 1 | Loss: 10.7095\n",
      "Epoch 516 | Batch: 2 | Loss: 12.4942\n",
      "Epoch 516 | Batch: 3 | Loss: 11.0058\n",
      "Epoch 516 | Batch: 4 | Loss: 10.7208\n",
      "Epoch 516 | Batch: 5 | Loss: 10.4484\n",
      "Mean of loss / batch 11.0757474899292\n",
      "Epoch 517 | Batch: 1 | Loss: 9.9160\n",
      "Epoch 517 | Batch: 2 | Loss: 11.5588\n",
      "Epoch 517 | Batch: 3 | Loss: 11.7850\n",
      "Epoch 517 | Batch: 4 | Loss: 10.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517 | Batch: 5 | Loss: 10.7039\n",
      "Mean of loss / batch 10.98581314086914\n",
      "Epoch 518 | Batch: 1 | Loss: 11.2810\n",
      "Epoch 518 | Batch: 2 | Loss: 11.2130\n",
      "Epoch 518 | Batch: 3 | Loss: 10.3747\n",
      "Epoch 518 | Batch: 4 | Loss: 11.7058\n",
      "Epoch 518 | Batch: 5 | Loss: 10.4894\n",
      "Mean of loss / batch 11.01276969909668\n",
      "Epoch 519 | Batch: 1 | Loss: 10.6401\n",
      "Epoch 519 | Batch: 2 | Loss: 10.9941\n",
      "Epoch 519 | Batch: 3 | Loss: 10.9839\n",
      "Epoch 519 | Batch: 4 | Loss: 11.3074\n",
      "Epoch 519 | Batch: 5 | Loss: 10.7006\n",
      "Mean of loss / batch 10.925212860107422\n",
      "Epoch 520 | Batch: 1 | Loss: 11.2844\n",
      "Epoch 520 | Batch: 2 | Loss: 9.7141\n",
      "Epoch 520 | Batch: 3 | Loss: 12.0864\n",
      "Epoch 520 | Batch: 4 | Loss: 10.6327\n",
      "Epoch 520 | Batch: 5 | Loss: 11.7640\n",
      "Mean of loss / batch 11.096317291259766\n",
      "Epoch 521 | Batch: 1 | Loss: 10.7081\n",
      "Epoch 521 | Batch: 2 | Loss: 10.0532\n",
      "Epoch 521 | Batch: 3 | Loss: 11.0383\n",
      "Epoch 521 | Batch: 4 | Loss: 11.0127\n",
      "Epoch 521 | Batch: 5 | Loss: 12.1276\n",
      "Mean of loss / batch 10.98798656463623\n",
      "Epoch 522 | Batch: 1 | Loss: 10.9697\n",
      "Epoch 522 | Batch: 2 | Loss: 11.3925\n",
      "Epoch 522 | Batch: 3 | Loss: 11.1191\n",
      "Epoch 522 | Batch: 4 | Loss: 10.7248\n",
      "Epoch 522 | Batch: 5 | Loss: 10.6895\n",
      "Mean of loss / batch 10.979130744934082\n",
      "Epoch 523 | Batch: 1 | Loss: 10.3312\n",
      "Epoch 523 | Batch: 2 | Loss: 11.8290\n",
      "Epoch 523 | Batch: 3 | Loss: 10.9664\n",
      "Epoch 523 | Batch: 4 | Loss: 10.1488\n",
      "Epoch 523 | Batch: 5 | Loss: 11.8559\n",
      "Mean of loss / batch 11.026246070861816\n",
      "Epoch 524 | Batch: 1 | Loss: 10.9674\n",
      "Epoch 524 | Batch: 2 | Loss: 10.9665\n",
      "Epoch 524 | Batch: 3 | Loss: 10.6924\n",
      "Epoch 524 | Batch: 4 | Loss: 10.9741\n",
      "Epoch 524 | Batch: 5 | Loss: 10.9709\n",
      "Mean of loss / batch 10.91425609588623\n",
      "Epoch 525 | Batch: 1 | Loss: 10.3784\n",
      "Epoch 525 | Batch: 2 | Loss: 11.3874\n",
      "Epoch 525 | Batch: 3 | Loss: 10.9718\n",
      "Epoch 525 | Batch: 4 | Loss: 10.6708\n",
      "Epoch 525 | Batch: 5 | Loss: 11.3196\n",
      "Mean of loss / batch 10.945608139038086\n",
      "Epoch 526 | Batch: 1 | Loss: 11.2380\n",
      "Epoch 526 | Batch: 2 | Loss: 10.5311\n",
      "Epoch 526 | Batch: 3 | Loss: 10.6510\n",
      "Epoch 526 | Batch: 4 | Loss: 11.3485\n",
      "Epoch 526 | Batch: 5 | Loss: 10.9678\n",
      "Mean of loss / batch 10.947288513183594\n",
      "Epoch 527 | Batch: 1 | Loss: 9.5590\n",
      "Epoch 527 | Batch: 2 | Loss: 10.5854\n",
      "Epoch 527 | Batch: 3 | Loss: 11.1081\n",
      "Epoch 527 | Batch: 4 | Loss: 13.4117\n",
      "Epoch 527 | Batch: 5 | Loss: 10.9756\n",
      "Mean of loss / batch 11.127960205078125\n",
      "Epoch 528 | Batch: 1 | Loss: 11.3571\n",
      "Epoch 528 | Batch: 2 | Loss: 11.1121\n",
      "Epoch 528 | Batch: 3 | Loss: 10.7706\n",
      "Epoch 528 | Batch: 4 | Loss: 11.2322\n",
      "Epoch 528 | Batch: 5 | Loss: 10.5404\n",
      "Mean of loss / batch 11.002492904663086\n",
      "Epoch 529 | Batch: 1 | Loss: 11.2957\n",
      "Epoch 529 | Batch: 2 | Loss: 10.4502\n",
      "Epoch 529 | Batch: 3 | Loss: 10.6304\n",
      "Epoch 529 | Batch: 4 | Loss: 11.7718\n",
      "Epoch 529 | Batch: 5 | Loss: 10.7056\n",
      "Mean of loss / batch 10.970751762390137\n",
      "Epoch 530 | Batch: 1 | Loss: 11.2792\n",
      "Epoch 530 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 530 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 530 | Batch: 4 | Loss: 10.7166\n",
      "Epoch 530 | Batch: 5 | Loss: 10.6705\n",
      "Mean of loss / batch 10.919299125671387\n",
      "Epoch 531 | Batch: 1 | Loss: 11.3199\n",
      "Epoch 531 | Batch: 2 | Loss: 9.8765\n",
      "Epoch 531 | Batch: 3 | Loss: 10.5884\n",
      "Epoch 531 | Batch: 4 | Loss: 12.4922\n",
      "Epoch 531 | Batch: 5 | Loss: 10.9670\n",
      "Mean of loss / batch 11.048818588256836\n",
      "Epoch 532 | Batch: 1 | Loss: 10.6897\n",
      "Epoch 532 | Batch: 2 | Loss: 10.6531\n",
      "Epoch 532 | Batch: 3 | Loss: 10.9873\n",
      "Epoch 532 | Batch: 4 | Loss: 11.3165\n",
      "Epoch 532 | Batch: 5 | Loss: 10.9657\n",
      "Mean of loss / batch 10.922453880310059\n",
      "Epoch 533 | Batch: 1 | Loss: 10.6990\n",
      "Epoch 533 | Batch: 2 | Loss: 11.5997\n",
      "Epoch 533 | Batch: 3 | Loss: 10.9700\n",
      "Epoch 533 | Batch: 4 | Loss: 10.7570\n",
      "Epoch 533 | Batch: 5 | Loss: 10.6965\n",
      "Mean of loss / batch 10.944426536560059\n",
      "Epoch 534 | Batch: 1 | Loss: 10.3419\n",
      "Epoch 534 | Batch: 2 | Loss: 11.4130\n",
      "Epoch 534 | Batch: 3 | Loss: 10.9752\n",
      "Epoch 534 | Batch: 4 | Loss: 11.2810\n",
      "Epoch 534 | Batch: 5 | Loss: 10.7171\n",
      "Mean of loss / batch 10.945649147033691\n",
      "Epoch 535 | Batch: 1 | Loss: 11.2680\n",
      "Epoch 535 | Batch: 2 | Loss: 10.7260\n",
      "Epoch 535 | Batch: 3 | Loss: 11.2599\n",
      "Epoch 535 | Batch: 4 | Loss: 11.1994\n",
      "Epoch 535 | Batch: 5 | Loss: 10.4115\n",
      "Mean of loss / batch 10.97296142578125\n",
      "Epoch 536 | Batch: 1 | Loss: 11.3340\n",
      "Epoch 536 | Batch: 2 | Loss: 11.5280\n",
      "Epoch 536 | Batch: 3 | Loss: 10.4520\n",
      "Epoch 536 | Batch: 4 | Loss: 11.6604\n",
      "Epoch 536 | Batch: 5 | Loss: 10.2988\n",
      "Mean of loss / batch 11.05461311340332\n",
      "Epoch 537 | Batch: 1 | Loss: 11.3749\n",
      "Epoch 537 | Batch: 2 | Loss: 11.5774\n",
      "Epoch 537 | Batch: 3 | Loss: 10.9717\n",
      "Epoch 537 | Batch: 4 | Loss: 10.3551\n",
      "Epoch 537 | Batch: 5 | Loss: 10.6259\n",
      "Mean of loss / batch 10.980993270874023\n",
      "Epoch 538 | Batch: 1 | Loss: 10.6118\n",
      "Epoch 538 | Batch: 2 | Loss: 11.0171\n",
      "Epoch 538 | Batch: 3 | Loss: 11.3817\n",
      "Epoch 538 | Batch: 4 | Loss: 10.6640\n",
      "Epoch 538 | Batch: 5 | Loss: 10.9827\n",
      "Mean of loss / batch 10.93143081665039\n",
      "Epoch 539 | Batch: 1 | Loss: 10.9765\n",
      "Epoch 539 | Batch: 2 | Loss: 11.2851\n",
      "Epoch 539 | Batch: 3 | Loss: 10.7144\n",
      "Epoch 539 | Batch: 4 | Loss: 10.3683\n",
      "Epoch 539 | Batch: 5 | Loss: 11.3943\n",
      "Mean of loss / batch 10.94770336151123\n",
      "Epoch 540 | Batch: 1 | Loss: 10.3450\n",
      "Epoch 540 | Batch: 2 | Loss: 11.4108\n",
      "Epoch 540 | Batch: 3 | Loss: 10.6526\n",
      "Epoch 540 | Batch: 4 | Loss: 10.9875\n",
      "Epoch 540 | Batch: 5 | Loss: 11.3171\n",
      "Mean of loss / batch 10.942587852478027\n",
      "Epoch 541 | Batch: 1 | Loss: 11.5070\n",
      "Epoch 541 | Batch: 2 | Loss: 11.1460\n",
      "Epoch 541 | Batch: 3 | Loss: 10.7254\n",
      "Epoch 541 | Batch: 4 | Loss: 10.4513\n",
      "Epoch 541 | Batch: 5 | Loss: 10.9864\n",
      "Mean of loss / batch 10.963218688964844\n",
      "Epoch 542 | Batch: 1 | Loss: 9.6374\n",
      "Epoch 542 | Batch: 2 | Loss: 12.6608\n",
      "Epoch 542 | Batch: 3 | Loss: 11.2910\n",
      "Epoch 542 | Batch: 4 | Loss: 10.9650\n",
      "Epoch 542 | Batch: 5 | Loss: 10.7112\n",
      "Mean of loss / batch 11.053094863891602\n",
      "Epoch 543 | Batch: 1 | Loss: 10.6670\n",
      "Epoch 543 | Batch: 2 | Loss: 10.9816\n",
      "Epoch 543 | Batch: 3 | Loss: 10.9757\n",
      "Epoch 543 | Batch: 4 | Loss: 10.9720\n",
      "Epoch 543 | Batch: 5 | Loss: 10.9695\n",
      "Mean of loss / batch 10.9131498336792\n",
      "Epoch 544 | Batch: 1 | Loss: 11.2576\n",
      "Epoch 544 | Batch: 2 | Loss: 10.7336\n",
      "Epoch 544 | Batch: 3 | Loss: 10.9674\n",
      "Epoch 544 | Batch: 4 | Loss: 10.4083\n",
      "Epoch 544 | Batch: 5 | Loss: 11.3680\n",
      "Mean of loss / batch 10.946974754333496\n",
      "Epoch 545 | Batch: 1 | Loss: 11.2694\n",
      "Epoch 545 | Batch: 2 | Loss: 10.4847\n",
      "Epoch 545 | Batch: 3 | Loss: 11.3238\n",
      "Epoch 545 | Batch: 4 | Loss: 10.9661\n",
      "Epoch 545 | Batch: 5 | Loss: 10.6957\n",
      "Mean of loss / batch 10.947938919067383\n",
      "Epoch 546 | Batch: 1 | Loss: 10.9733\n",
      "Epoch 546 | Batch: 2 | Loss: 11.5776\n",
      "Epoch 546 | Batch: 3 | Loss: 10.3916\n",
      "Epoch 546 | Batch: 4 | Loss: 11.6956\n",
      "Epoch 546 | Batch: 5 | Loss: 10.4964\n",
      "Mean of loss / batch 11.0269193649292\n",
      "Epoch 547 | Batch: 1 | Loss: 11.6555\n",
      "Epoch 547 | Batch: 2 | Loss: 11.6297\n",
      "Epoch 547 | Batch: 3 | Loss: 10.8714\n",
      "Epoch 547 | Batch: 4 | Loss: 10.5450\n",
      "Epoch 547 | Batch: 5 | Loss: 10.3353\n",
      "Mean of loss / batch 11.0073823928833\n",
      "Epoch 548 | Batch: 1 | Loss: 12.2300\n",
      "Epoch 548 | Batch: 2 | Loss: 10.7404\n",
      "Epoch 548 | Batch: 3 | Loss: 10.1239\n",
      "Epoch 548 | Batch: 4 | Loss: 11.8742\n",
      "Epoch 548 | Batch: 5 | Loss: 10.3855\n",
      "Mean of loss / batch 11.070794105529785\n",
      "Epoch 549 | Batch: 1 | Loss: 12.1497\n",
      "Epoch 549 | Batch: 2 | Loss: 11.3842\n",
      "Epoch 549 | Batch: 3 | Loss: 11.2337\n",
      "Epoch 549 | Batch: 4 | Loss: 10.8786\n",
      "Epoch 549 | Batch: 5 | Loss: 9.8293\n",
      "Mean of loss / batch 11.095114707946777\n",
      "Epoch 550 | Batch: 1 | Loss: 9.6311\n",
      "Epoch 550 | Batch: 2 | Loss: 11.7633\n",
      "Epoch 550 | Batch: 3 | Loss: 11.9997\n",
      "Epoch 550 | Batch: 4 | Loss: 11.3047\n",
      "Epoch 550 | Batch: 5 | Loss: 10.4391\n",
      "Mean of loss / batch 11.027592658996582\n",
      "Epoch 551 | Batch: 1 | Loss: 11.7100\n",
      "Epoch 551 | Batch: 2 | Loss: 10.4865\n",
      "Epoch 551 | Batch: 3 | Loss: 10.2976\n",
      "Epoch 551 | Batch: 4 | Loss: 10.5992\n",
      "Epoch 551 | Batch: 5 | Loss: 11.9158\n",
      "Mean of loss / batch 11.001835823059082\n",
      "Epoch 552 | Batch: 1 | Loss: 10.6666\n",
      "Epoch 552 | Batch: 2 | Loss: 10.9817\n",
      "Epoch 552 | Batch: 3 | Loss: 10.6504\n",
      "Epoch 552 | Batch: 4 | Loss: 11.3495\n",
      "Epoch 552 | Batch: 5 | Loss: 10.9679\n",
      "Mean of loss / batch 10.9232177734375\n",
      "Epoch 553 | Batch: 1 | Loss: 11.2489\n",
      "Epoch 553 | Batch: 2 | Loss: 10.9663\n",
      "Epoch 553 | Batch: 3 | Loss: 10.2729\n",
      "Epoch 553 | Batch: 4 | Loss: 11.3850\n",
      "Epoch 553 | Batch: 5 | Loss: 10.9715\n",
      "Mean of loss / batch 10.96892261505127\n",
      "Epoch 554 | Batch: 1 | Loss: 10.6716\n",
      "Epoch 554 | Batch: 2 | Loss: 10.9799\n",
      "Epoch 554 | Batch: 3 | Loss: 11.2962\n",
      "Epoch 554 | Batch: 4 | Loss: 10.9651\n",
      "Epoch 554 | Batch: 5 | Loss: 10.7086\n",
      "Mean of loss / batch 10.924288749694824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555 | Batch: 1 | Loss: 10.9708\n",
      "Epoch 555 | Batch: 2 | Loss: 11.5584\n",
      "Epoch 555 | Batch: 3 | Loss: 11.1597\n",
      "Epoch 555 | Batch: 4 | Loss: 10.6874\n",
      "Epoch 555 | Batch: 5 | Loss: 10.4269\n",
      "Mean of loss / batch 10.9606351852417\n",
      "Epoch 556 | Batch: 1 | Loss: 11.7223\n",
      "Epoch 556 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 556 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 556 | Batch: 4 | Loss: 10.4726\n",
      "Epoch 556 | Batch: 5 | Loss: 10.6358\n",
      "Mean of loss / batch 10.952198028564453\n",
      "Epoch 557 | Batch: 1 | Loss: 9.8612\n",
      "Epoch 557 | Batch: 2 | Loss: 11.0888\n",
      "Epoch 557 | Batch: 3 | Loss: 11.5009\n",
      "Epoch 557 | Batch: 4 | Loss: 10.2595\n",
      "Epoch 557 | Batch: 5 | Loss: 12.3666\n",
      "Mean of loss / batch 11.015401840209961\n",
      "Epoch 558 | Batch: 1 | Loss: 11.7331\n",
      "Epoch 558 | Batch: 2 | Loss: 11.1124\n",
      "Epoch 558 | Batch: 3 | Loss: 10.5999\n",
      "Epoch 558 | Batch: 4 | Loss: 10.9914\n",
      "Epoch 558 | Batch: 5 | Loss: 10.9821\n",
      "Mean of loss / batch 11.083791732788086\n",
      "Epoch 559 | Batch: 1 | Loss: 10.6497\n",
      "Epoch 559 | Batch: 2 | Loss: 11.3506\n",
      "Epoch 559 | Batch: 3 | Loss: 10.0976\n",
      "Epoch 559 | Batch: 4 | Loss: 11.4616\n",
      "Epoch 559 | Batch: 5 | Loss: 11.3304\n",
      "Mean of loss / batch 10.977978706359863\n",
      "Epoch 560 | Batch: 1 | Loss: 11.2450\n",
      "Epoch 560 | Batch: 2 | Loss: 11.1898\n",
      "Epoch 560 | Batch: 3 | Loss: 10.9754\n",
      "Epoch 560 | Batch: 4 | Loss: 10.7786\n",
      "Epoch 560 | Batch: 5 | Loss: 10.4559\n",
      "Mean of loss / batch 10.928946495056152\n",
      "Epoch 561 | Batch: 1 | Loss: 10.6317\n",
      "Epoch 561 | Batch: 2 | Loss: 10.6155\n",
      "Epoch 561 | Batch: 3 | Loss: 11.4211\n",
      "Epoch 561 | Batch: 4 | Loss: 10.3213\n",
      "Epoch 561 | Batch: 5 | Loss: 11.8411\n",
      "Mean of loss / batch 10.966146469116211\n",
      "Epoch 562 | Batch: 1 | Loss: 10.6855\n",
      "Epoch 562 | Batch: 2 | Loss: 11.3011\n",
      "Epoch 562 | Batch: 3 | Loss: 11.2261\n",
      "Epoch 562 | Batch: 4 | Loss: 10.7596\n",
      "Epoch 562 | Batch: 5 | Loss: 10.6982\n",
      "Mean of loss / batch 10.934107780456543\n",
      "Epoch 563 | Batch: 1 | Loss: 10.6586\n",
      "Epoch 563 | Batch: 2 | Loss: 10.6330\n",
      "Epoch 563 | Batch: 3 | Loss: 10.9986\n",
      "Epoch 563 | Batch: 4 | Loss: 10.6301\n",
      "Epoch 563 | Batch: 5 | Loss: 11.7727\n",
      "Mean of loss / batch 10.938596725463867\n",
      "Epoch 564 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 564 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 564 | Batch: 3 | Loss: 11.2219\n",
      "Epoch 564 | Batch: 4 | Loss: 10.3520\n",
      "Epoch 564 | Batch: 5 | Loss: 11.3549\n",
      "Mean of loss / batch 10.97181510925293\n",
      "Epoch 565 | Batch: 1 | Loss: 11.2609\n",
      "Epoch 565 | Batch: 2 | Loss: 10.7311\n",
      "Epoch 565 | Batch: 3 | Loss: 11.5432\n",
      "Epoch 565 | Batch: 4 | Loss: 10.6136\n",
      "Epoch 565 | Batch: 5 | Loss: 10.6741\n",
      "Mean of loss / batch 10.964606285095215\n",
      "Epoch 566 | Batch: 1 | Loss: 10.9791\n",
      "Epoch 566 | Batch: 2 | Loss: 9.6961\n",
      "Epoch 566 | Batch: 3 | Loss: 10.0789\n",
      "Epoch 566 | Batch: 4 | Loss: 12.2601\n",
      "Epoch 566 | Batch: 5 | Loss: 12.2026\n",
      "Mean of loss / batch 11.043356895446777\n",
      "Epoch 567 | Batch: 1 | Loss: 11.4065\n",
      "Epoch 567 | Batch: 2 | Loss: 10.6181\n",
      "Epoch 567 | Batch: 3 | Loss: 11.8723\n",
      "Epoch 567 | Batch: 4 | Loss: 10.7068\n",
      "Epoch 567 | Batch: 5 | Loss: 10.7024\n",
      "Mean of loss / batch 11.061227798461914\n",
      "Epoch 568 | Batch: 1 | Loss: 10.6613\n",
      "Epoch 568 | Batch: 2 | Loss: 12.0308\n",
      "Epoch 568 | Batch: 3 | Loss: 10.4354\n",
      "Epoch 568 | Batch: 4 | Loss: 10.6379\n",
      "Epoch 568 | Batch: 5 | Loss: 11.3713\n",
      "Mean of loss / batch 11.027315139770508\n",
      "Epoch 569 | Batch: 1 | Loss: 10.0652\n",
      "Epoch 569 | Batch: 2 | Loss: 11.4775\n",
      "Epoch 569 | Batch: 3 | Loss: 10.9860\n",
      "Epoch 569 | Batch: 4 | Loss: 10.9786\n",
      "Epoch 569 | Batch: 5 | Loss: 11.2921\n",
      "Mean of loss / batch 10.959882736206055\n",
      "Epoch 570 | Batch: 1 | Loss: 10.7099\n",
      "Epoch 570 | Batch: 2 | Loss: 10.9706\n",
      "Epoch 570 | Batch: 3 | Loss: 10.0867\n",
      "Epoch 570 | Batch: 4 | Loss: 11.0313\n",
      "Epoch 570 | Batch: 5 | Loss: 12.2077\n",
      "Mean of loss / batch 11.001215934753418\n",
      "Epoch 571 | Batch: 1 | Loss: 10.9668\n",
      "Epoch 571 | Batch: 2 | Loss: 10.7393\n",
      "Epoch 571 | Batch: 3 | Loss: 11.2486\n",
      "Epoch 571 | Batch: 4 | Loss: 11.1921\n",
      "Epoch 571 | Batch: 5 | Loss: 10.6133\n",
      "Mean of loss / batch 10.952006340026855\n",
      "Epoch 572 | Batch: 1 | Loss: 10.6740\n",
      "Epoch 572 | Batch: 2 | Loss: 11.6516\n",
      "Epoch 572 | Batch: 3 | Loss: 10.7474\n",
      "Epoch 572 | Batch: 4 | Loss: 10.4145\n",
      "Epoch 572 | Batch: 5 | Loss: 11.3641\n",
      "Mean of loss / batch 10.970324516296387\n",
      "Epoch 573 | Batch: 1 | Loss: 10.9692\n",
      "Epoch 573 | Batch: 2 | Loss: 10.9678\n",
      "Epoch 573 | Batch: 3 | Loss: 11.5293\n",
      "Epoch 573 | Batch: 4 | Loss: 10.9764\n",
      "Epoch 573 | Batch: 5 | Loss: 10.4012\n",
      "Mean of loss / batch 10.968782424926758\n",
      "Epoch 574 | Batch: 1 | Loss: 10.2802\n",
      "Epoch 574 | Batch: 2 | Loss: 11.0292\n",
      "Epoch 574 | Batch: 3 | Loss: 10.2119\n",
      "Epoch 574 | Batch: 4 | Loss: 12.4643\n",
      "Epoch 574 | Batch: 5 | Loss: 10.9663\n",
      "Mean of loss / batch 10.990374565124512\n",
      "Epoch 575 | Batch: 1 | Loss: 10.9659\n",
      "Epoch 575 | Batch: 2 | Loss: 11.5012\n",
      "Epoch 575 | Batch: 3 | Loss: 10.8153\n",
      "Epoch 575 | Batch: 4 | Loss: 11.1975\n",
      "Epoch 575 | Batch: 5 | Loss: 10.4168\n",
      "Mean of loss / batch 10.97933292388916\n",
      "Epoch 576 | Batch: 1 | Loss: 12.0293\n",
      "Epoch 576 | Batch: 2 | Loss: 10.7956\n",
      "Epoch 576 | Batch: 3 | Loss: 11.4526\n",
      "Epoch 576 | Batch: 4 | Loss: 10.9873\n",
      "Epoch 576 | Batch: 5 | Loss: 10.1481\n",
      "Mean of loss / batch 11.082592964172363\n",
      "Epoch 577 | Batch: 1 | Loss: 11.8956\n",
      "Epoch 577 | Batch: 2 | Loss: 11.2671\n",
      "Epoch 577 | Batch: 3 | Loss: 10.4880\n",
      "Epoch 577 | Batch: 4 | Loss: 9.9574\n",
      "Epoch 577 | Batch: 5 | Loss: 11.5348\n",
      "Mean of loss / batch 11.028572082519531\n",
      "Epoch 578 | Batch: 1 | Loss: 11.3783\n",
      "Epoch 578 | Batch: 2 | Loss: 10.0546\n",
      "Epoch 578 | Batch: 3 | Loss: 11.0380\n",
      "Epoch 578 | Batch: 4 | Loss: 11.4198\n",
      "Epoch 578 | Batch: 5 | Loss: 10.9762\n",
      "Mean of loss / batch 10.97340202331543\n",
      "Epoch 579 | Batch: 1 | Loss: 10.6602\n",
      "Epoch 579 | Batch: 2 | Loss: 10.9842\n",
      "Epoch 579 | Batch: 3 | Loss: 10.3157\n",
      "Epoch 579 | Batch: 4 | Loss: 11.0175\n",
      "Epoch 579 | Batch: 5 | Loss: 11.7660\n",
      "Mean of loss / batch 10.948718070983887\n",
      "Epoch 580 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 580 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 580 | Batch: 3 | Loss: 10.7097\n",
      "Epoch 580 | Batch: 4 | Loss: 10.6660\n",
      "Epoch 580 | Batch: 5 | Loss: 11.3261\n",
      "Mean of loss / batch 10.926383018493652\n",
      "Epoch 581 | Batch: 1 | Loss: 10.4143\n",
      "Epoch 581 | Batch: 2 | Loss: 12.1065\n",
      "Epoch 581 | Batch: 3 | Loss: 10.1797\n",
      "Epoch 581 | Batch: 4 | Loss: 11.0132\n",
      "Epoch 581 | Batch: 5 | Loss: 11.7519\n",
      "Mean of loss / batch 11.093114852905273\n",
      "Epoch 582 | Batch: 1 | Loss: 11.2181\n",
      "Epoch 582 | Batch: 2 | Loss: 10.9697\n",
      "Epoch 582 | Batch: 3 | Loss: 10.9680\n",
      "Epoch 582 | Batch: 4 | Loss: 10.9670\n",
      "Epoch 582 | Batch: 5 | Loss: 10.5139\n",
      "Mean of loss / batch 10.927331924438477\n",
      "Epoch 583 | Batch: 1 | Loss: 11.3087\n",
      "Epoch 583 | Batch: 2 | Loss: 10.4344\n",
      "Epoch 583 | Batch: 3 | Loss: 11.7148\n",
      "Epoch 583 | Batch: 4 | Loss: 10.2423\n",
      "Epoch 583 | Batch: 5 | Loss: 11.3973\n",
      "Mean of loss / batch 11.019497871398926\n",
      "Epoch 584 | Batch: 1 | Loss: 11.2885\n",
      "Epoch 584 | Batch: 2 | Loss: 11.2179\n",
      "Epoch 584 | Batch: 3 | Loss: 10.7672\n",
      "Epoch 584 | Batch: 4 | Loss: 10.7031\n",
      "Epoch 584 | Batch: 5 | Loss: 10.6618\n",
      "Mean of loss / batch 10.927679061889648\n",
      "Epoch 585 | Batch: 1 | Loss: 11.3321\n",
      "Epoch 585 | Batch: 2 | Loss: 10.9666\n",
      "Epoch 585 | Batch: 3 | Loss: 10.4181\n",
      "Epoch 585 | Batch: 4 | Loss: 10.2534\n",
      "Epoch 585 | Batch: 5 | Loss: 11.9322\n",
      "Mean of loss / batch 10.980451583862305\n",
      "Epoch 586 | Batch: 1 | Loss: 11.5887\n",
      "Epoch 586 | Batch: 2 | Loss: 10.3787\n",
      "Epoch 586 | Batch: 3 | Loss: 10.2713\n",
      "Epoch 586 | Batch: 4 | Loss: 12.3439\n",
      "Epoch 586 | Batch: 5 | Loss: 10.7139\n",
      "Mean of loss / batch 11.059298515319824\n",
      "Epoch 587 | Batch: 1 | Loss: 10.6688\n",
      "Epoch 587 | Batch: 2 | Loss: 9.9568\n",
      "Epoch 587 | Batch: 3 | Loss: 10.5876\n",
      "Epoch 587 | Batch: 4 | Loss: 13.4711\n",
      "Epoch 587 | Batch: 5 | Loss: 10.7869\n",
      "Mean of loss / batch 11.094247817993164\n",
      "Epoch 588 | Batch: 1 | Loss: 10.2174\n",
      "Epoch 588 | Batch: 2 | Loss: 11.0080\n",
      "Epoch 588 | Batch: 3 | Loss: 11.3637\n",
      "Epoch 588 | Batch: 4 | Loss: 10.9692\n",
      "Epoch 588 | Batch: 5 | Loss: 11.2561\n",
      "Mean of loss / batch 10.96288776397705\n",
      "Epoch 589 | Batch: 1 | Loss: 10.9658\n",
      "Epoch 589 | Batch: 2 | Loss: 10.7305\n",
      "Epoch 589 | Batch: 3 | Loss: 11.2560\n",
      "Epoch 589 | Batch: 4 | Loss: 10.5038\n",
      "Epoch 589 | Batch: 5 | Loss: 11.3138\n",
      "Mean of loss / batch 10.953973770141602\n",
      "Epoch 590 | Batch: 1 | Loss: 11.7715\n",
      "Epoch 590 | Batch: 2 | Loss: 11.0017\n",
      "Epoch 590 | Batch: 3 | Loss: 10.7041\n",
      "Epoch 590 | Batch: 4 | Loss: 10.7015\n",
      "Epoch 590 | Batch: 5 | Loss: 10.6607\n",
      "Mean of loss / batch 10.967920303344727\n",
      "Epoch 591 | Batch: 1 | Loss: 10.9840\n",
      "Epoch 591 | Batch: 2 | Loss: 11.6380\n",
      "Epoch 591 | Batch: 3 | Loss: 10.3230\n",
      "Epoch 591 | Batch: 4 | Loss: 11.7377\n",
      "Epoch 591 | Batch: 5 | Loss: 10.4680\n",
      "Mean of loss / batch 11.030141830444336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592 | Batch: 1 | Loss: 10.6347\n",
      "Epoch 592 | Batch: 2 | Loss: 10.9974\n",
      "Epoch 592 | Batch: 3 | Loss: 10.9860\n",
      "Epoch 592 | Batch: 4 | Loss: 11.6479\n",
      "Epoch 592 | Batch: 5 | Loss: 10.5305\n",
      "Mean of loss / batch 10.959314346313477\n",
      "Epoch 593 | Batch: 1 | Loss: 10.6508\n",
      "Epoch 593 | Batch: 2 | Loss: 10.9883\n",
      "Epoch 593 | Batch: 3 | Loss: 10.6410\n",
      "Epoch 593 | Batch: 4 | Loss: 11.7374\n",
      "Epoch 593 | Batch: 5 | Loss: 10.7167\n",
      "Mean of loss / batch 10.946842193603516\n",
      "Epoch 594 | Batch: 1 | Loss: 11.2685\n",
      "Epoch 594 | Batch: 2 | Loss: 10.7257\n",
      "Epoch 594 | Batch: 3 | Loss: 9.8006\n",
      "Epoch 594 | Batch: 4 | Loss: 12.0382\n",
      "Epoch 594 | Batch: 5 | Loss: 11.3191\n",
      "Mean of loss / batch 11.03040885925293\n",
      "Epoch 595 | Batch: 1 | Loss: 11.2377\n",
      "Epoch 595 | Batch: 2 | Loss: 10.9672\n",
      "Epoch 595 | Batch: 3 | Loss: 10.9665\n",
      "Epoch 595 | Batch: 4 | Loss: 10.7362\n",
      "Epoch 595 | Batch: 5 | Loss: 10.6831\n",
      "Mean of loss / batch 10.918153762817383\n",
      "Epoch 596 | Batch: 1 | Loss: 10.6489\n",
      "Epoch 596 | Batch: 2 | Loss: 10.2640\n",
      "Epoch 596 | Batch: 3 | Loss: 11.4760\n",
      "Epoch 596 | Batch: 4 | Loss: 10.6316\n",
      "Epoch 596 | Batch: 5 | Loss: 11.7675\n",
      "Mean of loss / batch 10.957612991333008\n",
      "Epoch 597 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 597 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 597 | Batch: 3 | Loss: 11.2208\n",
      "Epoch 597 | Batch: 4 | Loss: 10.5596\n",
      "Epoch 597 | Batch: 5 | Loss: 10.9727\n",
      "Mean of loss / batch 10.936663627624512\n",
      "Epoch 598 | Batch: 1 | Loss: 11.2718\n",
      "Epoch 598 | Batch: 2 | Loss: 11.6907\n",
      "Epoch 598 | Batch: 3 | Loss: 10.9205\n",
      "Epoch 598 | Batch: 4 | Loss: 10.6266\n",
      "Epoch 598 | Batch: 5 | Loss: 10.3878\n",
      "Mean of loss / batch 10.979477882385254\n",
      "Epoch 599 | Batch: 1 | Loss: 9.8513\n",
      "Epoch 599 | Batch: 2 | Loss: 10.5850\n",
      "Epoch 599 | Batch: 3 | Loss: 12.6155\n",
      "Epoch 599 | Batch: 4 | Loss: 10.3549\n",
      "Epoch 599 | Batch: 5 | Loss: 11.8007\n",
      "Mean of loss / batch 11.04150104522705\n",
      "Epoch 600 | Batch: 1 | Loss: 10.4283\n",
      "Epoch 600 | Batch: 2 | Loss: 12.0862\n",
      "Epoch 600 | Batch: 3 | Loss: 10.9717\n",
      "Epoch 600 | Batch: 4 | Loss: 10.9693\n",
      "Epoch 600 | Batch: 5 | Loss: 10.5403\n",
      "Mean of loss / batch 10.999173164367676\n",
      "Epoch 601 | Batch: 1 | Loss: 10.9746\n",
      "Epoch 601 | Batch: 2 | Loss: 10.9712\n",
      "Epoch 601 | Batch: 3 | Loss: 10.6726\n",
      "Epoch 601 | Batch: 4 | Loss: 10.9796\n",
      "Epoch 601 | Batch: 5 | Loss: 10.9745\n",
      "Mean of loss / batch 10.91450023651123\n",
      "Epoch 602 | Batch: 1 | Loss: 10.0498\n",
      "Epoch 602 | Batch: 2 | Loss: 10.5929\n",
      "Epoch 602 | Batch: 3 | Loss: 10.1318\n",
      "Epoch 602 | Batch: 4 | Loss: 12.6583\n",
      "Epoch 602 | Batch: 5 | Loss: 11.6072\n",
      "Mean of loss / batch 11.007993698120117\n",
      "Epoch 603 | Batch: 1 | Loss: 11.1735\n",
      "Epoch 603 | Batch: 2 | Loss: 10.8169\n",
      "Epoch 603 | Batch: 3 | Loss: 10.2736\n",
      "Epoch 603 | Batch: 4 | Loss: 11.7695\n",
      "Epoch 603 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 10.999727249145508\n",
      "Epoch 604 | Batch: 1 | Loss: 11.2224\n",
      "Epoch 604 | Batch: 2 | Loss: 11.5875\n",
      "Epoch 604 | Batch: 3 | Loss: 10.9687\n",
      "Epoch 604 | Batch: 4 | Loss: 10.8324\n",
      "Epoch 604 | Batch: 5 | Loss: 10.3017\n",
      "Mean of loss / batch 10.982542037963867\n",
      "Epoch 605 | Batch: 1 | Loss: 9.8636\n",
      "Epoch 605 | Batch: 2 | Loss: 10.5851\n",
      "Epoch 605 | Batch: 3 | Loss: 11.0895\n",
      "Epoch 605 | Batch: 4 | Loss: 11.5020\n",
      "Epoch 605 | Batch: 5 | Loss: 11.7229\n",
      "Mean of loss / batch 10.952608108520508\n",
      "Epoch 606 | Batch: 1 | Loss: 10.7215\n",
      "Epoch 606 | Batch: 2 | Loss: 10.9688\n",
      "Epoch 606 | Batch: 3 | Loss: 10.6809\n",
      "Epoch 606 | Batch: 4 | Loss: 10.6474\n",
      "Epoch 606 | Batch: 5 | Loss: 11.7186\n",
      "Mean of loss / batch 10.947454452514648\n",
      "Epoch 607 | Batch: 1 | Loss: 11.2074\n",
      "Epoch 607 | Batch: 2 | Loss: 11.3595\n",
      "Epoch 607 | Batch: 3 | Loss: 11.0072\n",
      "Epoch 607 | Batch: 4 | Loss: 10.5892\n",
      "Epoch 607 | Batch: 5 | Loss: 10.6638\n",
      "Mean of loss / batch 10.965431213378906\n",
      "Epoch 608 | Batch: 1 | Loss: 11.3292\n",
      "Epoch 608 | Batch: 2 | Loss: 11.2443\n",
      "Epoch 608 | Batch: 3 | Loss: 10.9666\n",
      "Epoch 608 | Batch: 4 | Loss: 10.7378\n",
      "Epoch 608 | Batch: 5 | Loss: 10.4013\n",
      "Mean of loss / batch 10.935847282409668\n",
      "Epoch 609 | Batch: 1 | Loss: 11.3724\n",
      "Epoch 609 | Batch: 2 | Loss: 10.9701\n",
      "Epoch 609 | Batch: 3 | Loss: 11.2605\n",
      "Epoch 609 | Batch: 4 | Loss: 11.6681\n",
      "Epoch 609 | Batch: 5 | Loss: 10.4928\n",
      "Mean of loss / batch 11.152793884277344\n",
      "Epoch 610 | Batch: 1 | Loss: 11.8607\n",
      "Epoch 610 | Batch: 2 | Loss: 10.6803\n",
      "Epoch 610 | Batch: 3 | Loss: 10.6470\n",
      "Epoch 610 | Batch: 4 | Loss: 10.9902\n",
      "Epoch 610 | Batch: 5 | Loss: 10.6388\n",
      "Mean of loss / batch 10.963415145874023\n",
      "Epoch 611 | Batch: 1 | Loss: 10.6201\n",
      "Epoch 611 | Batch: 2 | Loss: 11.0086\n",
      "Epoch 611 | Batch: 3 | Loss: 10.6218\n",
      "Epoch 611 | Batch: 4 | Loss: 11.8034\n",
      "Epoch 611 | Batch: 5 | Loss: 10.6962\n",
      "Mean of loss / batch 10.950006484985352\n",
      "Epoch 612 | Batch: 1 | Loss: 10.9732\n",
      "Epoch 612 | Batch: 2 | Loss: 10.3638\n",
      "Epoch 612 | Batch: 3 | Loss: 11.7905\n",
      "Epoch 612 | Batch: 4 | Loss: 10.9654\n",
      "Epoch 612 | Batch: 5 | Loss: 10.7026\n",
      "Mean of loss / batch 10.959104537963867\n",
      "Epoch 613 | Batch: 1 | Loss: 11.2823\n",
      "Epoch 613 | Batch: 2 | Loss: 10.9650\n",
      "Epoch 613 | Batch: 3 | Loss: 10.9650\n",
      "Epoch 613 | Batch: 4 | Loss: 10.7153\n",
      "Epoch 613 | Batch: 5 | Loss: 10.6697\n",
      "Mean of loss / batch 10.919473648071289\n",
      "Epoch 614 | Batch: 1 | Loss: 10.9806\n",
      "Epoch 614 | Batch: 2 | Loss: 10.6521\n",
      "Epoch 614 | Batch: 3 | Loss: 10.2698\n",
      "Epoch 614 | Batch: 4 | Loss: 11.4709\n",
      "Epoch 614 | Batch: 5 | Loss: 11.3365\n",
      "Mean of loss / batch 10.941983222961426\n",
      "Epoch 615 | Batch: 1 | Loss: 11.5311\n",
      "Epoch 615 | Batch: 2 | Loss: 11.1523\n",
      "Epoch 615 | Batch: 3 | Loss: 10.8482\n",
      "Epoch 615 | Batch: 4 | Loss: 10.1168\n",
      "Epoch 615 | Batch: 5 | Loss: 11.4412\n",
      "Mean of loss / batch 11.017913818359375\n",
      "Epoch 616 | Batch: 1 | Loss: 10.6421\n",
      "Epoch 616 | Batch: 2 | Loss: 9.8809\n",
      "Epoch 616 | Batch: 3 | Loss: 10.5854\n",
      "Epoch 616 | Batch: 4 | Loss: 13.0847\n",
      "Epoch 616 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 11.031618118286133\n",
      "Epoch 617 | Batch: 1 | Loss: 9.9577\n",
      "Epoch 617 | Batch: 2 | Loss: 12.3985\n",
      "Epoch 617 | Batch: 3 | Loss: 11.2282\n",
      "Epoch 617 | Batch: 4 | Loss: 10.5471\n",
      "Epoch 617 | Batch: 5 | Loss: 11.2926\n",
      "Mean of loss / batch 11.084808349609375\n",
      "Epoch 618 | Batch: 1 | Loss: 11.2205\n",
      "Epoch 618 | Batch: 2 | Loss: 10.9693\n",
      "Epoch 618 | Batch: 3 | Loss: 10.5401\n",
      "Epoch 618 | Batch: 4 | Loss: 11.2959\n",
      "Epoch 618 | Batch: 5 | Loss: 10.7076\n",
      "Mean of loss / batch 10.946671485900879\n",
      "Epoch 619 | Batch: 1 | Loss: 10.6647\n",
      "Epoch 619 | Batch: 2 | Loss: 10.6369\n",
      "Epoch 619 | Batch: 3 | Loss: 11.3731\n",
      "Epoch 619 | Batch: 4 | Loss: 11.2727\n",
      "Epoch 619 | Batch: 5 | Loss: 10.7227\n",
      "Mean of loss / batch 10.934013366699219\n",
      "Epoch 620 | Batch: 1 | Loss: 10.0859\n",
      "Epoch 620 | Batch: 2 | Loss: 11.0314\n",
      "Epoch 620 | Batch: 3 | Loss: 11.0082\n",
      "Epoch 620 | Batch: 4 | Loss: 11.7352\n",
      "Epoch 620 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 10.965173721313477\n",
      "Epoch 621 | Batch: 1 | Loss: 11.2134\n",
      "Epoch 621 | Batch: 2 | Loss: 10.7715\n",
      "Epoch 621 | Batch: 3 | Loss: 10.9652\n",
      "Epoch 621 | Batch: 4 | Loss: 10.9651\n",
      "Epoch 621 | Batch: 5 | Loss: 10.7086\n",
      "Mean of loss / batch 10.92475414276123\n",
      "Epoch 622 | Batch: 1 | Loss: 10.6653\n",
      "Epoch 622 | Batch: 2 | Loss: 10.9822\n",
      "Epoch 622 | Batch: 3 | Loss: 9.9965\n",
      "Epoch 622 | Batch: 4 | Loss: 11.9750\n",
      "Epoch 622 | Batch: 5 | Loss: 11.2956\n",
      "Mean of loss / batch 10.982918739318848\n",
      "Epoch 623 | Batch: 1 | Loss: 11.2225\n",
      "Epoch 623 | Batch: 2 | Loss: 10.5567\n",
      "Epoch 623 | Batch: 3 | Loss: 11.9183\n",
      "Epoch 623 | Batch: 4 | Loss: 10.8317\n",
      "Epoch 623 | Batch: 5 | Loss: 10.5224\n",
      "Mean of loss / batch 11.010316848754883\n",
      "Epoch 624 | Batch: 1 | Loss: 11.9602\n",
      "Epoch 624 | Batch: 2 | Loss: 10.8176\n",
      "Epoch 624 | Batch: 3 | Loss: 10.7355\n",
      "Epoch 624 | Batch: 4 | Loss: 10.6827\n",
      "Epoch 624 | Batch: 5 | Loss: 10.6486\n",
      "Mean of loss / batch 10.968908309936523\n",
      "Epoch 625 | Batch: 1 | Loss: 10.6265\n",
      "Epoch 625 | Batch: 2 | Loss: 10.2209\n",
      "Epoch 625 | Batch: 3 | Loss: 12.4448\n",
      "Epoch 625 | Batch: 4 | Loss: 10.4204\n",
      "Epoch 625 | Batch: 5 | Loss: 11.3605\n",
      "Mean of loss / batch 11.01462459564209\n",
      "Epoch 626 | Batch: 1 | Loss: 11.2646\n",
      "Epoch 626 | Batch: 2 | Loss: 10.4915\n",
      "Epoch 626 | Batch: 3 | Loss: 10.6406\n",
      "Epoch 626 | Batch: 4 | Loss: 10.9938\n",
      "Epoch 626 | Batch: 5 | Loss: 11.3325\n",
      "Mean of loss / batch 10.944583892822266\n",
      "Epoch 627 | Batch: 1 | Loss: 10.4071\n",
      "Epoch 627 | Batch: 2 | Loss: 11.3687\n",
      "Epoch 627 | Batch: 3 | Loss: 9.7689\n",
      "Epoch 627 | Batch: 4 | Loss: 12.0576\n",
      "Epoch 627 | Batch: 5 | Loss: 11.6708\n",
      "Mean of loss / batch 11.05463981628418\n",
      "Epoch 628 | Batch: 1 | Loss: 10.7401\n",
      "Epoch 628 | Batch: 2 | Loss: 10.4045\n",
      "Epoch 628 | Batch: 3 | Loss: 11.3704\n",
      "Epoch 628 | Batch: 4 | Loss: 10.3677\n",
      "Epoch 628 | Batch: 5 | Loss: 12.1774\n",
      "Mean of loss / batch 11.012001991271973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 629 | Batch: 1 | Loss: 11.1818\n",
      "Epoch 629 | Batch: 2 | Loss: 11.4918\n",
      "Epoch 629 | Batch: 3 | Loss: 10.9815\n",
      "Epoch 629 | Batch: 4 | Loss: 11.3347\n",
      "Epoch 629 | Batch: 5 | Loss: 10.5445\n",
      "Mean of loss / batch 11.106874465942383\n",
      "Epoch 630 | Batch: 1 | Loss: 10.9950\n",
      "Epoch 630 | Batch: 2 | Loss: 10.6335\n",
      "Epoch 630 | Batch: 3 | Loss: 10.6167\n",
      "Epoch 630 | Batch: 4 | Loss: 11.0119\n",
      "Epoch 630 | Batch: 5 | Loss: 11.3714\n",
      "Mean of loss / batch 10.92570686340332\n",
      "Epoch 631 | Batch: 1 | Loss: 10.3667\n",
      "Epoch 631 | Batch: 2 | Loss: 11.7872\n",
      "Epoch 631 | Batch: 3 | Loss: 10.9654\n",
      "Epoch 631 | Batch: 4 | Loss: 10.4416\n",
      "Epoch 631 | Batch: 5 | Loss: 11.3478\n",
      "Mean of loss / batch 10.981727600097656\n",
      "Epoch 632 | Batch: 1 | Loss: 11.2563\n",
      "Epoch 632 | Batch: 2 | Loss: 11.1971\n",
      "Epoch 632 | Batch: 3 | Loss: 10.7884\n",
      "Epoch 632 | Batch: 4 | Loss: 10.2202\n",
      "Epoch 632 | Batch: 5 | Loss: 11.4065\n",
      "Mean of loss / batch 10.973709106445312\n",
      "Epoch 633 | Batch: 1 | Loss: 10.9743\n",
      "Epoch 633 | Batch: 2 | Loss: 10.6644\n",
      "Epoch 633 | Batch: 3 | Loss: 10.2909\n",
      "Epoch 633 | Batch: 4 | Loss: 11.0255\n",
      "Epoch 633 | Batch: 5 | Loss: 11.7906\n",
      "Mean of loss / batch 10.949152946472168\n",
      "Epoch 634 | Batch: 1 | Loss: 10.4344\n",
      "Epoch 634 | Batch: 2 | Loss: 9.9012\n",
      "Epoch 634 | Batch: 3 | Loss: 12.5496\n",
      "Epoch 634 | Batch: 4 | Loss: 11.2634\n",
      "Epoch 634 | Batch: 5 | Loss: 10.9655\n",
      "Mean of loss / batch 11.022815704345703\n",
      "Epoch 635 | Batch: 1 | Loss: 10.7262\n",
      "Epoch 635 | Batch: 2 | Loss: 11.8429\n",
      "Epoch 635 | Batch: 3 | Loss: 11.2597\n",
      "Epoch 635 | Batch: 4 | Loss: 10.8690\n",
      "Epoch 635 | Batch: 5 | Loss: 10.4739\n",
      "Mean of loss / batch 11.034335136413574\n",
      "Epoch 636 | Batch: 1 | Loss: 10.9829\n",
      "Epoch 636 | Batch: 2 | Loss: 10.9766\n",
      "Epoch 636 | Batch: 3 | Loss: 11.2855\n",
      "Epoch 636 | Batch: 4 | Loss: 10.7141\n",
      "Epoch 636 | Batch: 5 | Loss: 10.6689\n",
      "Mean of loss / batch 10.925589561462402\n",
      "Epoch 637 | Batch: 1 | Loss: 10.6396\n",
      "Epoch 637 | Batch: 2 | Loss: 10.9943\n",
      "Epoch 637 | Batch: 3 | Loss: 10.6342\n",
      "Epoch 637 | Batch: 4 | Loss: 10.9977\n",
      "Epoch 637 | Batch: 5 | Loss: 11.3416\n",
      "Mean of loss / batch 10.921492576599121\n",
      "Epoch 638 | Batch: 1 | Loss: 9.5422\n",
      "Epoch 638 | Batch: 2 | Loss: 13.7559\n",
      "Epoch 638 | Batch: 3 | Loss: 10.9664\n",
      "Epoch 638 | Batch: 4 | Loss: 11.4264\n",
      "Epoch 638 | Batch: 5 | Loss: 10.5888\n",
      "Mean of loss / batch 11.255951881408691\n",
      "Epoch 639 | Batch: 1 | Loss: 11.5864\n",
      "Epoch 639 | Batch: 2 | Loss: 10.3813\n",
      "Epoch 639 | Batch: 3 | Loss: 11.3444\n",
      "Epoch 639 | Batch: 4 | Loss: 10.9675\n",
      "Epoch 639 | Batch: 5 | Loss: 10.6869\n",
      "Mean of loss / batch 10.993304252624512\n",
      "Epoch 640 | Batch: 1 | Loss: 10.9754\n",
      "Epoch 640 | Batch: 2 | Loss: 11.5915\n",
      "Epoch 640 | Batch: 3 | Loss: 10.3754\n",
      "Epoch 640 | Batch: 4 | Loss: 11.7053\n",
      "Epoch 640 | Batch: 5 | Loss: 10.4897\n",
      "Mean of loss / batch 11.027478218078613\n",
      "Epoch 641 | Batch: 1 | Loss: 9.2782\n",
      "Epoch 641 | Batch: 2 | Loss: 14.0305\n",
      "Epoch 641 | Batch: 3 | Loss: 10.7038\n",
      "Epoch 641 | Batch: 4 | Loss: 11.2811\n",
      "Epoch 641 | Batch: 5 | Loss: 10.7170\n",
      "Mean of loss / batch 11.202108383178711\n",
      "Epoch 642 | Batch: 1 | Loss: 11.2681\n",
      "Epoch 642 | Batch: 2 | Loss: 10.4865\n",
      "Epoch 642 | Batch: 3 | Loss: 10.6393\n",
      "Epoch 642 | Batch: 4 | Loss: 11.7426\n",
      "Epoch 642 | Batch: 5 | Loss: 10.7149\n",
      "Mean of loss / batch 10.97030258178711\n",
      "Epoch 643 | Batch: 1 | Loss: 10.9698\n",
      "Epoch 643 | Batch: 2 | Loss: 11.2588\n",
      "Epoch 643 | Batch: 3 | Loss: 10.9657\n",
      "Epoch 643 | Batch: 4 | Loss: 10.7289\n",
      "Epoch 643 | Batch: 5 | Loss: 10.6784\n",
      "Mean of loss / batch 10.920297622680664\n",
      "Epoch 644 | Batch: 1 | Loss: 10.3138\n",
      "Epoch 644 | Batch: 2 | Loss: 11.4343\n",
      "Epoch 644 | Batch: 3 | Loss: 10.9785\n",
      "Epoch 644 | Batch: 4 | Loss: 10.6558\n",
      "Epoch 644 | Batch: 5 | Loss: 11.3409\n",
      "Mean of loss / batch 10.944666862487793\n",
      "Epoch 645 | Batch: 1 | Loss: 11.5365\n",
      "Epoch 645 | Batch: 2 | Loss: 10.4413\n",
      "Epoch 645 | Batch: 3 | Loss: 10.6388\n",
      "Epoch 645 | Batch: 4 | Loss: 10.9948\n",
      "Epoch 645 | Batch: 5 | Loss: 11.3350\n",
      "Mean of loss / batch 10.989288330078125\n",
      "Epoch 646 | Batch: 1 | Loss: 10.9668\n",
      "Epoch 646 | Batch: 2 | Loss: 10.9662\n",
      "Epoch 646 | Batch: 3 | Loss: 10.9658\n",
      "Epoch 646 | Batch: 4 | Loss: 10.6987\n",
      "Epoch 646 | Batch: 5 | Loss: 10.9727\n",
      "Mean of loss / batch 10.91401481628418\n",
      "Epoch 647 | Batch: 1 | Loss: 10.6685\n",
      "Epoch 647 | Batch: 2 | Loss: 11.3227\n",
      "Epoch 647 | Batch: 3 | Loss: 10.9660\n",
      "Epoch 647 | Batch: 4 | Loss: 11.2352\n",
      "Epoch 647 | Batch: 5 | Loss: 10.5356\n",
      "Mean of loss / batch 10.945602416992188\n",
      "Epoch 648 | Batch: 1 | Loss: 10.9751\n",
      "Epoch 648 | Batch: 2 | Loss: 11.8982\n",
      "Epoch 648 | Batch: 3 | Loss: 10.6911\n",
      "Epoch 648 | Batch: 4 | Loss: 10.6974\n",
      "Epoch 648 | Batch: 5 | Loss: 10.6581\n",
      "Mean of loss / batch 10.983991622924805\n",
      "Epoch 649 | Batch: 1 | Loss: 11.3374\n",
      "Epoch 649 | Batch: 2 | Loss: 10.9670\n",
      "Epoch 649 | Batch: 3 | Loss: 10.9663\n",
      "Epoch 649 | Batch: 4 | Loss: 10.4228\n",
      "Epoch 649 | Batch: 5 | Loss: 10.9915\n",
      "Mean of loss / batch 10.936981201171875\n",
      "Epoch 650 | Batch: 1 | Loss: 10.9822\n",
      "Epoch 650 | Batch: 2 | Loss: 10.9761\n",
      "Epoch 650 | Batch: 3 | Loss: 10.3486\n",
      "Epoch 650 | Batch: 4 | Loss: 11.0082\n",
      "Epoch 650 | Batch: 5 | Loss: 11.3641\n",
      "Mean of loss / batch 10.93584156036377\n",
      "Epoch 651 | Batch: 1 | Loss: 10.0763\n",
      "Epoch 651 | Batch: 2 | Loss: 11.9105\n",
      "Epoch 651 | Batch: 3 | Loss: 11.2723\n",
      "Epoch 651 | Batch: 4 | Loss: 10.4807\n",
      "Epoch 651 | Batch: 5 | Loss: 11.3259\n",
      "Mean of loss / batch 11.013157844543457\n",
      "Epoch 652 | Batch: 1 | Loss: 11.5180\n",
      "Epoch 652 | Batch: 2 | Loss: 11.1488\n",
      "Epoch 652 | Batch: 3 | Loss: 10.7170\n",
      "Epoch 652 | Batch: 4 | Loss: 10.4460\n",
      "Epoch 652 | Batch: 5 | Loss: 10.9873\n",
      "Mean of loss / batch 10.963427543640137\n",
      "Epoch 653 | Batch: 1 | Loss: 10.6423\n",
      "Epoch 653 | Batch: 2 | Loss: 10.6224\n",
      "Epoch 653 | Batch: 3 | Loss: 11.4037\n",
      "Epoch 653 | Batch: 4 | Loss: 11.6114\n",
      "Epoch 653 | Batch: 5 | Loss: 10.5582\n",
      "Mean of loss / batch 10.967595100402832\n",
      "Epoch 654 | Batch: 1 | Loss: 11.6020\n",
      "Epoch 654 | Batch: 2 | Loss: 10.5655\n",
      "Epoch 654 | Batch: 3 | Loss: 10.6604\n",
      "Epoch 654 | Batch: 4 | Loss: 11.3341\n",
      "Epoch 654 | Batch: 5 | Loss: 10.6860\n",
      "Mean of loss / batch 10.969589233398438\n",
      "Epoch 655 | Batch: 1 | Loss: 11.9504\n",
      "Epoch 655 | Batch: 2 | Loss: 10.6603\n",
      "Epoch 655 | Batch: 3 | Loss: 10.9665\n",
      "Epoch 655 | Batch: 4 | Loss: 10.1466\n",
      "Epoch 655 | Batch: 5 | Loss: 11.4387\n",
      "Mean of loss / batch 11.032491683959961\n",
      "Epoch 656 | Batch: 1 | Loss: 10.6429\n",
      "Epoch 656 | Batch: 2 | Loss: 12.1014\n",
      "Epoch 656 | Batch: 3 | Loss: 10.7744\n",
      "Epoch 656 | Batch: 4 | Loss: 10.4504\n",
      "Epoch 656 | Batch: 5 | Loss: 10.9866\n",
      "Mean of loss / batch 10.991127014160156\n",
      "Epoch 657 | Batch: 1 | Loss: 10.6433\n",
      "Epoch 657 | Batch: 2 | Loss: 10.2539\n",
      "Epoch 657 | Batch: 3 | Loss: 11.0391\n",
      "Epoch 657 | Batch: 4 | Loss: 12.2384\n",
      "Epoch 657 | Batch: 5 | Loss: 10.7383\n",
      "Mean of loss / batch 10.982583045959473\n",
      "Epoch 658 | Batch: 1 | Loss: 10.6845\n",
      "Epoch 658 | Batch: 2 | Loss: 10.3234\n",
      "Epoch 658 | Batch: 3 | Loss: 11.0152\n",
      "Epoch 658 | Batch: 4 | Loss: 11.3781\n",
      "Epoch 658 | Batch: 5 | Loss: 11.2760\n",
      "Mean of loss / batch 10.935452461242676\n",
      "Epoch 659 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 659 | Batch: 2 | Loss: 10.4731\n",
      "Epoch 659 | Batch: 3 | Loss: 10.9830\n",
      "Epoch 659 | Batch: 4 | Loss: 10.9767\n",
      "Epoch 659 | Batch: 5 | Loss: 11.2858\n",
      "Mean of loss / batch 10.936732292175293\n",
      "Epoch 660 | Batch: 1 | Loss: 11.2161\n",
      "Epoch 660 | Batch: 2 | Loss: 11.1711\n",
      "Epoch 660 | Batch: 3 | Loss: 11.3032\n",
      "Epoch 660 | Batch: 4 | Loss: 10.7872\n",
      "Epoch 660 | Batch: 5 | Loss: 10.4390\n",
      "Mean of loss / batch 10.983338356018066\n",
      "Epoch 661 | Batch: 1 | Loss: 10.6277\n",
      "Epoch 661 | Batch: 2 | Loss: 12.1706\n",
      "Epoch 661 | Batch: 3 | Loss: 10.7555\n",
      "Epoch 661 | Batch: 4 | Loss: 10.6956\n",
      "Epoch 661 | Batch: 5 | Loss: 10.6569\n",
      "Mean of loss / batch 10.98124885559082\n",
      "Epoch 662 | Batch: 1 | Loss: 10.9856\n",
      "Epoch 662 | Batch: 2 | Loss: 9.9773\n",
      "Epoch 662 | Batch: 3 | Loss: 11.0561\n",
      "Epoch 662 | Batch: 4 | Loss: 10.5987\n",
      "Epoch 662 | Batch: 5 | Loss: 12.3613\n",
      "Mean of loss / batch 10.995790481567383\n",
      "Epoch 663 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 663 | Batch: 2 | Loss: 10.2025\n",
      "Epoch 663 | Batch: 3 | Loss: 10.6067\n",
      "Epoch 663 | Batch: 4 | Loss: 11.0232\n",
      "Epoch 663 | Batch: 5 | Loss: 12.1741\n",
      "Mean of loss / batch 10.99433708190918\n",
      "Epoch 664 | Batch: 1 | Loss: 10.3279\n",
      "Epoch 664 | Batch: 2 | Loss: 10.6222\n",
      "Epoch 664 | Batch: 3 | Loss: 10.6093\n",
      "Epoch 664 | Batch: 4 | Loss: 13.1151\n",
      "Epoch 664 | Batch: 5 | Loss: 10.8547\n",
      "Mean of loss / batch 11.1058349609375\n",
      "Epoch 665 | Batch: 1 | Loss: 10.9685\n",
      "Epoch 665 | Batch: 2 | Loss: 10.5323\n",
      "Epoch 665 | Batch: 3 | Loss: 10.3271\n",
      "Epoch 665 | Batch: 4 | Loss: 11.8340\n",
      "Epoch 665 | Batch: 5 | Loss: 11.2456\n",
      "Mean of loss / batch 10.98149299621582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666 | Batch: 1 | Loss: 11.4137\n",
      "Epoch 666 | Batch: 2 | Loss: 10.8655\n",
      "Epoch 666 | Batch: 3 | Loss: 10.7663\n",
      "Epoch 666 | Batch: 4 | Loss: 10.9653\n",
      "Epoch 666 | Batch: 5 | Loss: 10.7047\n",
      "Mean of loss / batch 10.943102836608887\n",
      "Epoch 667 | Batch: 1 | Loss: 10.9715\n",
      "Epoch 667 | Batch: 2 | Loss: 11.5641\n",
      "Epoch 667 | Batch: 3 | Loss: 11.1612\n",
      "Epoch 667 | Batch: 4 | Loss: 10.6833\n",
      "Epoch 667 | Batch: 5 | Loss: 10.4243\n",
      "Mean of loss / batch 10.96090030670166\n",
      "Epoch 668 | Batch: 1 | Loss: 12.0919\n",
      "Epoch 668 | Batch: 2 | Loss: 10.7771\n",
      "Epoch 668 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 668 | Batch: 4 | Loss: 10.7103\n",
      "Epoch 668 | Batch: 5 | Loss: 10.3624\n",
      "Mean of loss / batch 10.981343269348145\n",
      "Epoch 669 | Batch: 1 | Loss: 11.0047\n",
      "Epoch 669 | Batch: 2 | Loss: 11.3568\n",
      "Epoch 669 | Batch: 3 | Loss: 10.6749\n",
      "Epoch 669 | Batch: 4 | Loss: 10.9789\n",
      "Epoch 669 | Batch: 5 | Loss: 10.6551\n",
      "Mean of loss / batch 10.934075355529785\n",
      "Epoch 670 | Batch: 1 | Loss: 10.2751\n",
      "Epoch 670 | Batch: 2 | Loss: 11.4663\n",
      "Epoch 670 | Batch: 3 | Loss: 10.9839\n",
      "Epoch 670 | Batch: 4 | Loss: 11.6379\n",
      "Epoch 670 | Batch: 5 | Loss: 10.5379\n",
      "Mean of loss / batch 10.98023509979248\n",
      "Epoch 671 | Batch: 1 | Loss: 11.2969\n",
      "Epoch 671 | Batch: 2 | Loss: 10.4487\n",
      "Epoch 671 | Batch: 3 | Loss: 10.9868\n",
      "Epoch 671 | Batch: 4 | Loss: 10.6429\n",
      "Epoch 671 | Batch: 5 | Loss: 11.3620\n",
      "Mean of loss / batch 10.947488784790039\n",
      "Epoch 672 | Batch: 1 | Loss: 10.0795\n",
      "Epoch 672 | Batch: 2 | Loss: 11.0328\n",
      "Epoch 672 | Batch: 3 | Loss: 11.0091\n",
      "Epoch 672 | Batch: 4 | Loss: 10.9937\n",
      "Epoch 672 | Batch: 5 | Loss: 11.6809\n",
      "Mean of loss / batch 10.959183692932129\n",
      "Epoch 673 | Batch: 1 | Loss: 11.1956\n",
      "Epoch 673 | Batch: 2 | Loss: 10.7901\n",
      "Epoch 673 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 673 | Batch: 4 | Loss: 10.9650\n",
      "Epoch 673 | Batch: 5 | Loss: 10.7164\n",
      "Mean of loss / batch 10.926431655883789\n",
      "Epoch 674 | Batch: 1 | Loss: 10.0720\n",
      "Epoch 674 | Batch: 2 | Loss: 11.9139\n",
      "Epoch 674 | Batch: 3 | Loss: 10.6671\n",
      "Epoch 674 | Batch: 4 | Loss: 12.0107\n",
      "Epoch 674 | Batch: 5 | Loss: 10.6263\n",
      "Mean of loss / batch 11.057981491088867\n",
      "Epoch 675 | Batch: 1 | Loss: 10.9680\n",
      "Epoch 675 | Batch: 2 | Loss: 10.9669\n",
      "Epoch 675 | Batch: 3 | Loss: 11.2427\n",
      "Epoch 675 | Batch: 4 | Loss: 10.5238\n",
      "Epoch 675 | Batch: 5 | Loss: 10.9764\n",
      "Mean of loss / batch 10.935564041137695\n",
      "Epoch 676 | Batch: 1 | Loss: 10.3474\n",
      "Epoch 676 | Batch: 2 | Loss: 11.0085\n",
      "Epoch 676 | Batch: 3 | Loss: 11.3647\n",
      "Epoch 676 | Batch: 4 | Loss: 11.5653\n",
      "Epoch 676 | Batch: 5 | Loss: 10.5951\n",
      "Mean of loss / batch 10.976205825805664\n",
      "Epoch 677 | Batch: 1 | Loss: 10.9699\n",
      "Epoch 677 | Batch: 2 | Loss: 10.9682\n",
      "Epoch 677 | Batch: 3 | Loss: 10.4000\n",
      "Epoch 677 | Batch: 4 | Loss: 10.9960\n",
      "Epoch 677 | Batch: 5 | Loss: 11.3378\n",
      "Mean of loss / batch 10.934388160705566\n",
      "Epoch 678 | Batch: 1 | Loss: 11.2498\n",
      "Epoch 678 | Batch: 2 | Loss: 10.7396\n",
      "Epoch 678 | Batch: 3 | Loss: 11.2483\n",
      "Epoch 678 | Batch: 4 | Loss: 10.5152\n",
      "Epoch 678 | Batch: 5 | Loss: 10.9774\n",
      "Mean of loss / batch 10.94605827331543\n",
      "Epoch 679 | Batch: 1 | Loss: 10.3428\n",
      "Epoch 679 | Batch: 2 | Loss: 11.0098\n",
      "Epoch 679 | Batch: 3 | Loss: 10.9941\n",
      "Epoch 679 | Batch: 4 | Loss: 11.6826\n",
      "Epoch 679 | Batch: 5 | Loss: 10.7357\n",
      "Mean of loss / batch 10.952997207641602\n",
      "Epoch 680 | Batch: 1 | Loss: 11.5359\n",
      "Epoch 680 | Batch: 2 | Loss: 10.9757\n",
      "Epoch 680 | Batch: 3 | Loss: 10.7795\n",
      "Epoch 680 | Batch: 4 | Loss: 11.2191\n",
      "Epoch 680 | Batch: 5 | Loss: 10.3590\n",
      "Mean of loss / batch 10.973838806152344\n",
      "Epoch 681 | Batch: 1 | Loss: 12.0782\n",
      "Epoch 681 | Batch: 2 | Loss: 10.7810\n",
      "Epoch 681 | Batch: 3 | Loss: 10.4590\n",
      "Epoch 681 | Batch: 4 | Loss: 11.3379\n",
      "Epoch 681 | Batch: 5 | Loss: 10.4012\n",
      "Mean of loss / batch 11.01147174835205\n",
      "Epoch 682 | Batch: 1 | Loss: 11.3725\n",
      "Epoch 682 | Batch: 2 | Loss: 9.4590\n",
      "Epoch 682 | Batch: 3 | Loss: 11.1291\n",
      "Epoch 682 | Batch: 4 | Loss: 10.5861\n",
      "Epoch 682 | Batch: 5 | Loss: 13.0406\n",
      "Mean of loss / batch 11.117457389831543\n",
      "Epoch 683 | Batch: 1 | Loss: 11.6992\n",
      "Epoch 683 | Batch: 2 | Loss: 11.0128\n",
      "Epoch 683 | Batch: 3 | Loss: 10.3616\n",
      "Epoch 683 | Batch: 4 | Loss: 11.8121\n",
      "Epoch 683 | Batch: 5 | Loss: 10.6936\n",
      "Mean of loss / batch 11.115860939025879\n",
      "Epoch 684 | Batch: 1 | Loss: 10.3375\n",
      "Epoch 684 | Batch: 2 | Loss: 11.8213\n",
      "Epoch 684 | Batch: 3 | Loss: 10.4159\n",
      "Epoch 684 | Batch: 4 | Loss: 11.3633\n",
      "Epoch 684 | Batch: 5 | Loss: 10.9692\n",
      "Mean of loss / batch 10.981425285339355\n",
      "Epoch 685 | Batch: 1 | Loss: 10.9677\n",
      "Epoch 685 | Batch: 2 | Loss: 10.1239\n",
      "Epoch 685 | Batch: 3 | Loss: 10.5989\n",
      "Epoch 685 | Batch: 4 | Loss: 11.0355\n",
      "Epoch 685 | Batch: 5 | Loss: 12.2244\n",
      "Mean of loss / batch 10.99006462097168\n",
      "Epoch 686 | Batch: 1 | Loss: 10.2924\n",
      "Epoch 686 | Batch: 2 | Loss: 11.3773\n",
      "Epoch 686 | Batch: 3 | Loss: 11.5803\n",
      "Epoch 686 | Batch: 4 | Loss: 10.9714\n",
      "Epoch 686 | Batch: 5 | Loss: 10.7636\n",
      "Mean of loss / batch 10.99700927734375\n",
      "Epoch 687 | Batch: 1 | Loss: 10.1715\n",
      "Epoch 687 | Batch: 2 | Loss: 11.4275\n",
      "Epoch 687 | Batch: 3 | Loss: 10.6467\n",
      "Epoch 687 | Batch: 4 | Loss: 11.7208\n",
      "Epoch 687 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 10.986324310302734\n",
      "Epoch 688 | Batch: 1 | Loss: 11.9435\n",
      "Epoch 688 | Batch: 2 | Loss: 11.1405\n",
      "Epoch 688 | Batch: 3 | Loss: 11.1305\n",
      "Epoch 688 | Batch: 4 | Loss: 10.2928\n",
      "Epoch 688 | Batch: 5 | Loss: 11.0152\n",
      "Mean of loss / batch 11.10450553894043\n",
      "Epoch 689 | Batch: 1 | Loss: 12.1388\n",
      "Epoch 689 | Batch: 2 | Loss: 10.5588\n",
      "Epoch 689 | Batch: 3 | Loss: 10.3442\n",
      "Epoch 689 | Batch: 4 | Loss: 10.2055\n",
      "Epoch 689 | Batch: 5 | Loss: 12.0057\n",
      "Mean of loss / batch 11.050580978393555\n",
      "Epoch 690 | Batch: 1 | Loss: 11.3070\n",
      "Epoch 690 | Batch: 2 | Loss: 10.9654\n",
      "Epoch 690 | Batch: 3 | Loss: 11.4890\n",
      "Epoch 690 | Batch: 4 | Loss: 10.3424\n",
      "Epoch 690 | Batch: 5 | Loss: 10.9964\n",
      "Mean of loss / batch 11.02001953125\n",
      "Epoch 691 | Batch: 1 | Loss: 10.6322\n",
      "Epoch 691 | Batch: 2 | Loss: 11.3824\n",
      "Epoch 691 | Batch: 3 | Loss: 11.5864\n",
      "Epoch 691 | Batch: 4 | Loss: 10.7744\n",
      "Epoch 691 | Batch: 5 | Loss: 10.4504\n",
      "Mean of loss / batch 10.96514892578125\n",
      "Epoch 692 | Batch: 1 | Loss: 10.9866\n",
      "Epoch 692 | Batch: 2 | Loss: 9.9720\n",
      "Epoch 692 | Batch: 3 | Loss: 10.5883\n",
      "Epoch 692 | Batch: 4 | Loss: 12.0182\n",
      "Epoch 692 | Batch: 5 | Loss: 11.3116\n",
      "Mean of loss / batch 10.975324630737305\n",
      "Epoch 693 | Batch: 1 | Loss: 10.9655\n",
      "Epoch 693 | Batch: 2 | Loss: 11.2295\n",
      "Epoch 693 | Batch: 3 | Loss: 10.7565\n",
      "Epoch 693 | Batch: 4 | Loss: 10.6962\n",
      "Epoch 693 | Batch: 5 | Loss: 10.9732\n",
      "Mean of loss / batch 10.924193382263184\n",
      "Epoch 694 | Batch: 1 | Loss: 10.9703\n",
      "Epoch 694 | Batch: 2 | Loss: 10.6754\n",
      "Epoch 694 | Batch: 3 | Loss: 10.3090\n",
      "Epoch 694 | Batch: 4 | Loss: 11.8566\n",
      "Epoch 694 | Batch: 5 | Loss: 10.9674\n",
      "Mean of loss / batch 10.955747604370117\n",
      "Epoch 695 | Batch: 1 | Loss: 11.8041\n",
      "Epoch 695 | Batch: 2 | Loss: 10.6261\n",
      "Epoch 695 | Batch: 3 | Loss: 11.5675\n",
      "Epoch 695 | Batch: 4 | Loss: 10.7829\n",
      "Epoch 695 | Batch: 5 | Loss: 10.4614\n",
      "Mean of loss / batch 11.048397064208984\n",
      "Epoch 696 | Batch: 1 | Loss: 11.6882\n",
      "Epoch 696 | Batch: 2 | Loss: 11.4299\n",
      "Epoch 696 | Batch: 3 | Loss: 10.8555\n",
      "Epoch 696 | Batch: 4 | Loss: 10.5511\n",
      "Epoch 696 | Batch: 5 | Loss: 10.3392\n",
      "Mean of loss / batch 10.972803115844727\n",
      "Epoch 697 | Batch: 1 | Loss: 11.4150\n",
      "Epoch 697 | Batch: 2 | Loss: 10.9755\n",
      "Epoch 697 | Batch: 3 | Loss: 11.5921\n",
      "Epoch 697 | Batch: 4 | Loss: 10.5733\n",
      "Epoch 697 | Batch: 5 | Loss: 10.3535\n",
      "Mean of loss / batch 10.981890678405762\n",
      "Epoch 698 | Batch: 1 | Loss: 11.4046\n",
      "Epoch 698 | Batch: 2 | Loss: 11.6125\n",
      "Epoch 698 | Batch: 3 | Loss: 10.3514\n",
      "Epoch 698 | Batch: 4 | Loss: 10.2606\n",
      "Epoch 698 | Batch: 5 | Loss: 11.4791\n",
      "Mean of loss / batch 11.02164077758789\n",
      "Epoch 699 | Batch: 1 | Loss: 11.6975\n",
      "Epoch 699 | Batch: 2 | Loss: 11.2007\n",
      "Epoch 699 | Batch: 3 | Loss: 10.5961\n",
      "Epoch 699 | Batch: 4 | Loss: 11.5715\n",
      "Epoch 699 | Batch: 5 | Loss: 10.2078\n",
      "Mean of loss / batch 11.054710388183594\n",
      "Epoch 700 | Batch: 1 | Loss: 12.2190\n",
      "Epoch 700 | Batch: 2 | Loss: 10.0727\n",
      "Epoch 700 | Batch: 3 | Loss: 10.5977\n",
      "Epoch 700 | Batch: 4 | Loss: 11.4822\n",
      "Epoch 700 | Batch: 5 | Loss: 10.9869\n",
      "Mean of loss / batch 11.071691513061523\n",
      "Epoch 701 | Batch: 1 | Loss: 11.9883\n",
      "Epoch 701 | Batch: 2 | Loss: 11.4873\n",
      "Epoch 701 | Batch: 3 | Loss: 10.8778\n",
      "Epoch 701 | Batch: 4 | Loss: 11.3054\n",
      "Epoch 701 | Batch: 5 | Loss: 10.1747\n",
      "Mean of loss / batch 11.166717529296875\n",
      "Epoch 702 | Batch: 1 | Loss: 10.1927\n",
      "Epoch 702 | Batch: 2 | Loss: 11.5469\n",
      "Epoch 702 | Batch: 3 | Loss: 11.0004\n",
      "Epoch 702 | Batch: 4 | Loss: 11.3476\n",
      "Epoch 702 | Batch: 5 | Loss: 10.6793\n",
      "Mean of loss / batch 10.953373908996582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703 | Batch: 1 | Loss: 10.3152\n",
      "Epoch 703 | Batch: 2 | Loss: 11.4332\n",
      "Epoch 703 | Batch: 3 | Loss: 10.3111\n",
      "Epoch 703 | Batch: 4 | Loss: 10.6015\n",
      "Epoch 703 | Batch: 5 | Loss: 12.3365\n",
      "Mean of loss / batch 10.999510765075684\n",
      "Epoch 704 | Batch: 1 | Loss: 10.9650\n",
      "Epoch 704 | Batch: 2 | Loss: 10.7152\n",
      "Epoch 704 | Batch: 3 | Loss: 11.5700\n",
      "Epoch 704 | Batch: 4 | Loss: 10.5912\n",
      "Epoch 704 | Batch: 5 | Loss: 10.9702\n",
      "Mean of loss / batch 10.96231746673584\n",
      "Epoch 705 | Batch: 1 | Loss: 10.6759\n",
      "Epoch 705 | Batch: 2 | Loss: 10.9786\n",
      "Epoch 705 | Batch: 3 | Loss: 10.3375\n",
      "Epoch 705 | Batch: 4 | Loss: 11.4163\n",
      "Epoch 705 | Batch: 5 | Loss: 11.3009\n",
      "Mean of loss / batch 10.941808700561523\n",
      "Epoch 706 | Batch: 1 | Loss: 10.7045\n",
      "Epoch 706 | Batch: 2 | Loss: 10.9715\n",
      "Epoch 706 | Batch: 3 | Loss: 11.8619\n",
      "Epoch 706 | Batch: 4 | Loss: 10.2978\n",
      "Epoch 706 | Batch: 5 | Loss: 11.8364\n",
      "Mean of loss / batch 11.134427070617676\n",
      "Epoch 707 | Batch: 1 | Loss: 10.1272\n",
      "Epoch 707 | Batch: 2 | Loss: 11.8718\n",
      "Epoch 707 | Batch: 3 | Loss: 10.6775\n",
      "Epoch 707 | Batch: 4 | Loss: 10.3123\n",
      "Epoch 707 | Batch: 5 | Loss: 12.2694\n",
      "Mean of loss / batch 11.05162239074707\n",
      "Epoch 708 | Batch: 1 | Loss: 11.6697\n",
      "Epoch 708 | Batch: 2 | Loss: 11.1938\n",
      "Epoch 708 | Batch: 3 | Loss: 10.9892\n",
      "Epoch 708 | Batch: 4 | Loss: 10.6991\n",
      "Epoch 708 | Batch: 5 | Loss: 10.6592\n",
      "Mean of loss / batch 11.042218208312988\n",
      "Epoch 709 | Batch: 1 | Loss: 12.0382\n",
      "Epoch 709 | Batch: 2 | Loss: 10.2479\n",
      "Epoch 709 | Batch: 3 | Loss: 10.6102\n",
      "Epoch 709 | Batch: 4 | Loss: 10.6015\n",
      "Epoch 709 | Batch: 5 | Loss: 11.9011\n",
      "Mean of loss / batch 11.079778671264648\n",
      "Epoch 710 | Batch: 1 | Loss: 9.7719\n",
      "Epoch 710 | Batch: 2 | Loss: 11.5658\n",
      "Epoch 710 | Batch: 3 | Loss: 11.0048\n",
      "Epoch 710 | Batch: 4 | Loss: 10.9908\n",
      "Epoch 710 | Batch: 5 | Loss: 11.6692\n",
      "Mean of loss / batch 11.000494956970215\n",
      "Epoch 711 | Batch: 1 | Loss: 10.7407\n",
      "Epoch 711 | Batch: 2 | Loss: 10.6860\n",
      "Epoch 711 | Batch: 3 | Loss: 10.3258\n",
      "Epoch 711 | Batch: 4 | Loss: 11.4250\n",
      "Epoch 711 | Batch: 5 | Loss: 11.6361\n",
      "Mean of loss / batch 10.962736129760742\n",
      "Epoch 712 | Batch: 1 | Loss: 10.9677\n",
      "Epoch 712 | Batch: 2 | Loss: 11.6314\n",
      "Epoch 712 | Batch: 3 | Loss: 10.8701\n",
      "Epoch 712 | Batch: 4 | Loss: 10.7561\n",
      "Epoch 712 | Batch: 5 | Loss: 10.6960\n",
      "Mean of loss / batch 10.984273910522461\n",
      "Epoch 713 | Batch: 1 | Loss: 10.6572\n",
      "Epoch 713 | Batch: 2 | Loss: 10.6321\n",
      "Epoch 713 | Batch: 3 | Loss: 11.7661\n",
      "Epoch 713 | Batch: 4 | Loss: 11.2228\n",
      "Epoch 713 | Batch: 5 | Loss: 10.5561\n",
      "Mean of loss / batch 10.96684455871582\n",
      "Epoch 714 | Batch: 1 | Loss: 10.6578\n",
      "Epoch 714 | Batch: 2 | Loss: 10.2797\n",
      "Epoch 714 | Batch: 3 | Loss: 11.0294\n",
      "Epoch 714 | Batch: 4 | Loss: 11.4046\n",
      "Epoch 714 | Batch: 5 | Loss: 11.2932\n",
      "Mean of loss / batch 10.932929992675781\n",
      "Epoch 715 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 715 | Batch: 2 | Loss: 10.2001\n",
      "Epoch 715 | Batch: 3 | Loss: 11.0107\n",
      "Epoch 715 | Batch: 4 | Loss: 11.3692\n",
      "Epoch 715 | Batch: 5 | Loss: 11.2702\n",
      "Mean of loss / batch 10.963075637817383\n",
      "Epoch 716 | Batch: 1 | Loss: 11.2061\n",
      "Epoch 716 | Batch: 2 | Loss: 10.9718\n",
      "Epoch 716 | Batch: 3 | Loss: 11.1738\n",
      "Epoch 716 | Batch: 4 | Loss: 10.6528\n",
      "Epoch 716 | Batch: 5 | Loss: 10.6857\n",
      "Mean of loss / batch 10.938036918640137\n",
      "Epoch 717 | Batch: 1 | Loss: 10.9757\n",
      "Epoch 717 | Batch: 2 | Loss: 10.6612\n",
      "Epoch 717 | Batch: 3 | Loss: 11.3328\n",
      "Epoch 717 | Batch: 4 | Loss: 10.4067\n",
      "Epoch 717 | Batch: 5 | Loss: 11.3690\n",
      "Mean of loss / batch 10.949101448059082\n",
      "Epoch 718 | Batch: 1 | Loss: 11.5704\n",
      "Epoch 718 | Batch: 2 | Loss: 10.5909\n",
      "Epoch 718 | Batch: 3 | Loss: 11.2729\n",
      "Epoch 718 | Batch: 4 | Loss: 10.9652\n",
      "Epoch 718 | Batch: 5 | Loss: 10.4765\n",
      "Mean of loss / batch 10.975162506103516\n",
      "Epoch 719 | Batch: 1 | Loss: 10.9825\n",
      "Epoch 719 | Batch: 2 | Loss: 11.3036\n",
      "Epoch 719 | Batch: 3 | Loss: 10.9653\n",
      "Epoch 719 | Batch: 4 | Loss: 10.7050\n",
      "Epoch 719 | Batch: 5 | Loss: 10.6630\n",
      "Mean of loss / batch 10.92386245727539\n",
      "Epoch 720 | Batch: 1 | Loss: 10.9831\n",
      "Epoch 720 | Batch: 2 | Loss: 9.9913\n",
      "Epoch 720 | Batch: 3 | Loss: 11.0526\n",
      "Epoch 720 | Batch: 4 | Loss: 11.0221\n",
      "Epoch 720 | Batch: 5 | Loss: 11.7803\n",
      "Mean of loss / batch 10.965883255004883\n",
      "Epoch 721 | Batch: 1 | Loss: 10.7030\n",
      "Epoch 721 | Batch: 2 | Loss: 11.5920\n",
      "Epoch 721 | Batch: 3 | Loss: 10.9705\n",
      "Epoch 721 | Batch: 4 | Loss: 10.5506\n",
      "Epoch 721 | Batch: 5 | Loss: 10.9736\n",
      "Mean of loss / batch 10.957942962646484\n",
      "Epoch 722 | Batch: 1 | Loss: 11.8837\n",
      "Epoch 722 | Batch: 2 | Loss: 10.9878\n",
      "Epoch 722 | Batch: 3 | Loss: 10.6492\n",
      "Epoch 722 | Batch: 4 | Loss: 11.2492\n",
      "Epoch 722 | Batch: 5 | Loss: 10.2877\n",
      "Mean of loss / batch 11.011526107788086\n",
      "Epoch 723 | Batch: 1 | Loss: 10.9980\n",
      "Epoch 723 | Batch: 2 | Loss: 10.6306\n",
      "Epoch 723 | Batch: 3 | Loss: 11.0002\n",
      "Epoch 723 | Batch: 4 | Loss: 11.3471\n",
      "Epoch 723 | Batch: 5 | Loss: 10.6795\n",
      "Mean of loss / batch 10.93109130859375\n",
      "Epoch 724 | Batch: 1 | Loss: 9.6537\n",
      "Epoch 724 | Batch: 2 | Loss: 11.1004\n",
      "Epoch 724 | Batch: 3 | Loss: 11.5180\n",
      "Epoch 724 | Batch: 4 | Loss: 11.7406\n",
      "Epoch 724 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 10.995559692382812\n",
      "Epoch 725 | Batch: 1 | Loss: 10.7152\n",
      "Epoch 725 | Batch: 2 | Loss: 11.2698\n",
      "Epoch 725 | Batch: 3 | Loss: 10.9653\n",
      "Epoch 725 | Batch: 4 | Loss: 10.7225\n",
      "Epoch 725 | Batch: 5 | Loss: 10.9687\n",
      "Mean of loss / batch 10.928295135498047\n",
      "Epoch 726 | Batch: 1 | Loss: 11.8251\n",
      "Epoch 726 | Batch: 2 | Loss: 10.6072\n",
      "Epoch 726 | Batch: 3 | Loss: 11.5770\n",
      "Epoch 726 | Batch: 4 | Loss: 10.9717\n",
      "Epoch 726 | Batch: 5 | Loss: 10.3555\n",
      "Mean of loss / batch 11.067300796508789\n",
      "Epoch 727 | Batch: 1 | Loss: 10.9898\n",
      "Epoch 727 | Batch: 2 | Loss: 10.6392\n",
      "Epoch 727 | Batch: 3 | Loss: 11.3687\n",
      "Epoch 727 | Batch: 4 | Loss: 11.5701\n",
      "Epoch 727 | Batch: 5 | Loss: 10.4005\n",
      "Mean of loss / batch 10.993678092956543\n",
      "Epoch 728 | Batch: 1 | Loss: 10.9851\n",
      "Epoch 728 | Batch: 2 | Loss: 11.6436\n",
      "Epoch 728 | Batch: 3 | Loss: 11.1842\n",
      "Epoch 728 | Batch: 4 | Loss: 10.8033\n",
      "Epoch 728 | Batch: 5 | Loss: 10.2483\n",
      "Mean of loss / batch 10.972917556762695\n",
      "Epoch 729 | Batch: 1 | Loss: 11.7863\n",
      "Epoch 729 | Batch: 2 | Loss: 10.7012\n",
      "Epoch 729 | Batch: 3 | Loss: 11.2838\n",
      "Epoch 729 | Batch: 4 | Loss: 10.7152\n",
      "Epoch 729 | Batch: 5 | Loss: 10.3695\n",
      "Mean of loss / batch 10.971209526062012\n",
      "Epoch 730 | Batch: 1 | Loss: 10.6124\n",
      "Epoch 730 | Batch: 2 | Loss: 10.1896\n",
      "Epoch 730 | Batch: 3 | Loss: 10.1047\n",
      "Epoch 730 | Batch: 4 | Loss: 12.7356\n",
      "Epoch 730 | Batch: 5 | Loss: 11.3103\n",
      "Mean of loss / batch 10.990513801574707\n",
      "Epoch 731 | Batch: 1 | Loss: 10.6990\n",
      "Epoch 731 | Batch: 2 | Loss: 10.6591\n",
      "Epoch 731 | Batch: 3 | Loss: 11.3359\n",
      "Epoch 731 | Batch: 4 | Loss: 11.2486\n",
      "Epoch 731 | Batch: 5 | Loss: 10.7405\n",
      "Mean of loss / batch 10.936635971069336\n",
      "Epoch 732 | Batch: 1 | Loss: 11.5284\n",
      "Epoch 732 | Batch: 2 | Loss: 10.8015\n",
      "Epoch 732 | Batch: 3 | Loss: 10.7252\n",
      "Epoch 732 | Batch: 4 | Loss: 10.6760\n",
      "Epoch 732 | Batch: 5 | Loss: 10.9785\n",
      "Mean of loss / batch 10.941917419433594\n",
      "Epoch 733 | Batch: 1 | Loss: 10.6557\n",
      "Epoch 733 | Batch: 2 | Loss: 10.9861\n",
      "Epoch 733 | Batch: 3 | Loss: 10.6440\n",
      "Epoch 733 | Batch: 4 | Loss: 10.9919\n",
      "Epoch 733 | Batch: 5 | Loss: 11.3279\n",
      "Mean of loss / batch 10.921116828918457\n",
      "Epoch 734 | Batch: 1 | Loss: 11.2434\n",
      "Epoch 734 | Batch: 2 | Loss: 10.3006\n",
      "Epoch 734 | Batch: 3 | Loss: 12.1298\n",
      "Epoch 734 | Batch: 4 | Loss: 10.7665\n",
      "Epoch 734 | Batch: 5 | Loss: 10.7026\n",
      "Mean of loss / batch 11.028586387634277\n",
      "Epoch 735 | Batch: 1 | Loss: 11.5927\n",
      "Epoch 735 | Batch: 2 | Loss: 11.3681\n",
      "Epoch 735 | Batch: 3 | Loss: 10.8958\n",
      "Epoch 735 | Batch: 4 | Loss: 10.9731\n",
      "Epoch 735 | Batch: 5 | Loss: 10.1702\n",
      "Mean of loss / batch 10.999982833862305\n",
      "Epoch 736 | Batch: 1 | Loss: 11.4245\n",
      "Epoch 736 | Batch: 2 | Loss: 11.6354\n",
      "Epoch 736 | Batch: 3 | Loss: 10.9678\n",
      "Epoch 736 | Batch: 4 | Loss: 10.5241\n",
      "Epoch 736 | Batch: 5 | Loss: 10.3218\n",
      "Mean of loss / batch 10.974717140197754\n",
      "Epoch 737 | Batch: 1 | Loss: 10.6033\n",
      "Epoch 737 | Batch: 2 | Loss: 11.0281\n",
      "Epoch 737 | Batch: 3 | Loss: 11.4022\n",
      "Epoch 737 | Batch: 4 | Loss: 10.9737\n",
      "Epoch 737 | Batch: 5 | Loss: 10.6658\n",
      "Mean of loss / batch 10.934625625610352\n",
      "Epoch 738 | Batch: 1 | Loss: 11.6708\n",
      "Epoch 738 | Batch: 2 | Loss: 10.7401\n",
      "Epoch 738 | Batch: 3 | Loss: 10.4045\n",
      "Epoch 738 | Batch: 4 | Loss: 11.7456\n",
      "Epoch 738 | Batch: 5 | Loss: 10.4629\n",
      "Mean of loss / batch 11.004776000976562\n",
      "Epoch 739 | Batch: 1 | Loss: 11.6868\n",
      "Epoch 739 | Batch: 2 | Loss: 10.7342\n",
      "Epoch 739 | Batch: 3 | Loss: 10.6818\n",
      "Epoch 739 | Batch: 4 | Loss: 11.3056\n",
      "Epoch 739 | Batch: 5 | Loss: 10.4381\n",
      "Mean of loss / batch 10.96929931640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740 | Batch: 1 | Loss: 10.9887\n",
      "Epoch 740 | Batch: 2 | Loss: 10.6406\n",
      "Epoch 740 | Batch: 3 | Loss: 9.8765\n",
      "Epoch 740 | Batch: 4 | Loss: 11.0841\n",
      "Epoch 740 | Batch: 5 | Loss: 12.3960\n",
      "Mean of loss / batch 10.997157096862793\n",
      "Epoch 741 | Batch: 1 | Loss: 11.2276\n",
      "Epoch 741 | Batch: 2 | Loss: 11.1785\n",
      "Epoch 741 | Batch: 3 | Loss: 10.3055\n",
      "Epoch 741 | Batch: 4 | Loss: 11.3846\n",
      "Epoch 741 | Batch: 5 | Loss: 10.9715\n",
      "Mean of loss / batch 11.013532638549805\n",
      "Epoch 742 | Batch: 1 | Loss: 10.6718\n",
      "Epoch 742 | Batch: 2 | Loss: 11.9951\n",
      "Epoch 742 | Batch: 3 | Loss: 10.6349\n",
      "Epoch 742 | Batch: 4 | Loss: 10.3932\n",
      "Epoch 742 | Batch: 5 | Loss: 11.3776\n",
      "Mean of loss / batch 11.014525413513184\n",
      "Epoch 743 | Batch: 1 | Loss: 10.9707\n",
      "Epoch 743 | Batch: 2 | Loss: 10.9687\n",
      "Epoch 743 | Batch: 3 | Loss: 10.6814\n",
      "Epoch 743 | Batch: 4 | Loss: 10.3186\n",
      "Epoch 743 | Batch: 5 | Loss: 11.8446\n",
      "Mean of loss / batch 10.95677661895752\n",
      "Epoch 744 | Batch: 1 | Loss: 10.4023\n",
      "Epoch 744 | Batch: 2 | Loss: 10.9956\n",
      "Epoch 744 | Batch: 3 | Loss: 10.9848\n",
      "Epoch 744 | Batch: 4 | Loss: 12.3067\n",
      "Epoch 744 | Batch: 5 | Loss: 10.6520\n",
      "Mean of loss / batch 11.068262100219727\n",
      "Epoch 745 | Batch: 1 | Loss: 10.6753\n",
      "Epoch 745 | Batch: 2 | Loss: 10.9787\n",
      "Epoch 745 | Batch: 3 | Loss: 10.9739\n",
      "Epoch 745 | Batch: 4 | Loss: 11.2761\n",
      "Epoch 745 | Batch: 5 | Loss: 10.7203\n",
      "Mean of loss / batch 10.924891471862793\n",
      "Epoch 746 | Batch: 1 | Loss: 10.9690\n",
      "Epoch 746 | Batch: 2 | Loss: 11.2548\n",
      "Epoch 746 | Batch: 3 | Loss: 11.1961\n",
      "Epoch 746 | Batch: 4 | Loss: 10.7895\n",
      "Epoch 746 | Batch: 5 | Loss: 10.4699\n",
      "Mean of loss / batch 10.9358549118042\n",
      "Epoch 747 | Batch: 1 | Loss: 12.0285\n",
      "Epoch 747 | Batch: 2 | Loss: 10.9752\n",
      "Epoch 747 | Batch: 3 | Loss: 10.5844\n",
      "Epoch 747 | Batch: 4 | Loss: 10.0557\n",
      "Epoch 747 | Batch: 5 | Loss: 11.4822\n",
      "Mean of loss / batch 11.02522087097168\n",
      "Epoch 748 | Batch: 1 | Loss: 11.3439\n",
      "Epoch 748 | Batch: 2 | Loss: 11.5401\n",
      "Epoch 748 | Batch: 3 | Loss: 10.4368\n",
      "Epoch 748 | Batch: 4 | Loss: 11.3254\n",
      "Epoch 748 | Batch: 5 | Loss: 10.4150\n",
      "Mean of loss / batch 11.012252807617188\n",
      "Epoch 749 | Batch: 1 | Loss: 11.3638\n",
      "Epoch 749 | Batch: 2 | Loss: 10.6717\n",
      "Epoch 749 | Batch: 3 | Loss: 10.6415\n",
      "Epoch 749 | Batch: 4 | Loss: 10.2505\n",
      "Epoch 749 | Batch: 5 | Loss: 11.9363\n",
      "Mean of loss / batch 10.972763061523438\n",
      "Epoch 750 | Batch: 1 | Loss: 10.9718\n",
      "Epoch 750 | Batch: 2 | Loss: 10.6710\n",
      "Epoch 750 | Batch: 3 | Loss: 9.9628\n",
      "Epoch 750 | Batch: 4 | Loss: 11.0598\n",
      "Epoch 750 | Batch: 5 | Loss: 12.3146\n",
      "Mean of loss / batch 10.99599552154541\n",
      "Epoch 751 | Batch: 1 | Loss: 10.7204\n",
      "Epoch 751 | Batch: 2 | Loss: 10.3769\n",
      "Epoch 751 | Batch: 3 | Loss: 11.0012\n",
      "Epoch 751 | Batch: 4 | Loss: 11.3492\n",
      "Epoch 751 | Batch: 5 | Loss: 11.2572\n",
      "Mean of loss / batch 10.940994262695312\n",
      "Epoch 752 | Batch: 1 | Loss: 10.7339\n",
      "Epoch 752 | Batch: 2 | Loss: 10.6816\n",
      "Epoch 752 | Batch: 3 | Loss: 10.9769\n",
      "Epoch 752 | Batch: 4 | Loss: 10.9727\n",
      "Epoch 752 | Batch: 5 | Loss: 11.2715\n",
      "Mean of loss / batch 10.927308082580566\n",
      "Epoch 753 | Batch: 1 | Loss: 10.7235\n",
      "Epoch 753 | Batch: 2 | Loss: 10.9685\n",
      "Epoch 753 | Batch: 3 | Loss: 10.3968\n",
      "Epoch 753 | Batch: 4 | Loss: 10.6181\n",
      "Epoch 753 | Batch: 5 | Loss: 12.2218\n",
      "Mean of loss / batch 10.985748291015625\n",
      "Epoch 754 | Batch: 1 | Loss: 11.1906\n",
      "Epoch 754 | Batch: 2 | Loss: 10.4368\n",
      "Epoch 754 | Batch: 3 | Loss: 11.3254\n",
      "Epoch 754 | Batch: 4 | Loss: 10.9662\n",
      "Epoch 754 | Batch: 5 | Loss: 10.9658\n",
      "Mean of loss / batch 10.976957321166992\n",
      "Epoch 755 | Batch: 1 | Loss: 10.9655\n",
      "Epoch 755 | Batch: 2 | Loss: 11.7571\n",
      "Epoch 755 | Batch: 3 | Loss: 10.7809\n",
      "Epoch 755 | Batch: 4 | Loss: 10.2478\n",
      "Epoch 755 | Batch: 5 | Loss: 11.3951\n",
      "Mean of loss / batch 11.029266357421875\n",
      "Epoch 756 | Batch: 1 | Loss: 11.2870\n",
      "Epoch 756 | Batch: 2 | Loss: 10.2093\n",
      "Epoch 756 | Batch: 3 | Loss: 11.4111\n",
      "Epoch 756 | Batch: 4 | Loss: 11.6200\n",
      "Epoch 756 | Batch: 5 | Loss: 10.5515\n",
      "Mean of loss / batch 11.01578426361084\n",
      "Epoch 757 | Batch: 1 | Loss: 10.3395\n",
      "Epoch 757 | Batch: 2 | Loss: 11.4148\n",
      "Epoch 757 | Batch: 3 | Loss: 10.9755\n",
      "Epoch 757 | Batch: 4 | Loss: 10.9718\n",
      "Epoch 757 | Batch: 5 | Loss: 10.9694\n",
      "Mean of loss / batch 10.934202194213867\n",
      "Epoch 758 | Batch: 1 | Loss: 11.2571\n",
      "Epoch 758 | Batch: 2 | Loss: 11.1976\n",
      "Epoch 758 | Batch: 3 | Loss: 10.6022\n",
      "Epoch 758 | Batch: 4 | Loss: 10.9694\n",
      "Epoch 758 | Batch: 5 | Loss: 10.6785\n",
      "Mean of loss / batch 10.940977096557617\n",
      "Epoch 759 | Batch: 1 | Loss: 11.9734\n",
      "Epoch 759 | Batch: 2 | Loss: 10.9794\n",
      "Epoch 759 | Batch: 3 | Loss: 10.4254\n",
      "Epoch 759 | Batch: 4 | Loss: 10.9828\n",
      "Epoch 759 | Batch: 5 | Loss: 10.6487\n",
      "Mean of loss / batch 11.001913070678711\n",
      "Epoch 760 | Batch: 1 | Loss: 12.0780\n",
      "Epoch 760 | Batch: 2 | Loss: 10.7811\n",
      "Epoch 760 | Batch: 3 | Loss: 10.7121\n",
      "Epoch 760 | Batch: 4 | Loss: 10.6676\n",
      "Epoch 760 | Batch: 5 | Loss: 10.6388\n",
      "Mean of loss / batch 10.975500106811523\n",
      "Epoch 761 | Batch: 1 | Loss: 10.6201\n",
      "Epoch 761 | Batch: 2 | Loss: 11.8099\n",
      "Epoch 761 | Batch: 3 | Loss: 11.2374\n",
      "Epoch 761 | Batch: 4 | Loss: 10.5321\n",
      "Epoch 761 | Batch: 5 | Loss: 10.6512\n",
      "Mean of loss / batch 10.970149993896484\n",
      "Epoch 762 | Batch: 1 | Loss: 9.9083\n",
      "Epoch 762 | Batch: 2 | Loss: 10.5859\n",
      "Epoch 762 | Batch: 3 | Loss: 12.0643\n",
      "Epoch 762 | Batch: 4 | Loss: 11.6752\n",
      "Epoch 762 | Batch: 5 | Loss: 10.7384\n",
      "Mean of loss / batch 10.994427680969238\n",
      "Epoch 763 | Batch: 1 | Loss: 10.9669\n",
      "Epoch 763 | Batch: 2 | Loss: 11.5188\n",
      "Epoch 763 | Batch: 3 | Loss: 10.9777\n",
      "Epoch 763 | Batch: 4 | Loss: 10.5988\n",
      "Epoch 763 | Batch: 5 | Loss: 10.6698\n",
      "Mean of loss / batch 10.946393013000488\n",
      "Epoch 764 | Batch: 1 | Loss: 10.2999\n",
      "Epoch 764 | Batch: 2 | Loss: 10.1767\n",
      "Epoch 764 | Batch: 3 | Loss: 11.0754\n",
      "Epoch 764 | Batch: 4 | Loss: 11.9242\n",
      "Epoch 764 | Batch: 5 | Loss: 11.2772\n",
      "Mean of loss / batch 10.950700759887695\n",
      "Epoch 765 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 765 | Batch: 2 | Loss: 11.2117\n",
      "Epoch 765 | Batch: 3 | Loss: 10.3780\n",
      "Epoch 765 | Batch: 4 | Loss: 10.6292\n",
      "Epoch 765 | Batch: 5 | Loss: 11.7758\n",
      "Mean of loss / batch 10.991973876953125\n",
      "Epoch 766 | Batch: 1 | Loss: 10.4436\n",
      "Epoch 766 | Batch: 2 | Loss: 11.7056\n",
      "Epoch 766 | Batch: 3 | Loss: 10.9654\n",
      "Epoch 766 | Batch: 4 | Loss: 11.4463\n",
      "Epoch 766 | Batch: 5 | Loss: 10.5604\n",
      "Mean of loss / batch 11.024255752563477\n",
      "Epoch 767 | Batch: 1 | Loss: 10.6586\n",
      "Epoch 767 | Batch: 2 | Loss: 11.6886\n",
      "Epoch 767 | Batch: 3 | Loss: 10.7335\n",
      "Epoch 767 | Batch: 4 | Loss: 10.3954\n",
      "Epoch 767 | Batch: 5 | Loss: 11.3762\n",
      "Mean of loss / batch 10.970464706420898\n",
      "Epoch 768 | Batch: 1 | Loss: 11.2748\n",
      "Epoch 768 | Batch: 2 | Loss: 10.4774\n",
      "Epoch 768 | Batch: 3 | Loss: 9.9464\n",
      "Epoch 768 | Batch: 4 | Loss: 11.5410\n",
      "Epoch 768 | Batch: 5 | Loss: 11.7657\n",
      "Mean of loss / batch 11.001075744628906\n",
      "Epoch 769 | Batch: 1 | Loss: 10.4500\n",
      "Epoch 769 | Batch: 2 | Loss: 10.6303\n",
      "Epoch 769 | Batch: 3 | Loss: 11.0004\n",
      "Epoch 769 | Batch: 4 | Loss: 10.9880\n",
      "Epoch 769 | Batch: 5 | Loss: 11.6568\n",
      "Mean of loss / batch 10.945093154907227\n",
      "Epoch 770 | Batch: 1 | Loss: 10.9668\n",
      "Epoch 770 | Batch: 2 | Loss: 10.7389\n",
      "Epoch 770 | Batch: 3 | Loss: 10.6849\n",
      "Epoch 770 | Batch: 4 | Loss: 10.6500\n",
      "Epoch 770 | Batch: 5 | Loss: 11.7115\n",
      "Mean of loss / batch 10.950395584106445\n",
      "Epoch 771 | Batch: 1 | Loss: 10.0058\n",
      "Epoch 771 | Batch: 2 | Loss: 11.0360\n",
      "Epoch 771 | Batch: 3 | Loss: 11.0113\n",
      "Epoch 771 | Batch: 4 | Loss: 12.1206\n",
      "Epoch 771 | Batch: 5 | Loss: 10.9700\n",
      "Mean of loss / batch 11.028742790222168\n",
      "Epoch 772 | Batch: 1 | Loss: 11.3901\n",
      "Epoch 772 | Batch: 2 | Loss: 10.8808\n",
      "Epoch 772 | Batch: 3 | Loss: 10.7761\n",
      "Epoch 772 | Batch: 4 | Loss: 11.4776\n",
      "Epoch 772 | Batch: 5 | Loss: 10.5174\n",
      "Mean of loss / batch 11.008401870727539\n",
      "Epoch 773 | Batch: 1 | Loss: 11.2998\n",
      "Epoch 773 | Batch: 2 | Loss: 10.4452\n",
      "Epoch 773 | Batch: 3 | Loss: 10.6292\n",
      "Epoch 773 | Batch: 4 | Loss: 12.5508\n",
      "Epoch 773 | Batch: 5 | Loss: 10.4986\n",
      "Mean of loss / batch 11.084700584411621\n",
      "Epoch 774 | Batch: 1 | Loss: 10.3193\n",
      "Epoch 774 | Batch: 2 | Loss: 11.4301\n",
      "Epoch 774 | Batch: 3 | Loss: 10.3137\n",
      "Epoch 774 | Batch: 4 | Loss: 11.4344\n",
      "Epoch 774 | Batch: 5 | Loss: 11.3127\n",
      "Mean of loss / batch 10.962023735046387\n",
      "Epoch 775 | Batch: 1 | Loss: 10.9656\n",
      "Epoch 775 | Batch: 2 | Loss: 10.9654\n",
      "Epoch 775 | Batch: 3 | Loss: 10.1791\n",
      "Epoch 775 | Batch: 4 | Loss: 11.4241\n",
      "Epoch 775 | Batch: 5 | Loss: 11.3060\n",
      "Mean of loss / batch 10.96803092956543\n",
      "Epoch 776 | Batch: 1 | Loss: 10.4376\n",
      "Epoch 776 | Batch: 2 | Loss: 10.6274\n",
      "Epoch 776 | Batch: 3 | Loss: 11.3925\n",
      "Epoch 776 | Batch: 4 | Loss: 11.2853\n",
      "Epoch 776 | Batch: 5 | Loss: 10.9650\n",
      "Mean of loss / batch 10.941572189331055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777 | Batch: 1 | Loss: 10.9650\n",
      "Epoch 777 | Batch: 2 | Loss: 10.9650\n",
      "Epoch 777 | Batch: 3 | Loss: 10.7140\n",
      "Epoch 777 | Batch: 4 | Loss: 10.0666\n",
      "Epoch 777 | Batch: 5 | Loss: 12.3595\n",
      "Mean of loss / batch 11.014013290405273\n",
      "Epoch 778 | Batch: 1 | Loss: 10.7106\n",
      "Epoch 778 | Batch: 2 | Loss: 11.2743\n",
      "Epoch 778 | Batch: 3 | Loss: 10.2345\n",
      "Epoch 778 | Batch: 4 | Loss: 11.4005\n",
      "Epoch 778 | Batch: 5 | Loss: 11.2906\n",
      "Mean of loss / batch 10.982097625732422\n",
      "Epoch 779 | Batch: 1 | Loss: 10.9650\n",
      "Epoch 779 | Batch: 2 | Loss: 10.4578\n",
      "Epoch 779 | Batch: 3 | Loss: 11.6917\n",
      "Epoch 779 | Batch: 4 | Loss: 10.7324\n",
      "Epoch 779 | Batch: 5 | Loss: 10.9675\n",
      "Mean of loss / batch 10.962889671325684\n",
      "Epoch 780 | Batch: 1 | Loss: 10.9666\n",
      "Epoch 780 | Batch: 2 | Loss: 10.4176\n",
      "Epoch 780 | Batch: 3 | Loss: 10.9925\n",
      "Epoch 780 | Batch: 4 | Loss: 11.3294\n",
      "Epoch 780 | Batch: 5 | Loss: 10.9664\n",
      "Mean of loss / batch 10.934513092041016\n",
      "Epoch 781 | Batch: 1 | Loss: 10.6932\n",
      "Epoch 781 | Batch: 2 | Loss: 10.6554\n",
      "Epoch 781 | Batch: 3 | Loss: 11.3416\n",
      "Epoch 781 | Batch: 4 | Loss: 10.9673\n",
      "Epoch 781 | Batch: 5 | Loss: 10.9665\n",
      "Mean of loss / batch 10.924776077270508\n",
      "Epoch 782 | Batch: 1 | Loss: 11.5121\n",
      "Epoch 782 | Batch: 2 | Loss: 10.3033\n",
      "Epoch 782 | Batch: 3 | Loss: 11.7703\n",
      "Epoch 782 | Batch: 4 | Loss: 10.7061\n",
      "Epoch 782 | Batch: 5 | Loss: 10.9712\n",
      "Mean of loss / batch 11.052606582641602\n",
      "Epoch 783 | Batch: 1 | Loss: 11.2655\n",
      "Epoch 783 | Batch: 2 | Loss: 10.7278\n",
      "Epoch 783 | Batch: 3 | Loss: 11.8390\n",
      "Epoch 783 | Batch: 4 | Loss: 10.5949\n",
      "Epoch 783 | Batch: 5 | Loss: 10.6648\n",
      "Mean of loss / batch 11.018387794494629\n",
      "Epoch 784 | Batch: 1 | Loss: 11.6732\n",
      "Epoch 784 | Batch: 2 | Loss: 10.7392\n",
      "Epoch 784 | Batch: 3 | Loss: 10.4033\n",
      "Epoch 784 | Batch: 4 | Loss: 10.6196\n",
      "Epoch 784 | Batch: 5 | Loss: 11.4106\n",
      "Mean of loss / batch 10.969168663024902\n",
      "Epoch 785 | Batch: 1 | Loss: 10.6526\n",
      "Epoch 785 | Batch: 2 | Loss: 10.6291\n",
      "Epoch 785 | Batch: 3 | Loss: 11.7762\n",
      "Epoch 785 | Batch: 4 | Loss: 10.1824\n",
      "Epoch 785 | Batch: 5 | Loss: 11.8317\n",
      "Mean of loss / batch 11.01441478729248\n",
      "Epoch 786 | Batch: 1 | Loss: 11.2448\n",
      "Epoch 786 | Batch: 2 | Loss: 10.7436\n",
      "Epoch 786 | Batch: 3 | Loss: 10.9665\n",
      "Epoch 786 | Batch: 4 | Loss: 10.6927\n",
      "Epoch 786 | Batch: 5 | Loss: 10.9740\n",
      "Mean of loss / batch 10.92431926727295\n",
      "Epoch 787 | Batch: 1 | Loss: 10.6652\n",
      "Epoch 787 | Batch: 2 | Loss: 10.9822\n",
      "Epoch 787 | Batch: 3 | Loss: 11.3029\n",
      "Epoch 787 | Batch: 4 | Loss: 10.7033\n",
      "Epoch 787 | Batch: 5 | Loss: 10.9718\n",
      "Mean of loss / batch 10.925065994262695\n",
      "Epoch 788 | Batch: 1 | Loss: 12.4612\n",
      "Epoch 788 | Batch: 2 | Loss: 10.9760\n",
      "Epoch 788 | Batch: 3 | Loss: 10.0682\n",
      "Epoch 788 | Batch: 4 | Loss: 11.9286\n",
      "Epoch 788 | Batch: 5 | Loss: 10.6637\n",
      "Mean of loss / batch 11.21953010559082\n",
      "Epoch 789 | Batch: 1 | Loss: 11.3293\n",
      "Epoch 789 | Batch: 2 | Loss: 10.9664\n",
      "Epoch 789 | Batch: 3 | Loss: 10.4206\n",
      "Epoch 789 | Batch: 4 | Loss: 10.2550\n",
      "Epoch 789 | Batch: 5 | Loss: 11.9298\n",
      "Mean of loss / batch 10.98022174835205\n",
      "Epoch 790 | Batch: 1 | Loss: 10.9713\n",
      "Epoch 790 | Batch: 2 | Loss: 10.6723\n",
      "Epoch 790 | Batch: 3 | Loss: 10.6418\n",
      "Epoch 790 | Batch: 4 | Loss: 12.4769\n",
      "Epoch 790 | Batch: 5 | Loss: 10.5435\n",
      "Mean of loss / batch 11.061153411865234\n",
      "Epoch 791 | Batch: 1 | Loss: 11.2919\n",
      "Epoch 791 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 791 | Batch: 3 | Loss: 10.9650\n",
      "Epoch 791 | Batch: 4 | Loss: 10.9650\n",
      "Epoch 791 | Batch: 5 | Loss: 10.4585\n",
      "Mean of loss / batch 10.929122924804688\n",
      "Epoch 792 | Batch: 1 | Loss: 10.9852\n",
      "Epoch 792 | Batch: 2 | Loss: 10.6451\n",
      "Epoch 792 | Batch: 3 | Loss: 10.9912\n",
      "Epoch 792 | Batch: 4 | Loss: 12.0153\n",
      "Epoch 792 | Batch: 5 | Loss: 10.4475\n",
      "Mean of loss / batch 11.016881942749023\n",
      "Epoch 793 | Batch: 1 | Loss: 10.9808\n",
      "Epoch 793 | Batch: 2 | Loss: 10.9753\n",
      "Epoch 793 | Batch: 3 | Loss: 11.5904\n",
      "Epoch 793 | Batch: 4 | Loss: 10.7727\n",
      "Epoch 793 | Batch: 5 | Loss: 10.4481\n",
      "Mean of loss / batch 10.953442573547363\n",
      "Epoch 794 | Batch: 1 | Loss: 10.9870\n",
      "Epoch 794 | Batch: 2 | Loss: 10.9792\n",
      "Epoch 794 | Batch: 3 | Loss: 11.6138\n",
      "Epoch 794 | Batch: 4 | Loss: 10.5563\n",
      "Epoch 794 | Batch: 5 | Loss: 10.6578\n",
      "Mean of loss / batch 10.95881462097168\n",
      "Epoch 795 | Batch: 1 | Loss: 11.3379\n",
      "Epoch 795 | Batch: 2 | Loss: 10.6841\n",
      "Epoch 795 | Batch: 3 | Loss: 10.3228\n",
      "Epoch 795 | Batch: 4 | Loss: 12.2512\n",
      "Epoch 795 | Batch: 5 | Loss: 10.5045\n",
      "Mean of loss / batch 11.020092964172363\n",
      "Epoch 796 | Batch: 1 | Loss: 10.3092\n",
      "Epoch 796 | Batch: 2 | Loss: 11.4380\n",
      "Epoch 796 | Batch: 3 | Loss: 10.3072\n",
      "Epoch 796 | Batch: 4 | Loss: 11.4396\n",
      "Epoch 796 | Batch: 5 | Loss: 11.3160\n",
      "Mean of loss / batch 10.96198844909668\n",
      "Epoch 797 | Batch: 1 | Loss: 10.4257\n",
      "Epoch 797 | Batch: 2 | Loss: 10.9909\n",
      "Epoch 797 | Batch: 3 | Loss: 11.6695\n",
      "Epoch 797 | Batch: 4 | Loss: 10.7406\n",
      "Epoch 797 | Batch: 5 | Loss: 10.9667\n",
      "Mean of loss / batch 10.958699226379395\n",
      "Epoch 798 | Batch: 1 | Loss: 10.9661\n",
      "Epoch 798 | Batch: 2 | Loss: 11.5064\n",
      "Epoch 798 | Batch: 3 | Loss: 10.8126\n",
      "Epoch 798 | Batch: 4 | Loss: 10.7323\n",
      "Epoch 798 | Batch: 5 | Loss: 10.6806\n",
      "Mean of loss / batch 10.939616203308105\n",
      "Epoch 799 | Batch: 1 | Loss: 10.3173\n",
      "Epoch 799 | Batch: 2 | Loss: 9.7735\n",
      "Epoch 799 | Batch: 3 | Loss: 10.5859\n",
      "Epoch 799 | Batch: 4 | Loss: 11.1143\n",
      "Epoch 799 | Batch: 5 | Loss: 13.4394\n",
      "Mean of loss / batch 11.046085357666016\n",
      "Epoch 800 | Batch: 1 | Loss: 11.1565\n",
      "Epoch 800 | Batch: 2 | Loss: 10.8414\n",
      "Epoch 800 | Batch: 3 | Loss: 10.5341\n",
      "Epoch 800 | Batch: 4 | Loss: 11.2987\n",
      "Epoch 800 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 10.959179878234863\n",
      "Epoch 801 | Batch: 1 | Loss: 11.4806\n",
      "Epoch 801 | Batch: 2 | Loss: 10.8263\n",
      "Epoch 801 | Batch: 3 | Loss: 10.5159\n",
      "Epoch 801 | Batch: 4 | Loss: 10.9773\n",
      "Epoch 801 | Batch: 5 | Loss: 10.9730\n",
      "Mean of loss / batch 10.954608917236328\n",
      "Epoch 802 | Batch: 1 | Loss: 10.6677\n",
      "Epoch 802 | Batch: 2 | Loss: 11.3237\n",
      "Epoch 802 | Batch: 3 | Loss: 11.5153\n",
      "Epoch 802 | Batch: 4 | Loss: 10.8081\n",
      "Epoch 802 | Batch: 5 | Loss: 10.4933\n",
      "Mean of loss / batch 10.961613655090332\n",
      "Epoch 803 | Batch: 1 | Loss: 10.6410\n",
      "Epoch 803 | Batch: 2 | Loss: 11.3654\n",
      "Epoch 803 | Batch: 3 | Loss: 11.8645\n",
      "Epoch 803 | Batch: 4 | Loss: 10.8508\n",
      "Epoch 803 | Batch: 5 | Loss: 10.3341\n",
      "Mean of loss / batch 11.011168479919434\n",
      "Epoch 804 | Batch: 1 | Loss: 10.9923\n",
      "Epoch 804 | Batch: 2 | Loss: 9.5978\n",
      "Epoch 804 | Batch: 3 | Loss: 12.1685\n",
      "Epoch 804 | Batch: 4 | Loss: 10.6202\n",
      "Epoch 804 | Batch: 5 | Loss: 11.8095\n",
      "Mean of loss / batch 11.037652969360352\n",
      "Epoch 805 | Batch: 1 | Loss: 11.2373\n",
      "Epoch 805 | Batch: 2 | Loss: 10.9673\n",
      "Epoch 805 | Batch: 3 | Loss: 10.9665\n",
      "Epoch 805 | Batch: 4 | Loss: 10.7365\n",
      "Epoch 805 | Batch: 5 | Loss: 10.6833\n",
      "Mean of loss / batch 10.9181547164917\n",
      "Epoch 806 | Batch: 1 | Loss: 10.6490\n",
      "Epoch 806 | Batch: 2 | Loss: 10.9893\n",
      "Epoch 806 | Batch: 3 | Loss: 10.9807\n",
      "Epoch 806 | Batch: 4 | Loss: 10.6519\n",
      "Epoch 806 | Batch: 5 | Loss: 11.3470\n",
      "Mean of loss / batch 10.92357349395752\n",
      "Epoch 807 | Batch: 1 | Loss: 10.9677\n",
      "Epoch 807 | Batch: 2 | Loss: 10.9667\n",
      "Epoch 807 | Batch: 3 | Loss: 10.6911\n",
      "Epoch 807 | Batch: 4 | Loss: 11.2948\n",
      "Epoch 807 | Batch: 5 | Loss: 10.7082\n",
      "Mean of loss / batch 10.925704002380371\n",
      "Epoch 808 | Batch: 1 | Loss: 10.6651\n",
      "Epoch 808 | Batch: 2 | Loss: 10.9823\n",
      "Epoch 808 | Batch: 3 | Loss: 11.6297\n",
      "Epoch 808 | Batch: 4 | Loss: 10.5441\n",
      "Epoch 808 | Batch: 5 | Loss: 10.9742\n",
      "Mean of loss / batch 10.959077835083008\n",
      "Epoch 809 | Batch: 1 | Loss: 10.9710\n",
      "Epoch 809 | Batch: 2 | Loss: 10.9689\n",
      "Epoch 809 | Batch: 3 | Loss: 10.9675\n",
      "Epoch 809 | Batch: 4 | Loss: 10.1270\n",
      "Epoch 809 | Batch: 5 | Loss: 11.8719\n",
      "Mean of loss / batch 10.981260299682617\n",
      "Epoch 810 | Batch: 1 | Loss: 11.2587\n",
      "Epoch 810 | Batch: 2 | Loss: 10.2669\n",
      "Epoch 810 | Batch: 3 | Loss: 11.3874\n",
      "Epoch 810 | Batch: 4 | Loss: 11.5922\n",
      "Epoch 810 | Batch: 5 | Loss: 10.5732\n",
      "Mean of loss / batch 11.015681266784668\n",
      "Epoch 811 | Batch: 1 | Loss: 10.3535\n",
      "Epoch 811 | Batch: 2 | Loss: 11.4047\n",
      "Epoch 811 | Batch: 3 | Loss: 11.6125\n",
      "Epoch 811 | Batch: 4 | Loss: 11.3809\n",
      "Epoch 811 | Batch: 5 | Loss: 10.5424\n",
      "Mean of loss / batch 11.058785438537598\n",
      "Epoch 812 | Batch: 1 | Loss: 11.6650\n",
      "Epoch 812 | Batch: 2 | Loss: 11.1907\n",
      "Epoch 812 | Batch: 3 | Loss: 10.4366\n",
      "Epoch 812 | Batch: 4 | Loss: 11.3255\n",
      "Epoch 812 | Batch: 5 | Loss: 10.4149\n",
      "Mean of loss / batch 11.006518363952637\n",
      "Epoch 813 | Batch: 1 | Loss: 10.2513\n",
      "Epoch 813 | Batch: 2 | Loss: 10.1450\n",
      "Epoch 813 | Batch: 3 | Loss: 11.6040\n",
      "Epoch 813 | Batch: 4 | Loss: 11.4238\n",
      "Epoch 813 | Batch: 5 | Loss: 11.3058\n",
      "Mean of loss / batch 10.945974349975586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814 | Batch: 1 | Loss: 10.9653\n",
      "Epoch 814 | Batch: 2 | Loss: 10.9652\n",
      "Epoch 814 | Batch: 3 | Loss: 11.4838\n",
      "Epoch 814 | Batch: 4 | Loss: 11.1401\n",
      "Epoch 814 | Batch: 5 | Loss: 10.4909\n",
      "Mean of loss / batch 11.009065628051758\n",
      "Epoch 815 | Batch: 1 | Loss: 12.0376\n",
      "Epoch 815 | Batch: 2 | Loss: 10.7931\n",
      "Epoch 815 | Batch: 3 | Loss: 10.4744\n",
      "Epoch 815 | Batch: 4 | Loss: 10.6363\n",
      "Epoch 815 | Batch: 5 | Loss: 10.9964\n",
      "Mean of loss / batch 10.987565994262695\n",
      "Epoch 816 | Batch: 1 | Loss: 10.9854\n",
      "Epoch 816 | Batch: 2 | Loss: 10.9782\n",
      "Epoch 816 | Batch: 3 | Loss: 10.6563\n",
      "Epoch 816 | Batch: 4 | Loss: 10.6315\n",
      "Epoch 816 | Batch: 5 | Loss: 11.3838\n",
      "Mean of loss / batch 10.927030563354492\n",
      "Epoch 817 | Batch: 1 | Loss: 10.9714\n",
      "Epoch 817 | Batch: 2 | Loss: 10.9691\n",
      "Epoch 817 | Batch: 3 | Loss: 10.9677\n",
      "Epoch 817 | Batch: 4 | Loss: 9.8432\n",
      "Epoch 817 | Batch: 5 | Loss: 12.4877\n",
      "Mean of loss / batch 11.047830581665039\n",
      "Epoch 818 | Batch: 1 | Loss: 10.9669\n",
      "Epoch 818 | Batch: 2 | Loss: 10.6904\n",
      "Epoch 818 | Batch: 3 | Loss: 11.9376\n",
      "Epoch 818 | Batch: 4 | Loss: 10.8251\n",
      "Epoch 818 | Batch: 5 | Loss: 10.5144\n",
      "Mean of loss / batch 10.986868858337402\n",
      "Epoch 819 | Batch: 1 | Loss: 10.9775\n",
      "Epoch 819 | Batch: 2 | Loss: 11.9191\n",
      "Epoch 819 | Batch: 3 | Loss: 11.2898\n",
      "Epoch 819 | Batch: 4 | Loss: 10.8839\n",
      "Epoch 819 | Batch: 5 | Loss: 10.1374\n",
      "Mean of loss / batch 11.041536331176758\n",
      "Epoch 820 | Batch: 1 | Loss: 10.6018\n",
      "Epoch 820 | Batch: 2 | Loss: 10.5961\n",
      "Epoch 820 | Batch: 3 | Loss: 11.0411\n",
      "Epoch 820 | Batch: 4 | Loss: 11.0145\n",
      "Epoch 820 | Batch: 5 | Loss: 11.3768\n",
      "Mean of loss / batch 10.92605209350586\n",
      "Epoch 821 | Batch: 1 | Loss: 10.3615\n",
      "Epoch 821 | Batch: 2 | Loss: 9.8226\n",
      "Epoch 821 | Batch: 3 | Loss: 11.6176\n",
      "Epoch 821 | Batch: 4 | Loss: 11.0175\n",
      "Epoch 821 | Batch: 5 | Loss: 12.1493\n",
      "Mean of loss / batch 10.993715286254883\n",
      "Epoch 822 | Batch: 1 | Loss: 11.1764\n",
      "Epoch 822 | Batch: 2 | Loss: 10.4806\n",
      "Epoch 822 | Batch: 3 | Loss: 10.6451\n",
      "Epoch 822 | Batch: 4 | Loss: 11.3583\n",
      "Epoch 822 | Batch: 5 | Loss: 11.2632\n",
      "Mean of loss / batch 10.984707832336426\n",
      "Epoch 823 | Batch: 1 | Loss: 11.6735\n",
      "Epoch 823 | Batch: 2 | Loss: 11.1062\n",
      "Epoch 823 | Batch: 3 | Loss: 11.0293\n",
      "Epoch 823 | Batch: 4 | Loss: 10.6853\n",
      "Epoch 823 | Batch: 5 | Loss: 10.3961\n",
      "Mean of loss / batch 10.978074073791504\n",
      "Epoch 824 | Batch: 1 | Loss: 12.5124\n",
      "Epoch 824 | Batch: 2 | Loss: 11.1377\n",
      "Epoch 824 | Batch: 3 | Loss: 10.9975\n",
      "Epoch 824 | Batch: 4 | Loss: 10.8372\n",
      "Epoch 824 | Batch: 5 | Loss: 9.8723\n",
      "Mean of loss / batch 11.071413040161133\n",
      "Epoch 825 | Batch: 1 | Loss: 9.6367\n",
      "Epoch 825 | Batch: 2 | Loss: 8.8484\n",
      "Epoch 825 | Batch: 3 | Loss: 14.2586\n",
      "Epoch 825 | Batch: 4 | Loss: 11.4589\n",
      "Epoch 825 | Batch: 5 | Loss: 11.3287\n",
      "Mean of loss / batch 11.106246948242188\n",
      "Epoch 826 | Batch: 1 | Loss: 10.6889\n",
      "Epoch 826 | Batch: 2 | Loss: 11.6197\n",
      "Epoch 826 | Batch: 3 | Loss: 10.9687\n",
      "Epoch 826 | Batch: 4 | Loss: 10.7505\n",
      "Epoch 826 | Batch: 5 | Loss: 10.6923\n",
      "Mean of loss / batch 10.943990707397461\n",
      "Epoch 827 | Batch: 1 | Loss: 10.9741\n",
      "Epoch 827 | Batch: 2 | Loss: 10.9709\n",
      "Epoch 827 | Batch: 3 | Loss: 10.6736\n",
      "Epoch 827 | Batch: 4 | Loss: 10.9793\n",
      "Epoch 827 | Batch: 5 | Loss: 10.9743\n",
      "Mean of loss / batch 10.914426803588867\n",
      "Epoch 828 | Batch: 1 | Loss: 10.6645\n",
      "Epoch 828 | Batch: 2 | Loss: 10.9825\n",
      "Epoch 828 | Batch: 3 | Loss: 11.6308\n",
      "Epoch 828 | Batch: 4 | Loss: 10.7557\n",
      "Epoch 828 | Batch: 5 | Loss: 10.6957\n",
      "Mean of loss / batch 10.945821762084961\n",
      "Epoch 829 | Batch: 1 | Loss: 10.9733\n",
      "Epoch 829 | Batch: 2 | Loss: 11.2740\n",
      "Epoch 829 | Batch: 3 | Loss: 10.4785\n",
      "Epoch 829 | Batch: 4 | Loss: 10.6373\n",
      "Epoch 829 | Batch: 5 | Loss: 11.3724\n",
      "Mean of loss / batch 10.947088241577148\n",
      "Epoch 830 | Batch: 1 | Loss: 10.6679\n",
      "Epoch 830 | Batch: 2 | Loss: 10.2968\n",
      "Epoch 830 | Batch: 3 | Loss: 11.4479\n",
      "Epoch 830 | Batch: 4 | Loss: 10.2992\n",
      "Epoch 830 | Batch: 5 | Loss: 12.2926\n",
      "Mean of loss / batch 11.000892639160156\n",
      "Epoch 831 | Batch: 1 | Loss: 10.4856\n",
      "Epoch 831 | Batch: 2 | Loss: 10.6391\n",
      "Epoch 831 | Batch: 3 | Loss: 11.3690\n",
      "Epoch 831 | Batch: 4 | Loss: 10.9698\n",
      "Epoch 831 | Batch: 5 | Loss: 11.2588\n",
      "Mean of loss / batch 10.944440841674805\n",
      "Epoch 832 | Batch: 1 | Loss: 10.7327\n",
      "Epoch 832 | Batch: 2 | Loss: 11.2541\n",
      "Epoch 832 | Batch: 3 | Loss: 10.0473\n",
      "Epoch 832 | Batch: 4 | Loss: 11.4640\n",
      "Epoch 832 | Batch: 5 | Loss: 11.6805\n",
      "Mean of loss / batch 11.03571891784668\n",
      "Epoch 833 | Batch: 1 | Loss: 11.1955\n",
      "Epoch 833 | Batch: 2 | Loss: 10.9740\n",
      "Epoch 833 | Batch: 3 | Loss: 10.9708\n",
      "Epoch 833 | Batch: 4 | Loss: 10.5531\n",
      "Epoch 833 | Batch: 5 | Loss: 10.9733\n",
      "Mean of loss / batch 10.933345794677734\n",
      "Epoch 834 | Batch: 1 | Loss: 10.0594\n",
      "Epoch 834 | Batch: 2 | Loss: 11.9237\n",
      "Epoch 834 | Batch: 3 | Loss: 10.9709\n",
      "Epoch 834 | Batch: 4 | Loss: 10.3781\n",
      "Epoch 834 | Batch: 5 | Loss: 11.7744\n",
      "Mean of loss / batch 11.02131175994873\n",
      "Epoch 835 | Batch: 1 | Loss: 10.4445\n",
      "Epoch 835 | Batch: 2 | Loss: 11.3461\n",
      "Epoch 835 | Batch: 3 | Loss: 10.9676\n",
      "Epoch 835 | Batch: 4 | Loss: 10.9667\n",
      "Epoch 835 | Batch: 5 | Loss: 10.9661\n",
      "Mean of loss / batch 10.938212394714355\n",
      "Epoch 836 | Batch: 1 | Loss: 9.8852\n",
      "Epoch 836 | Batch: 2 | Loss: 11.5216\n",
      "Epoch 836 | Batch: 3 | Loss: 12.4941\n",
      "Epoch 836 | Batch: 4 | Loss: 10.9850\n",
      "Epoch 836 | Batch: 5 | Loss: 10.6366\n",
      "Mean of loss / batch 11.10450553894043\n",
      "Epoch 837 | Batch: 1 | Loss: 11.5406\n",
      "Epoch 837 | Batch: 2 | Loss: 10.9752\n",
      "Epoch 837 | Batch: 3 | Loss: 10.7777\n",
      "Epoch 837 | Batch: 4 | Loss: 10.4547\n",
      "Epoch 837 | Batch: 5 | Loss: 10.9859\n",
      "Mean of loss / batch 10.946818351745605\n",
      "Epoch 838 | Batch: 1 | Loss: 10.6443\n",
      "Epoch 838 | Batch: 2 | Loss: 11.7278\n",
      "Epoch 838 | Batch: 3 | Loss: 11.2103\n",
      "Epoch 838 | Batch: 4 | Loss: 9.9888\n",
      "Epoch 838 | Batch: 5 | Loss: 11.9622\n",
      "Mean of loss / batch 11.10667610168457\n",
      "Epoch 839 | Batch: 1 | Loss: 11.6084\n",
      "Epoch 839 | Batch: 2 | Loss: 10.9694\n",
      "Epoch 839 | Batch: 3 | Loss: 10.7541\n",
      "Epoch 839 | Batch: 4 | Loss: 10.9658\n",
      "Epoch 839 | Batch: 5 | Loss: 10.4311\n",
      "Mean of loss / batch 10.945747375488281\n",
      "Epoch 840 | Batch: 1 | Loss: 10.6258\n",
      "Epoch 840 | Batch: 2 | Loss: 10.2196\n",
      "Epoch 840 | Batch: 3 | Loss: 11.0537\n",
      "Epoch 840 | Batch: 4 | Loss: 11.8695\n",
      "Epoch 840 | Batch: 5 | Loss: 10.9680\n",
      "Mean of loss / batch 10.947324752807617\n",
      "Epoch 841 | Batch: 1 | Loss: 10.9669\n",
      "Epoch 841 | Batch: 2 | Loss: 10.6900\n",
      "Epoch 841 | Batch: 3 | Loss: 10.0106\n",
      "Epoch 841 | Batch: 4 | Loss: 12.4208\n",
      "Epoch 841 | Batch: 5 | Loss: 10.9656\n",
      "Mean of loss / batch 11.010786056518555\n",
      "Epoch 842 | Batch: 1 | Loss: 11.7587\n",
      "Epoch 842 | Batch: 2 | Loss: 10.5560\n",
      "Epoch 842 | Batch: 3 | Loss: 10.3013\n",
      "Epoch 842 | Batch: 4 | Loss: 11.4443\n",
      "Epoch 842 | Batch: 5 | Loss: 11.3192\n",
      "Mean of loss / batch 11.07590103149414\n",
      "Epoch 843 | Batch: 1 | Loss: 10.4221\n",
      "Epoch 843 | Batch: 2 | Loss: 11.3594\n",
      "Epoch 843 | Batch: 3 | Loss: 10.3786\n",
      "Epoch 843 | Batch: 4 | Loss: 11.7738\n",
      "Epoch 843 | Batch: 5 | Loss: 10.9652\n",
      "Mean of loss / batch 10.979822158813477\n",
      "Epoch 844 | Batch: 1 | Loss: 11.2235\n",
      "Epoch 844 | Batch: 2 | Loss: 10.7619\n",
      "Epoch 844 | Batch: 3 | Loss: 10.4339\n",
      "Epoch 844 | Batch: 4 | Loss: 10.9894\n",
      "Epoch 844 | Batch: 5 | Loss: 11.3220\n",
      "Mean of loss / batch 10.946146011352539\n",
      "Epoch 845 | Batch: 1 | Loss: 11.7866\n",
      "Epoch 845 | Batch: 2 | Loss: 10.7612\n",
      "Epoch 845 | Batch: 3 | Loss: 11.7012\n",
      "Epoch 845 | Batch: 4 | Loss: 10.8194\n",
      "Epoch 845 | Batch: 5 | Loss: 10.2844\n",
      "Mean of loss / batch 11.070571899414062\n",
      "Epoch 846 | Batch: 1 | Loss: 10.6164\n",
      "Epoch 846 | Batch: 2 | Loss: 10.6056\n",
      "Epoch 846 | Batch: 3 | Loss: 11.4511\n",
      "Epoch 846 | Batch: 4 | Loss: 11.3236\n",
      "Epoch 846 | Batch: 5 | Loss: 10.6916\n",
      "Mean of loss / batch 10.937660217285156\n",
      "Epoch 847 | Batch: 1 | Loss: 10.9743\n",
      "Epoch 847 | Batch: 2 | Loss: 11.8905\n",
      "Epoch 847 | Batch: 3 | Loss: 10.9871\n",
      "Epoch 847 | Batch: 4 | Loss: 10.4794\n",
      "Epoch 847 | Batch: 5 | Loss: 10.6449\n",
      "Mean of loss / batch 10.995235443115234\n",
      "Epoch 848 | Batch: 1 | Loss: 10.2568\n",
      "Epoch 848 | Batch: 2 | Loss: 11.0379\n",
      "Epoch 848 | Batch: 3 | Loss: 10.6053\n",
      "Epoch 848 | Batch: 4 | Loss: 11.4520\n",
      "Epoch 848 | Batch: 5 | Loss: 11.3242\n",
      "Mean of loss / batch 10.935234069824219\n",
      "Epoch 849 | Batch: 1 | Loss: 11.7907\n",
      "Epoch 849 | Batch: 2 | Loss: 10.7586\n",
      "Epoch 849 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 849 | Batch: 4 | Loss: 10.4706\n",
      "Epoch 849 | Batch: 5 | Loss: 10.9834\n",
      "Mean of loss / batch 10.99366283416748\n",
      "Epoch 850 | Batch: 1 | Loss: 10.9769\n",
      "Epoch 850 | Batch: 2 | Loss: 10.6588\n",
      "Epoch 850 | Batch: 3 | Loss: 10.6331\n",
      "Epoch 850 | Batch: 4 | Loss: 12.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850 | Batch: 5 | Loss: 10.5559\n",
      "Mean of loss / batch 10.993855476379395\n",
      "Epoch 851 | Batch: 1 | Loss: 10.3424\n",
      "Epoch 851 | Batch: 2 | Loss: 10.6071\n",
      "Epoch 851 | Batch: 3 | Loss: 11.0228\n",
      "Epoch 851 | Batch: 4 | Loss: 11.7824\n",
      "Epoch 851 | Batch: 5 | Loss: 10.9653\n",
      "Mean of loss / batch 10.943978309631348\n",
      "Epoch 852 | Batch: 1 | Loss: 11.4864\n",
      "Epoch 852 | Batch: 2 | Loss: 10.8232\n",
      "Epoch 852 | Batch: 3 | Loss: 10.7391\n",
      "Epoch 852 | Batch: 4 | Loss: 10.6850\n",
      "Epoch 852 | Batch: 5 | Loss: 10.9759\n",
      "Mean of loss / batch 10.941919326782227\n",
      "Epoch 853 | Batch: 1 | Loss: 10.6608\n",
      "Epoch 853 | Batch: 2 | Loss: 12.0324\n",
      "Epoch 853 | Batch: 3 | Loss: 11.1553\n",
      "Epoch 853 | Batch: 4 | Loss: 10.6990\n",
      "Epoch 853 | Batch: 5 | Loss: 10.4344\n",
      "Mean of loss / batch 10.996377944946289\n",
      "Epoch 854 | Batch: 1 | Loss: 10.9893\n",
      "Epoch 854 | Batch: 2 | Loss: 10.2988\n",
      "Epoch 854 | Batch: 3 | Loss: 10.1760\n",
      "Epoch 854 | Batch: 4 | Loss: 11.5658\n",
      "Epoch 854 | Batch: 5 | Loss: 11.7926\n",
      "Mean of loss / batch 10.964517593383789\n",
      "Epoch 855 | Batch: 1 | Loss: 11.4977\n",
      "Epoch 855 | Batch: 2 | Loss: 10.8171\n",
      "Epoch 855 | Batch: 3 | Loss: 10.7352\n",
      "Epoch 855 | Batch: 4 | Loss: 10.9672\n",
      "Epoch 855 | Batch: 5 | Loss: 10.6883\n",
      "Mean of loss / batch 10.941119194030762\n",
      "Epoch 856 | Batch: 1 | Loss: 10.0064\n",
      "Epoch 856 | Batch: 2 | Loss: 11.0490\n",
      "Epoch 856 | Batch: 3 | Loss: 11.4384\n",
      "Epoch 856 | Batch: 4 | Loss: 11.3153\n",
      "Epoch 856 | Batch: 5 | Loss: 10.9657\n",
      "Mean of loss / batch 10.954946517944336\n",
      "Epoch 857 | Batch: 1 | Loss: 11.4973\n",
      "Epoch 857 | Batch: 2 | Loss: 10.8173\n",
      "Epoch 857 | Batch: 3 | Loss: 11.1964\n",
      "Epoch 857 | Batch: 4 | Loss: 10.9738\n",
      "Epoch 857 | Batch: 5 | Loss: 10.3773\n",
      "Mean of loss / batch 10.972432136535645\n",
      "Epoch 858 | Batch: 1 | Loss: 10.6291\n",
      "Epoch 858 | Batch: 2 | Loss: 10.6138\n",
      "Epoch 858 | Batch: 3 | Loss: 10.6039\n",
      "Epoch 858 | Batch: 4 | Loss: 10.5974\n",
      "Epoch 858 | Batch: 5 | Loss: 12.3739\n",
      "Mean of loss / batch 10.963622093200684\n",
      "Epoch 859 | Batch: 1 | Loss: 10.1923\n",
      "Epoch 859 | Batch: 2 | Loss: 10.6056\n",
      "Epoch 859 | Batch: 3 | Loss: 12.3033\n",
      "Epoch 859 | Batch: 4 | Loss: 11.2074\n",
      "Epoch 859 | Batch: 5 | Loss: 10.7775\n",
      "Mean of loss / batch 11.017230033874512\n",
      "Epoch 860 | Batch: 1 | Loss: 10.7097\n",
      "Epoch 860 | Batch: 2 | Loss: 10.6660\n",
      "Epoch 860 | Batch: 3 | Loss: 11.6701\n",
      "Epoch 860 | Batch: 4 | Loss: 10.9663\n",
      "Epoch 860 | Batch: 5 | Loss: 10.7349\n",
      "Mean of loss / batch 10.949414253234863\n",
      "Epoch 861 | Batch: 1 | Loss: 10.1124\n",
      "Epoch 861 | Batch: 2 | Loss: 11.8829\n",
      "Epoch 861 | Batch: 3 | Loss: 10.0867\n",
      "Epoch 861 | Batch: 4 | Loss: 11.4669\n",
      "Epoch 861 | Batch: 5 | Loss: 11.6837\n",
      "Mean of loss / batch 11.046509742736816\n",
      "Epoch 862 | Batch: 1 | Loss: 10.9659\n",
      "Epoch 862 | Batch: 2 | Loss: 11.4349\n",
      "Epoch 862 | Batch: 3 | Loss: 10.7146\n",
      "Epoch 862 | Batch: 4 | Loss: 10.7048\n",
      "Epoch 862 | Batch: 5 | Loss: 10.9715\n",
      "Mean of loss / batch 10.958318710327148\n",
      "Epoch 863 | Batch: 1 | Loss: 10.9692\n",
      "Epoch 863 | Batch: 2 | Loss: 11.8327\n",
      "Epoch 863 | Batch: 3 | Loss: 10.7315\n",
      "Epoch 863 | Batch: 4 | Loss: 10.4553\n",
      "Epoch 863 | Batch: 5 | Loss: 10.9858\n",
      "Mean of loss / batch 10.994890213012695\n",
      "Epoch 864 | Batch: 1 | Loss: 10.3103\n",
      "Epoch 864 | Batch: 2 | Loss: 11.0192\n",
      "Epoch 864 | Batch: 3 | Loss: 12.5422\n",
      "Epoch 864 | Batch: 4 | Loss: 10.5037\n",
      "Epoch 864 | Batch: 5 | Loss: 10.9764\n",
      "Mean of loss / batch 11.070381164550781\n",
      "Epoch 865 | Batch: 1 | Loss: 10.3472\n",
      "Epoch 865 | Batch: 2 | Loss: 10.2074\n",
      "Epoch 865 | Batch: 3 | Loss: 11.0594\n",
      "Epoch 865 | Batch: 4 | Loss: 12.7423\n",
      "Epoch 865 | Batch: 5 | Loss: 10.7770\n",
      "Mean of loss / batch 11.026666641235352\n",
      "Epoch 866 | Batch: 1 | Loss: 10.7094\n",
      "Epoch 866 | Batch: 2 | Loss: 10.9706\n",
      "Epoch 866 | Batch: 3 | Loss: 10.0857\n",
      "Epoch 866 | Batch: 4 | Loss: 11.4674\n",
      "Epoch 866 | Batch: 5 | Loss: 11.6842\n",
      "Mean of loss / batch 10.983471870422363\n",
      "Epoch 867 | Batch: 1 | Loss: 11.1966\n",
      "Epoch 867 | Batch: 2 | Loss: 11.1586\n",
      "Epoch 867 | Batch: 3 | Loss: 10.6902\n",
      "Epoch 867 | Batch: 4 | Loss: 11.5024\n",
      "Epoch 867 | Batch: 5 | Loss: 10.4846\n",
      "Mean of loss / batch 11.006484985351562\n",
      "Epoch 868 | Batch: 1 | Loss: 11.3099\n",
      "Epoch 868 | Batch: 2 | Loss: 10.6992\n",
      "Epoch 868 | Batch: 3 | Loss: 10.3459\n",
      "Epoch 868 | Batch: 4 | Loss: 11.4101\n",
      "Epoch 868 | Batch: 5 | Loss: 10.9748\n",
      "Mean of loss / batch 10.947992324829102\n",
      "Epoch 869 | Batch: 1 | Loss: 10.9714\n",
      "Epoch 869 | Batch: 2 | Loss: 10.6721\n",
      "Epoch 869 | Batch: 3 | Loss: 10.9798\n",
      "Epoch 869 | Batch: 4 | Loss: 11.2956\n",
      "Epoch 869 | Batch: 5 | Loss: 10.7077\n",
      "Mean of loss / batch 10.925323486328125\n",
      "Epoch 870 | Batch: 1 | Loss: 12.1958\n",
      "Epoch 870 | Batch: 2 | Loss: 10.7268\n",
      "Epoch 870 | Batch: 3 | Loss: 10.4135\n",
      "Epoch 870 | Batch: 4 | Loss: 11.7362\n",
      "Epoch 870 | Batch: 5 | Loss: 10.4691\n",
      "Mean of loss / batch 11.10826587677002\n",
      "Epoch 871 | Batch: 1 | Loss: 10.6349\n",
      "Epoch 871 | Batch: 2 | Loss: 10.2380\n",
      "Epoch 871 | Batch: 3 | Loss: 10.5910\n",
      "Epoch 871 | Batch: 4 | Loss: 12.4498\n",
      "Epoch 871 | Batch: 5 | Loss: 10.9660\n",
      "Mean of loss / batch 10.97594165802002\n",
      "Epoch 872 | Batch: 1 | Loss: 10.6963\n",
      "Epoch 872 | Batch: 2 | Loss: 11.9207\n",
      "Epoch 872 | Batch: 3 | Loss: 10.5245\n",
      "Epoch 872 | Batch: 4 | Loss: 10.9750\n",
      "Epoch 872 | Batch: 5 | Loss: 10.9715\n",
      "Mean of loss / batch 11.017592430114746\n",
      "Epoch 873 | Batch: 1 | Loss: 10.0770\n",
      "Epoch 873 | Batch: 2 | Loss: 10.5949\n",
      "Epoch 873 | Batch: 3 | Loss: 11.0436\n",
      "Epoch 873 | Batch: 4 | Loss: 11.0162\n",
      "Epoch 873 | Batch: 5 | Loss: 12.1433\n",
      "Mean of loss / batch 10.975004196166992\n",
      "Epoch 874 | Batch: 1 | Loss: 11.1753\n",
      "Epoch 874 | Batch: 2 | Loss: 10.1539\n",
      "Epoch 874 | Batch: 3 | Loss: 11.4611\n",
      "Epoch 874 | Batch: 4 | Loss: 10.6359\n",
      "Epoch 874 | Batch: 5 | Loss: 12.1317\n",
      "Mean of loss / batch 11.111576080322266\n",
      "Epoch 875 | Batch: 1 | Loss: 10.7660\n",
      "Epoch 875 | Batch: 2 | Loss: 10.9653\n",
      "Epoch 875 | Batch: 3 | Loss: 10.7045\n",
      "Epoch 875 | Batch: 4 | Loss: 10.6627\n",
      "Epoch 875 | Batch: 5 | Loss: 11.6783\n",
      "Mean of loss / batch 10.955349922180176\n",
      "Epoch 876 | Batch: 1 | Loss: 10.7373\n",
      "Epoch 876 | Batch: 2 | Loss: 10.1174\n",
      "Epoch 876 | Batch: 3 | Loss: 11.0252\n",
      "Epoch 876 | Batch: 4 | Loss: 11.0042\n",
      "Epoch 876 | Batch: 5 | Loss: 12.0862\n",
      "Mean of loss / batch 10.994068145751953\n",
      "Epoch 877 | Batch: 1 | Loss: 11.1647\n",
      "Epoch 877 | Batch: 2 | Loss: 10.9835\n",
      "Epoch 877 | Batch: 3 | Loss: 10.8033\n",
      "Epoch 877 | Batch: 4 | Loss: 10.9653\n",
      "Epoch 877 | Batch: 5 | Loss: 10.7238\n",
      "Mean of loss / batch 10.928125381469727\n",
      "Epoch 878 | Batch: 1 | Loss: 11.8487\n",
      "Epoch 878 | Batch: 2 | Loss: 10.4512\n",
      "Epoch 878 | Batch: 3 | Loss: 10.9874\n",
      "Epoch 878 | Batch: 4 | Loss: 10.3050\n",
      "Epoch 878 | Batch: 5 | Loss: 11.8618\n",
      "Mean of loss / batch 11.090804100036621\n",
      "Epoch 879 | Batch: 1 | Loss: 10.6800\n",
      "Epoch 879 | Batch: 2 | Loss: 12.2991\n",
      "Epoch 879 | Batch: 3 | Loss: 10.7719\n",
      "Epoch 879 | Batch: 4 | Loss: 10.4812\n",
      "Epoch 879 | Batch: 5 | Loss: 10.9818\n",
      "Mean of loss / batch 11.042818069458008\n",
      "Epoch 880 | Batch: 1 | Loss: 10.9759\n",
      "Epoch 880 | Batch: 2 | Loss: 10.9721\n",
      "Epoch 880 | Batch: 3 | Loss: 11.2690\n",
      "Epoch 880 | Batch: 4 | Loss: 10.2453\n",
      "Epoch 880 | Batch: 5 | Loss: 11.3961\n",
      "Mean of loss / batch 10.971670150756836\n",
      "Epoch 881 | Batch: 1 | Loss: 11.2877\n",
      "Epoch 881 | Batch: 2 | Loss: 10.7127\n",
      "Epoch 881 | Batch: 3 | Loss: 10.9701\n",
      "Epoch 881 | Batch: 4 | Loss: 10.9683\n",
      "Epoch 881 | Batch: 5 | Loss: 10.6830\n",
      "Mean of loss / batch 10.924363136291504\n",
      "Epoch 882 | Batch: 1 | Loss: 10.6488\n",
      "Epoch 882 | Batch: 2 | Loss: 10.2639\n",
      "Epoch 882 | Batch: 3 | Loss: 9.7123\n",
      "Epoch 882 | Batch: 4 | Loss: 12.8052\n",
      "Epoch 882 | Batch: 5 | Loss: 11.6748\n",
      "Mean of loss / batch 11.020999908447266\n",
      "Epoch 883 | Batch: 1 | Loss: 10.9661\n",
      "Epoch 883 | Batch: 2 | Loss: 11.4302\n",
      "Epoch 883 | Batch: 3 | Loss: 10.7193\n",
      "Epoch 883 | Batch: 4 | Loss: 10.7063\n",
      "Epoch 883 | Batch: 5 | Loss: 10.9712\n",
      "Mean of loss / batch 10.958634376525879\n",
      "Epoch 884 | Batch: 1 | Loss: 11.5618\n",
      "Epoch 884 | Batch: 2 | Loss: 10.7855\n",
      "Epoch 884 | Batch: 3 | Loss: 10.7149\n",
      "Epoch 884 | Batch: 4 | Loss: 10.9698\n",
      "Epoch 884 | Batch: 5 | Loss: 10.6773\n",
      "Mean of loss / batch 10.941858291625977\n",
      "Epoch 885 | Batch: 1 | Loss: 10.3121\n",
      "Epoch 885 | Batch: 2 | Loss: 11.4357\n",
      "Epoch 885 | Batch: 3 | Loss: 10.9787\n",
      "Epoch 885 | Batch: 4 | Loss: 10.6554\n",
      "Epoch 885 | Batch: 5 | Loss: 11.3415\n",
      "Mean of loss / batch 10.944680213928223\n",
      "Epoch 886 | Batch: 1 | Loss: 10.3973\n",
      "Epoch 886 | Batch: 2 | Loss: 10.6183\n",
      "Epoch 886 | Batch: 3 | Loss: 10.2032\n",
      "Epoch 886 | Batch: 4 | Loss: 10.5876\n",
      "Epoch 886 | Batch: 5 | Loss: 13.4720\n",
      "Mean of loss / batch 11.055669784545898\n",
      "Epoch 887 | Batch: 1 | Loss: 11.3464\n",
      "Epoch 887 | Batch: 2 | Loss: 10.7128\n",
      "Epoch 887 | Batch: 3 | Loss: 10.4076\n",
      "Epoch 887 | Batch: 4 | Loss: 12.1163\n",
      "Epoch 887 | Batch: 5 | Loss: 10.7702\n",
      "Mean of loss / batch 11.070652961730957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 888 | Batch: 1 | Loss: 10.4449\n",
      "Epoch 888 | Batch: 2 | Loss: 10.2707\n",
      "Epoch 888 | Batch: 3 | Loss: 10.1577\n",
      "Epoch 888 | Batch: 4 | Loss: 12.5906\n",
      "Epoch 888 | Batch: 5 | Loss: 11.5766\n",
      "Mean of loss / batch 11.008084297180176\n",
      "Epoch 889 | Batch: 1 | Loss: 11.1647\n",
      "Epoch 889 | Batch: 2 | Loss: 10.9835\n",
      "Epoch 889 | Batch: 3 | Loss: 10.4560\n",
      "Epoch 889 | Batch: 4 | Loss: 10.9801\n",
      "Epoch 889 | Batch: 5 | Loss: 11.2966\n",
      "Mean of loss / batch 10.9761962890625\n",
      "Epoch 890 | Batch: 1 | Loss: 11.4812\n",
      "Epoch 890 | Batch: 2 | Loss: 10.8260\n",
      "Epoch 890 | Batch: 3 | Loss: 10.7409\n",
      "Epoch 890 | Batch: 4 | Loss: 10.9667\n",
      "Epoch 890 | Batch: 5 | Loss: 10.6913\n",
      "Mean of loss / batch 10.941225051879883\n",
      "Epoch 891 | Batch: 1 | Loss: 10.9743\n",
      "Epoch 891 | Batch: 2 | Loss: 10.6644\n",
      "Epoch 891 | Batch: 3 | Loss: 11.6742\n",
      "Epoch 891 | Batch: 4 | Loss: 10.9662\n",
      "Epoch 891 | Batch: 5 | Loss: 10.5016\n",
      "Mean of loss / batch 10.956133842468262\n",
      "Epoch 892 | Batch: 1 | Loss: 10.9790\n",
      "Epoch 892 | Batch: 2 | Loss: 10.9741\n",
      "Epoch 892 | Batch: 3 | Loss: 9.7469\n",
      "Epoch 892 | Batch: 4 | Loss: 11.5760\n",
      "Epoch 892 | Batch: 5 | Loss: 11.8036\n",
      "Mean of loss / batch 11.015932083129883\n",
      "Epoch 893 | Batch: 1 | Loss: 9.6178\n",
      "Epoch 893 | Batch: 2 | Loss: 13.1650\n",
      "Epoch 893 | Batch: 3 | Loss: 10.7004\n",
      "Epoch 893 | Batch: 4 | Loss: 10.9723\n",
      "Epoch 893 | Batch: 5 | Loss: 11.2701\n",
      "Mean of loss / batch 11.145121574401855\n",
      "Epoch 894 | Batch: 1 | Loss: 11.2060\n",
      "Epoch 894 | Batch: 2 | Loss: 10.3933\n",
      "Epoch 894 | Batch: 3 | Loss: 10.9858\n",
      "Epoch 894 | Batch: 4 | Loss: 11.6470\n",
      "Epoch 894 | Batch: 5 | Loss: 10.7492\n",
      "Mean of loss / batch 10.99626636505127\n",
      "Epoch 895 | Batch: 1 | Loss: 11.2407\n",
      "Epoch 895 | Batch: 2 | Loss: 10.5270\n",
      "Epoch 895 | Batch: 3 | Loss: 11.3022\n",
      "Epoch 895 | Batch: 4 | Loss: 10.7037\n",
      "Epoch 895 | Batch: 5 | Loss: 10.9717\n",
      "Mean of loss / batch 10.949043273925781\n",
      "Epoch 896 | Batch: 1 | Loss: 11.5655\n",
      "Epoch 896 | Batch: 2 | Loss: 10.9727\n",
      "Epoch 896 | Batch: 3 | Loss: 10.1650\n",
      "Epoch 896 | Batch: 4 | Loss: 11.0149\n",
      "Epoch 896 | Batch: 5 | Loss: 11.3775\n",
      "Mean of loss / batch 11.01913070678711\n",
      "Epoch 897 | Batch: 1 | Loss: 10.9707\n",
      "Epoch 897 | Batch: 2 | Loss: 10.3798\n",
      "Epoch 897 | Batch: 3 | Loss: 11.3864\n",
      "Epoch 897 | Batch: 4 | Loss: 11.2814\n",
      "Epoch 897 | Batch: 5 | Loss: 10.7168\n",
      "Mean of loss / batch 10.947037696838379\n",
      "Epoch 898 | Batch: 1 | Loss: 10.9695\n",
      "Epoch 898 | Batch: 2 | Loss: 10.6784\n",
      "Epoch 898 | Batch: 3 | Loss: 10.3138\n",
      "Epoch 898 | Batch: 4 | Loss: 11.4344\n",
      "Epoch 898 | Batch: 5 | Loss: 11.3126\n",
      "Mean of loss / batch 10.941720962524414\n",
      "Epoch 899 | Batch: 1 | Loss: 11.2335\n",
      "Epoch 899 | Batch: 2 | Loss: 10.9677\n",
      "Epoch 899 | Batch: 3 | Loss: 10.5229\n",
      "Epoch 899 | Batch: 4 | Loss: 10.9765\n",
      "Epoch 899 | Batch: 5 | Loss: 10.9724\n",
      "Mean of loss / batch 10.934605598449707\n",
      "Epoch 900 | Batch: 1 | Loss: 10.9698\n",
      "Epoch 900 | Batch: 2 | Loss: 10.9681\n",
      "Epoch 900 | Batch: 3 | Loss: 10.9670\n",
      "Epoch 900 | Batch: 4 | Loss: 10.6894\n",
      "Epoch 900 | Batch: 5 | Loss: 10.9748\n",
      "Mean of loss / batch 10.913829803466797\n",
      "Epoch 901 | Batch: 1 | Loss: 10.9714\n",
      "Epoch 901 | Batch: 2 | Loss: 10.9691\n",
      "Epoch 901 | Batch: 3 | Loss: 10.9677\n",
      "Epoch 901 | Batch: 4 | Loss: 10.9667\n",
      "Epoch 901 | Batch: 5 | Loss: 10.6911\n",
      "Mean of loss / batch 10.913202285766602\n",
      "Epoch 902 | Batch: 1 | Loss: 10.3337\n",
      "Epoch 902 | Batch: 2 | Loss: 10.1987\n",
      "Epoch 902 | Batch: 3 | Loss: 10.5872\n",
      "Epoch 902 | Batch: 4 | Loss: 12.5185\n",
      "Epoch 902 | Batch: 5 | Loss: 11.2559\n",
      "Mean of loss / batch 10.978802680969238\n",
      "Epoch 903 | Batch: 1 | Loss: 9.8109\n",
      "Epoch 903 | Batch: 2 | Loss: 11.5563\n",
      "Epoch 903 | Batch: 3 | Loss: 11.0026\n",
      "Epoch 903 | Batch: 4 | Loss: 11.7151\n",
      "Epoch 903 | Batch: 5 | Loss: 11.2063\n",
      "Mean of loss / batch 11.0582275390625\n",
      "Epoch 904 | Batch: 1 | Loss: 10.5855\n",
      "Epoch 904 | Batch: 2 | Loss: 11.2752\n",
      "Epoch 904 | Batch: 3 | Loss: 11.4534\n",
      "Epoch 904 | Batch: 4 | Loss: 10.8416\n",
      "Epoch 904 | Batch: 5 | Loss: 10.7509\n",
      "Mean of loss / batch 10.981328964233398\n",
      "Epoch 905 | Batch: 1 | Loss: 11.2393\n",
      "Epoch 905 | Batch: 2 | Loss: 10.3100\n",
      "Epoch 905 | Batch: 3 | Loss: 11.3706\n",
      "Epoch 905 | Batch: 4 | Loss: 11.5723\n",
      "Epoch 905 | Batch: 5 | Loss: 10.5893\n",
      "Mean of loss / batch 11.016301155090332\n",
      "Epoch 906 | Batch: 1 | Loss: 10.6671\n",
      "Epoch 906 | Batch: 2 | Loss: 11.3246\n",
      "Epoch 906 | Batch: 3 | Loss: 11.2412\n",
      "Epoch 906 | Batch: 4 | Loss: 10.3056\n",
      "Epoch 906 | Batch: 5 | Loss: 11.3722\n",
      "Mean of loss / batch 10.982151985168457\n",
      "Epoch 907 | Batch: 1 | Loss: 11.8764\n",
      "Epoch 907 | Batch: 2 | Loss: 11.1307\n",
      "Epoch 907 | Batch: 3 | Loss: 11.0025\n",
      "Epoch 907 | Batch: 4 | Loss: 10.8480\n",
      "Epoch 907 | Batch: 5 | Loss: 10.1165\n",
      "Mean of loss / batch 10.994816780090332\n",
      "Epoch 908 | Batch: 1 | Loss: 10.1800\n",
      "Epoch 908 | Batch: 2 | Loss: 12.0488\n",
      "Epoch 908 | Batch: 3 | Loss: 11.3231\n",
      "Epoch 908 | Batch: 4 | Loss: 11.2403\n",
      "Epoch 908 | Batch: 5 | Loss: 10.3078\n",
      "Mean of loss / batch 11.019991874694824\n",
      "Epoch 909 | Batch: 1 | Loss: 11.3714\n",
      "Epoch 909 | Batch: 2 | Loss: 10.3667\n",
      "Epoch 909 | Batch: 3 | Loss: 10.6118\n",
      "Epoch 909 | Batch: 4 | Loss: 9.7738\n",
      "Epoch 909 | Batch: 5 | Loss: 13.2493\n",
      "Mean of loss / batch 11.074613571166992\n",
      "Epoch 910 | Batch: 1 | Loss: 10.6879\n",
      "Epoch 910 | Batch: 2 | Loss: 10.3287\n",
      "Epoch 910 | Batch: 3 | Loss: 11.8320\n",
      "Epoch 910 | Batch: 4 | Loss: 11.5233\n",
      "Epoch 910 | Batch: 5 | Loss: 10.6309\n",
      "Mean of loss / batch 11.000566482543945\n",
      "Epoch 911 | Batch: 1 | Loss: 11.8335\n",
      "Epoch 911 | Batch: 2 | Loss: 10.5998\n",
      "Epoch 911 | Batch: 3 | Loss: 10.3606\n",
      "Epoch 911 | Batch: 4 | Loss: 11.3996\n",
      "Epoch 911 | Batch: 5 | Loss: 10.9734\n",
      "Mean of loss / batch 11.033373832702637\n",
      "Epoch 912 | Batch: 1 | Loss: 11.5781\n",
      "Epoch 912 | Batch: 2 | Loss: 10.5846\n",
      "Epoch 912 | Batch: 3 | Loss: 10.6657\n",
      "Epoch 912 | Batch: 4 | Loss: 10.9820\n",
      "Epoch 912 | Batch: 5 | Loss: 10.9760\n",
      "Mean of loss / batch 10.957290649414062\n",
      "Epoch 913 | Batch: 1 | Loss: 10.9721\n",
      "Epoch 913 | Batch: 2 | Loss: 10.6699\n",
      "Epoch 913 | Batch: 3 | Loss: 10.6403\n",
      "Epoch 913 | Batch: 4 | Loss: 11.7396\n",
      "Epoch 913 | Batch: 5 | Loss: 10.7159\n",
      "Mean of loss / batch 10.947572708129883\n",
      "Epoch 914 | Batch: 1 | Loss: 11.2691\n",
      "Epoch 914 | Batch: 2 | Loss: 10.9653\n",
      "Epoch 914 | Batch: 3 | Loss: 10.2383\n",
      "Epoch 914 | Batch: 4 | Loss: 10.6108\n",
      "Epoch 914 | Batch: 5 | Loss: 11.8507\n",
      "Mean of loss / batch 10.986845016479492\n",
      "Epoch 915 | Batch: 1 | Loss: 10.6830\n",
      "Epoch 915 | Batch: 2 | Loss: 10.6488\n",
      "Epoch 915 | Batch: 3 | Loss: 10.6266\n",
      "Epoch 915 | Batch: 4 | Loss: 11.7852\n",
      "Epoch 915 | Batch: 5 | Loss: 10.9653\n",
      "Mean of loss / batch 10.941763877868652\n",
      "Epoch 916 | Batch: 1 | Loss: 11.2266\n",
      "Epoch 916 | Batch: 2 | Loss: 10.5498\n",
      "Epoch 916 | Batch: 3 | Loss: 11.9266\n",
      "Epoch 916 | Batch: 4 | Loss: 10.6742\n",
      "Epoch 916 | Batch: 5 | Loss: 10.6922\n",
      "Mean of loss / batch 11.013874053955078\n",
      "Epoch 917 | Batch: 1 | Loss: 10.6548\n",
      "Epoch 917 | Batch: 2 | Loss: 10.2745\n",
      "Epoch 917 | Batch: 3 | Loss: 11.9024\n",
      "Epoch 917 | Batch: 4 | Loss: 11.8690\n",
      "Epoch 917 | Batch: 5 | Loss: 10.5685\n",
      "Mean of loss / batch 11.053837776184082\n",
      "Epoch 918 | Batch: 1 | Loss: 10.3478\n",
      "Epoch 918 | Batch: 2 | Loss: 11.8091\n",
      "Epoch 918 | Batch: 3 | Loss: 10.6945\n",
      "Epoch 918 | Batch: 4 | Loss: 10.3388\n",
      "Epoch 918 | Batch: 5 | Loss: 11.8197\n",
      "Mean of loss / batch 11.00197982788086\n",
      "Epoch 919 | Batch: 1 | Loss: 10.6915\n",
      "Epoch 919 | Batch: 2 | Loss: 11.2943\n",
      "Epoch 919 | Batch: 3 | Loss: 10.7085\n",
      "Epoch 919 | Batch: 4 | Loss: 10.6653\n",
      "Epoch 919 | Batch: 5 | Loss: 11.3271\n",
      "Mean of loss / batch 10.937335968017578\n",
      "Epoch 920 | Batch: 1 | Loss: 10.9663\n",
      "Epoch 920 | Batch: 2 | Loss: 10.9658\n",
      "Epoch 920 | Batch: 3 | Loss: 10.6979\n",
      "Epoch 920 | Batch: 4 | Loss: 10.6584\n",
      "Epoch 920 | Batch: 5 | Loss: 11.3370\n",
      "Mean of loss / batch 10.925085067749023\n",
      "Epoch 921 | Batch: 1 | Loss: 10.9669\n",
      "Epoch 921 | Batch: 2 | Loss: 10.9663\n",
      "Epoch 921 | Batch: 3 | Loss: 10.6945\n",
      "Epoch 921 | Batch: 4 | Loss: 10.9736\n",
      "Epoch 921 | Batch: 5 | Loss: 10.9706\n",
      "Mean of loss / batch 10.914361953735352\n",
      "Epoch 922 | Batch: 1 | Loss: 12.1448\n",
      "Epoch 922 | Batch: 2 | Loss: 11.0194\n",
      "Epoch 922 | Batch: 3 | Loss: 10.6443\n",
      "Epoch 922 | Batch: 4 | Loss: 10.6739\n",
      "Epoch 922 | Batch: 5 | Loss: 10.6429\n",
      "Mean of loss / batch 11.025047302246094\n",
      "Epoch 923 | Batch: 1 | Loss: 10.6228\n",
      "Epoch 923 | Batch: 2 | Loss: 10.6097\n",
      "Epoch 923 | Batch: 3 | Loss: 11.4377\n",
      "Epoch 923 | Batch: 4 | Loss: 11.3149\n",
      "Epoch 923 | Batch: 5 | Loss: 10.6964\n",
      "Mean of loss / batch 10.936296463012695\n",
      "Epoch 924 | Batch: 1 | Loss: 11.2889\n",
      "Epoch 924 | Batch: 2 | Loss: 11.2182\n",
      "Epoch 924 | Batch: 3 | Loss: 11.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924 | Batch: 4 | Loss: 10.9807\n",
      "Epoch 924 | Batch: 5 | Loss: 10.2553\n",
      "Mean of loss / batch 10.983091354370117\n",
      "Epoch 925 | Batch: 1 | Loss: 10.6108\n",
      "Epoch 925 | Batch: 2 | Loss: 11.4344\n",
      "Epoch 925 | Batch: 3 | Loss: 11.3127\n",
      "Epoch 925 | Batch: 4 | Loss: 10.9656\n",
      "Epoch 925 | Batch: 5 | Loss: 10.4360\n",
      "Mean of loss / batch 10.951894760131836\n",
      "Epoch 926 | Batch: 1 | Loss: 10.2649\n",
      "Epoch 926 | Batch: 2 | Loss: 10.1539\n",
      "Epoch 926 | Batch: 3 | Loss: 12.6001\n",
      "Epoch 926 | Batch: 4 | Loss: 10.3606\n",
      "Epoch 926 | Batch: 5 | Loss: 11.7942\n",
      "Mean of loss / batch 11.0347318649292\n",
      "Epoch 927 | Batch: 1 | Loss: 10.4322\n",
      "Epoch 927 | Batch: 2 | Loss: 10.2625\n",
      "Epoch 927 | Batch: 3 | Loss: 10.1523\n",
      "Epoch 927 | Batch: 4 | Loss: 13.1089\n",
      "Epoch 927 | Batch: 5 | Loss: 11.2210\n",
      "Mean of loss / batch 11.035379409790039\n",
      "Epoch 928 | Batch: 1 | Loss: 10.9693\n",
      "Epoch 928 | Batch: 2 | Loss: 10.5395\n",
      "Epoch 928 | Batch: 3 | Loss: 11.9391\n",
      "Epoch 928 | Batch: 4 | Loss: 11.1401\n",
      "Epoch 928 | Batch: 5 | Loss: 10.6172\n",
      "Mean of loss / batch 11.04102611541748\n",
      "Epoch 929 | Batch: 1 | Loss: 11.2709\n",
      "Epoch 929 | Batch: 2 | Loss: 10.7240\n",
      "Epoch 929 | Batch: 3 | Loss: 10.6752\n",
      "Epoch 929 | Batch: 4 | Loss: 10.3087\n",
      "Epoch 929 | Batch: 5 | Loss: 11.8570\n",
      "Mean of loss / batch 10.96716022491455\n",
      "Epoch 930 | Batch: 1 | Loss: 10.9674\n",
      "Epoch 930 | Batch: 2 | Loss: 10.9666\n",
      "Epoch 930 | Batch: 3 | Loss: 11.2398\n",
      "Epoch 930 | Batch: 4 | Loss: 10.7477\n",
      "Epoch 930 | Batch: 5 | Loss: 10.6905\n",
      "Mean of loss / batch 10.922395706176758\n",
      "Epoch 931 | Batch: 1 | Loss: 10.6536\n",
      "Epoch 931 | Batch: 2 | Loss: 10.9870\n",
      "Epoch 931 | Batch: 3 | Loss: 10.9793\n",
      "Epoch 931 | Batch: 4 | Loss: 11.9339\n",
      "Epoch 931 | Batch: 5 | Loss: 10.5135\n",
      "Mean of loss / batch 11.013460159301758\n",
      "Epoch 932 | Batch: 1 | Loss: 10.6505\n",
      "Epoch 932 | Batch: 2 | Loss: 11.7100\n",
      "Epoch 932 | Batch: 3 | Loss: 10.0079\n",
      "Epoch 932 | Batch: 4 | Loss: 11.4774\n",
      "Epoch 932 | Batch: 5 | Loss: 11.3408\n",
      "Mean of loss / batch 11.03731632232666\n",
      "Epoch 933 | Batch: 1 | Loss: 10.6826\n",
      "Epoch 933 | Batch: 2 | Loss: 10.9766\n",
      "Epoch 933 | Batch: 3 | Loss: 9.7205\n",
      "Epoch 933 | Batch: 4 | Loss: 11.0861\n",
      "Epoch 933 | Batch: 5 | Loss: 12.8552\n",
      "Mean of loss / batch 11.064204216003418\n",
      "Epoch 934 | Batch: 1 | Loss: 10.9678\n",
      "Epoch 934 | Batch: 2 | Loss: 11.1880\n",
      "Epoch 934 | Batch: 3 | Loss: 10.4446\n",
      "Epoch 934 | Batch: 4 | Loss: 11.6646\n",
      "Epoch 934 | Batch: 5 | Loss: 10.7424\n",
      "Mean of loss / batch 11.001482963562012\n",
      "Epoch 935 | Batch: 1 | Loss: 11.5255\n",
      "Epoch 935 | Batch: 2 | Loss: 11.3247\n",
      "Epoch 935 | Batch: 3 | Loss: 11.0170\n",
      "Epoch 935 | Batch: 4 | Loss: 10.8770\n",
      "Epoch 935 | Batch: 5 | Loss: 10.1823\n",
      "Mean of loss / batch 10.985300064086914\n",
      "Epoch 936 | Batch: 1 | Loss: 11.0129\n",
      "Epoch 936 | Batch: 2 | Loss: 10.9961\n",
      "Epoch 936 | Batch: 3 | Loss: 10.6324\n",
      "Epoch 936 | Batch: 4 | Loss: 10.9989\n",
      "Epoch 936 | Batch: 5 | Loss: 10.9870\n",
      "Mean of loss / batch 10.925483703613281\n",
      "Epoch 937 | Batch: 1 | Loss: 11.3159\n",
      "Epoch 937 | Batch: 2 | Loss: 10.1560\n",
      "Epoch 937 | Batch: 3 | Loss: 11.4344\n",
      "Epoch 937 | Batch: 4 | Loss: 10.6443\n",
      "Epoch 937 | Batch: 5 | Loss: 11.3596\n",
      "Mean of loss / batch 10.982046127319336\n",
      "Epoch 938 | Batch: 1 | Loss: 11.2640\n",
      "Epoch 938 | Batch: 2 | Loss: 10.4923\n",
      "Epoch 938 | Batch: 3 | Loss: 10.3013\n",
      "Epoch 938 | Batch: 4 | Loss: 12.7110\n",
      "Epoch 938 | Batch: 5 | Loss: 10.5947\n",
      "Mean of loss / batch 11.072649002075195\n",
      "Epoch 939 | Batch: 1 | Loss: 10.6686\n",
      "Epoch 939 | Batch: 2 | Loss: 9.9564\n",
      "Epoch 939 | Batch: 3 | Loss: 11.5353\n",
      "Epoch 939 | Batch: 4 | Loss: 11.7595\n",
      "Epoch 939 | Batch: 5 | Loss: 10.9651\n",
      "Mean of loss / batch 10.976987838745117\n",
      "Epoch 940 | Batch: 1 | Loss: 9.9461\n",
      "Epoch 940 | Batch: 2 | Loss: 11.9533\n",
      "Epoch 940 | Batch: 3 | Loss: 10.6582\n",
      "Epoch 940 | Batch: 4 | Loss: 11.3374\n",
      "Epoch 940 | Batch: 5 | Loss: 11.2495\n",
      "Mean of loss / batch 11.028887748718262\n",
      "Epoch 941 | Batch: 1 | Loss: 10.9662\n",
      "Epoch 941 | Batch: 2 | Loss: 10.7345\n",
      "Epoch 941 | Batch: 3 | Loss: 10.3967\n",
      "Epoch 941 | Batch: 4 | Loss: 11.3754\n",
      "Epoch 941 | Batch: 5 | Loss: 11.2742\n",
      "Mean of loss / batch 10.94940185546875\n",
      "Epoch 942 | Batch: 1 | Loss: 10.2347\n",
      "Epoch 942 | Batch: 2 | Loss: 11.0054\n",
      "Epoch 942 | Batch: 3 | Loss: 12.4594\n",
      "Epoch 942 | Batch: 4 | Loss: 10.5543\n",
      "Epoch 942 | Batch: 5 | Loss: 11.2887\n",
      "Mean of loss / batch 11.108502388000488\n",
      "Epoch 943 | Batch: 1 | Loss: 10.7120\n",
      "Epoch 943 | Batch: 2 | Loss: 10.9702\n",
      "Epoch 943 | Batch: 3 | Loss: 10.9684\n",
      "Epoch 943 | Batch: 4 | Loss: 10.9672\n",
      "Epoch 943 | Batch: 5 | Loss: 10.9664\n",
      "Mean of loss / batch 10.91684627532959\n",
      "Epoch 944 | Batch: 1 | Loss: 10.4205\n",
      "Epoch 944 | Batch: 2 | Loss: 10.9919\n",
      "Epoch 944 | Batch: 3 | Loss: 11.3281\n",
      "Epoch 944 | Batch: 4 | Loss: 10.4120\n",
      "Epoch 944 | Batch: 5 | Loss: 11.7378\n",
      "Mean of loss / batch 10.978053092956543\n",
      "Epoch 945 | Batch: 1 | Loss: 10.2194\n",
      "Epoch 945 | Batch: 2 | Loss: 11.4068\n",
      "Epoch 945 | Batch: 3 | Loss: 10.9744\n",
      "Epoch 945 | Batch: 4 | Loss: 10.3575\n",
      "Epoch 945 | Batch: 5 | Loss: 12.1936\n",
      "Mean of loss / batch 11.030346870422363\n",
      "Epoch 946 | Batch: 1 | Loss: 11.4027\n",
      "Epoch 946 | Batch: 2 | Loss: 11.2456\n",
      "Epoch 946 | Batch: 3 | Loss: 11.0457\n",
      "Epoch 946 | Batch: 4 | Loss: 10.6583\n",
      "Epoch 946 | Batch: 5 | Loss: 10.6530\n",
      "Mean of loss / batch 11.001089096069336\n",
      "Epoch 947 | Batch: 1 | Loss: 10.9873\n",
      "Epoch 947 | Batch: 2 | Loss: 10.6424\n",
      "Epoch 947 | Batch: 3 | Loss: 10.6224\n",
      "Epoch 947 | Batch: 4 | Loss: 11.0066\n",
      "Epoch 947 | Batch: 5 | Loss: 11.3607\n",
      "Mean of loss / batch 10.923871994018555\n",
      "Epoch 948 | Batch: 1 | Loss: 11.2647\n",
      "Epoch 948 | Batch: 2 | Loss: 10.9654\n",
      "Epoch 948 | Batch: 3 | Loss: 10.4856\n",
      "Epoch 948 | Batch: 4 | Loss: 10.9812\n",
      "Epoch 948 | Batch: 5 | Loss: 10.9755\n",
      "Mean of loss / batch 10.934473991394043\n",
      "Epoch 949 | Batch: 1 | Loss: 10.9718\n",
      "Epoch 949 | Batch: 2 | Loss: 10.6709\n",
      "Epoch 949 | Batch: 3 | Loss: 11.3195\n",
      "Epoch 949 | Batch: 4 | Loss: 10.9659\n",
      "Epoch 949 | Batch: 5 | Loss: 10.6976\n",
      "Mean of loss / batch 10.925121307373047\n",
      "Epoch 950 | Batch: 1 | Loss: 11.2876\n",
      "Epoch 950 | Batch: 2 | Loss: 11.2173\n",
      "Epoch 950 | Batch: 3 | Loss: 10.9698\n",
      "Epoch 950 | Batch: 4 | Loss: 10.7563\n",
      "Epoch 950 | Batch: 5 | Loss: 10.4265\n",
      "Mean of loss / batch 10.931502342224121\n",
      "Epoch 951 | Batch: 1 | Loss: 11.7228\n",
      "Epoch 951 | Batch: 2 | Loss: 9.9907\n",
      "Epoch 951 | Batch: 3 | Loss: 11.9285\n",
      "Epoch 951 | Batch: 4 | Loss: 10.9712\n",
      "Epoch 951 | Batch: 5 | Loss: 10.6725\n",
      "Mean of loss / batch 11.057159423828125\n",
      "Epoch 952 | Batch: 1 | Loss: 11.3173\n",
      "Epoch 952 | Batch: 2 | Loss: 10.6950\n",
      "Epoch 952 | Batch: 3 | Loss: 10.9735\n",
      "Epoch 952 | Batch: 4 | Loss: 10.9705\n",
      "Epoch 952 | Batch: 5 | Loss: 10.6748\n",
      "Mean of loss / batch 10.926224708557129\n",
      "Epoch 953 | Batch: 1 | Loss: 11.3143\n",
      "Epoch 953 | Batch: 2 | Loss: 11.5035\n",
      "Epoch 953 | Batch: 3 | Loss: 10.9796\n",
      "Epoch 953 | Batch: 4 | Loss: 10.7919\n",
      "Epoch 953 | Batch: 5 | Loss: 10.2269\n",
      "Mean of loss / batch 10.963241577148438\n",
      "Epoch 954 | Batch: 1 | Loss: 9.8153\n",
      "Epoch 954 | Batch: 2 | Loss: 11.6225\n",
      "Epoch 954 | Batch: 3 | Loss: 10.6016\n",
      "Epoch 954 | Batch: 4 | Loss: 10.5959\n",
      "Epoch 954 | Batch: 5 | Loss: 12.3894\n",
      "Mean of loss / batch 11.004938125610352\n",
      "Epoch 955 | Batch: 1 | Loss: 10.4433\n",
      "Epoch 955 | Batch: 2 | Loss: 12.0649\n",
      "Epoch 955 | Batch: 3 | Loss: 10.9729\n",
      "Epoch 955 | Batch: 4 | Loss: 10.9701\n",
      "Epoch 955 | Batch: 5 | Loss: 10.5472\n",
      "Mean of loss / batch 10.999702453613281\n",
      "Epoch 956 | Batch: 1 | Loss: 11.2925\n",
      "Epoch 956 | Batch: 2 | Loss: 10.4543\n",
      "Epoch 956 | Batch: 3 | Loss: 9.9221\n",
      "Epoch 956 | Batch: 4 | Loss: 12.0396\n",
      "Epoch 956 | Batch: 5 | Loss: 11.3196\n",
      "Mean of loss / batch 11.00561237335205\n",
      "Epoch 957 | Batch: 1 | Loss: 10.6937\n",
      "Epoch 957 | Batch: 2 | Loss: 10.6557\n",
      "Epoch 957 | Batch: 3 | Loss: 9.9212\n",
      "Epoch 957 | Batch: 4 | Loss: 12.0404\n",
      "Epoch 957 | Batch: 5 | Loss: 11.6596\n",
      "Mean of loss / batch 10.994124412536621\n",
      "Epoch 958 | Batch: 1 | Loss: 11.4114\n",
      "Epoch 958 | Batch: 2 | Loss: 11.2512\n",
      "Epoch 958 | Batch: 3 | Loss: 11.0434\n",
      "Epoch 958 | Batch: 4 | Loss: 10.5553\n",
      "Epoch 958 | Batch: 5 | Loss: 10.9943\n",
      "Mean of loss / batch 11.051118850708008\n",
      "Epoch 959 | Batch: 1 | Loss: 9.9348\n",
      "Epoch 959 | Batch: 2 | Loss: 12.0282\n",
      "Epoch 959 | Batch: 3 | Loss: 11.3154\n",
      "Epoch 959 | Batch: 4 | Loss: 11.2353\n",
      "Epoch 959 | Batch: 5 | Loss: 10.5355\n",
      "Mean of loss / batch 11.009832382202148\n",
      "Epoch 960 | Batch: 1 | Loss: 10.9751\n",
      "Epoch 960 | Batch: 2 | Loss: 12.2073\n",
      "Epoch 960 | Batch: 3 | Loss: 10.4260\n",
      "Epoch 960 | Batch: 4 | Loss: 11.0260\n",
      "Epoch 960 | Batch: 5 | Loss: 11.3985\n",
      "Mean of loss / batch 11.206581115722656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961 | Batch: 1 | Loss: 9.3931\n",
      "Epoch 961 | Batch: 2 | Loss: 12.2484\n",
      "Epoch 961 | Batch: 3 | Loss: 9.8194\n",
      "Epoch 961 | Batch: 4 | Loss: 12.1371\n",
      "Epoch 961 | Batch: 5 | Loss: 12.0892\n",
      "Mean of loss / batch 11.137452125549316\n",
      "Epoch 962 | Batch: 1 | Loss: 10.9716\n",
      "Epoch 962 | Batch: 2 | Loss: 11.5845\n",
      "Epoch 962 | Batch: 3 | Loss: 10.9060\n",
      "Epoch 962 | Batch: 4 | Loss: 11.1713\n",
      "Epoch 962 | Batch: 5 | Loss: 10.4974\n",
      "Mean of loss / batch 11.026143074035645\n",
      "Epoch 963 | Batch: 1 | Loss: 11.3059\n",
      "Epoch 963 | Batch: 2 | Loss: 10.9653\n",
      "Epoch 963 | Batch: 3 | Loss: 10.1811\n",
      "Epoch 963 | Batch: 4 | Loss: 11.8326\n",
      "Epoch 963 | Batch: 5 | Loss: 10.6879\n",
      "Mean of loss / batch 10.994576454162598\n",
      "Epoch 964 | Batch: 1 | Loss: 10.3287\n",
      "Epoch 964 | Batch: 2 | Loss: 10.6045\n",
      "Epoch 964 | Batch: 3 | Loss: 11.4547\n",
      "Epoch 964 | Batch: 4 | Loss: 10.2938\n",
      "Epoch 964 | Batch: 5 | Loss: 12.3023\n",
      "Mean of loss / batch 10.996798515319824\n",
      "Epoch 965 | Batch: 1 | Loss: 10.7232\n",
      "Epoch 965 | Batch: 2 | Loss: 11.2624\n",
      "Epoch 965 | Batch: 3 | Loss: 10.7300\n",
      "Epoch 965 | Batch: 4 | Loss: 10.3906\n",
      "Epoch 965 | Batch: 5 | Loss: 11.7606\n",
      "Mean of loss / batch 10.973368644714355\n",
      "Epoch 966 | Batch: 1 | Loss: 11.4769\n",
      "Epoch 966 | Batch: 2 | Loss: 10.6733\n",
      "Epoch 966 | Batch: 3 | Loss: 10.9660\n",
      "Epoch 966 | Batch: 4 | Loss: 10.1569\n",
      "Epoch 966 | Batch: 5 | Loss: 11.8500\n",
      "Mean of loss / batch 11.02463436126709\n",
      "Epoch 967 | Batch: 1 | Loss: 11.5351\n",
      "Epoch 967 | Batch: 2 | Loss: 11.1533\n",
      "Epoch 967 | Batch: 3 | Loss: 10.8464\n",
      "Epoch 967 | Batch: 4 | Loss: 10.9678\n",
      "Epoch 967 | Batch: 5 | Loss: 10.3033\n",
      "Mean of loss / batch 10.961194038391113\n",
      "Epoch 968 | Batch: 1 | Loss: 11.3731\n",
      "Epoch 968 | Batch: 2 | Loss: 10.3650\n",
      "Epoch 968 | Batch: 3 | Loss: 11.3965\n",
      "Epoch 968 | Batch: 4 | Loss: 10.6580\n",
      "Epoch 968 | Batch: 5 | Loss: 10.9851\n",
      "Mean of loss / batch 10.955556869506836\n",
      "Epoch 969 | Batch: 1 | Loss: 11.3108\n",
      "Epoch 969 | Batch: 2 | Loss: 11.2323\n",
      "Epoch 969 | Batch: 3 | Loss: 11.1816\n",
      "Epoch 969 | Batch: 4 | Loss: 10.9777\n",
      "Epoch 969 | Batch: 5 | Loss: 10.2251\n",
      "Mean of loss / batch 10.985494613647461\n",
      "Epoch 970 | Batch: 1 | Loss: 13.0067\n",
      "Epoch 970 | Batch: 2 | Loss: 10.6362\n",
      "Epoch 970 | Batch: 3 | Loss: 10.0790\n",
      "Epoch 970 | Batch: 4 | Loss: 10.5951\n",
      "Epoch 970 | Batch: 5 | Loss: 11.4948\n",
      "Mean of loss / batch 11.16236400604248\n",
      "Epoch 971 | Batch: 1 | Loss: 10.9894\n",
      "Epoch 971 | Batch: 2 | Loss: 10.9808\n",
      "Epoch 971 | Batch: 3 | Loss: 10.9752\n",
      "Epoch 971 | Batch: 4 | Loss: 10.6623\n",
      "Epoch 971 | Batch: 5 | Loss: 10.9833\n",
      "Mean of loss / batch 10.918210983276367\n",
      "Epoch 972 | Batch: 1 | Loss: 11.6350\n",
      "Epoch 972 | Batch: 2 | Loss: 10.3263\n",
      "Epoch 972 | Batch: 3 | Loss: 10.6220\n",
      "Epoch 972 | Batch: 4 | Loss: 10.6092\n",
      "Epoch 972 | Batch: 5 | Loss: 11.8587\n",
      "Mean of loss / batch 11.010225296020508\n",
      "Epoch 973 | Batch: 1 | Loss: 10.9675\n",
      "Epoch 973 | Batch: 2 | Loss: 10.9666\n",
      "Epoch 973 | Batch: 3 | Loss: 10.6919\n",
      "Epoch 973 | Batch: 4 | Loss: 10.6546\n",
      "Epoch 973 | Batch: 5 | Loss: 11.3429\n",
      "Mean of loss / batch 10.924683570861816\n",
      "Epoch 974 | Batch: 1 | Loss: 10.3959\n",
      "Epoch 974 | Batch: 2 | Loss: 10.6179\n",
      "Epoch 974 | Batch: 3 | Loss: 11.4147\n",
      "Epoch 974 | Batch: 4 | Loss: 10.9755\n",
      "Epoch 974 | Batch: 5 | Loss: 11.2818\n",
      "Mean of loss / batch 10.937172889709473\n",
      "Epoch 975 | Batch: 1 | Loss: 10.2195\n",
      "Epoch 975 | Batch: 2 | Loss: 11.0077\n",
      "Epoch 975 | Batch: 3 | Loss: 11.3630\n",
      "Epoch 975 | Batch: 4 | Loss: 10.6721\n",
      "Epoch 975 | Batch: 5 | Loss: 11.6560\n",
      "Mean of loss / batch 10.98365592956543\n",
      "Epoch 976 | Batch: 1 | Loss: 11.1879\n",
      "Epoch 976 | Batch: 2 | Loss: 10.7988\n",
      "Epoch 976 | Batch: 3 | Loss: 10.7235\n",
      "Epoch 976 | Batch: 4 | Loss: 10.3813\n",
      "Epoch 976 | Batch: 5 | Loss: 11.7708\n",
      "Mean of loss / batch 10.972466468811035\n",
      "Epoch 977 | Batch: 1 | Loss: 10.9651\n",
      "Epoch 977 | Batch: 2 | Loss: 11.2228\n",
      "Epoch 977 | Batch: 3 | Loss: 11.1754\n",
      "Epoch 977 | Batch: 4 | Loss: 11.1449\n",
      "Epoch 977 | Batch: 5 | Loss: 10.4639\n",
      "Mean of loss / batch 10.994423866271973\n",
      "Epoch 978 | Batch: 1 | Loss: 11.3423\n",
      "Epoch 978 | Batch: 2 | Loss: 10.3964\n",
      "Epoch 978 | Batch: 3 | Loss: 12.1330\n",
      "Epoch 978 | Batch: 4 | Loss: 10.7656\n",
      "Epoch 978 | Batch: 5 | Loss: 10.4388\n",
      "Mean of loss / batch 11.015233039855957\n",
      "Epoch 979 | Batch: 1 | Loss: 10.2668\n",
      "Epoch 979 | Batch: 2 | Loss: 10.5946\n",
      "Epoch 979 | Batch: 3 | Loss: 11.4973\n",
      "Epoch 979 | Batch: 4 | Loss: 11.7177\n",
      "Epoch 979 | Batch: 5 | Loss: 10.7233\n",
      "Mean of loss / batch 10.959918022155762\n",
      "Epoch 980 | Batch: 1 | Loss: 10.3810\n",
      "Epoch 980 | Batch: 2 | Loss: 10.6148\n",
      "Epoch 980 | Batch: 3 | Loss: 11.4231\n",
      "Epoch 980 | Batch: 4 | Loss: 11.3053\n",
      "Epoch 980 | Batch: 5 | Loss: 10.9653\n",
      "Mean of loss / batch 10.937898635864258\n",
      "Epoch 981 | Batch: 1 | Loss: 10.9652\n",
      "Epoch 981 | Batch: 2 | Loss: 10.9651\n",
      "Epoch 981 | Batch: 3 | Loss: 10.9651\n",
      "Epoch 981 | Batch: 4 | Loss: 10.9651\n",
      "Epoch 981 | Batch: 5 | Loss: 10.7097\n",
      "Mean of loss / batch 10.914047241210938\n",
      "Epoch 982 | Batch: 1 | Loss: 10.6660\n",
      "Epoch 982 | Batch: 2 | Loss: 10.9819\n",
      "Epoch 982 | Batch: 3 | Loss: 10.9760\n",
      "Epoch 982 | Batch: 4 | Loss: 11.5948\n",
      "Epoch 982 | Batch: 5 | Loss: 10.5712\n",
      "Mean of loss / batch 10.957971572875977\n",
      "Epoch 983 | Batch: 1 | Loss: 10.9717\n",
      "Epoch 983 | Batch: 2 | Loss: 10.6710\n",
      "Epoch 983 | Batch: 3 | Loss: 9.9628\n",
      "Epoch 983 | Batch: 4 | Loss: 12.4755\n",
      "Epoch 983 | Batch: 5 | Loss: 10.9666\n",
      "Mean of loss / batch 11.009547233581543\n",
      "Epoch 984 | Batch: 1 | Loss: 10.4185\n",
      "Epoch 984 | Batch: 2 | Loss: 10.6230\n",
      "Epoch 984 | Batch: 3 | Loss: 11.7987\n",
      "Epoch 984 | Batch: 4 | Loss: 10.6975\n",
      "Epoch 984 | Batch: 5 | Loss: 11.2877\n",
      "Mean of loss / batch 10.965084075927734\n",
      "Epoch 985 | Batch: 1 | Loss: 11.4697\n",
      "Epoch 985 | Batch: 2 | Loss: 10.9845\n",
      "Epoch 985 | Batch: 3 | Loss: 10.6340\n",
      "Epoch 985 | Batch: 4 | Loss: 10.6801\n",
      "Epoch 985 | Batch: 5 | Loss: 10.9773\n",
      "Mean of loss / batch 10.94911003112793\n",
      "Epoch 986 | Batch: 1 | Loss: 10.6581\n",
      "Epoch 986 | Batch: 2 | Loss: 9.9277\n",
      "Epoch 986 | Batch: 3 | Loss: 11.5518\n",
      "Epoch 986 | Batch: 4 | Loss: 12.1655\n",
      "Epoch 986 | Batch: 5 | Loss: 10.7568\n",
      "Mean of loss / batch 11.011992454528809\n",
      "Epoch 987 | Batch: 1 | Loss: 10.6964\n",
      "Epoch 987 | Batch: 2 | Loss: 11.2889\n",
      "Epoch 987 | Batch: 3 | Loss: 11.2181\n",
      "Epoch 987 | Batch: 4 | Loss: 10.7669\n",
      "Epoch 987 | Batch: 5 | Loss: 10.7029\n",
      "Mean of loss / batch 10.934660911560059\n",
      "Epoch 988 | Batch: 1 | Loss: 10.9718\n",
      "Epoch 988 | Batch: 2 | Loss: 10.3722\n",
      "Epoch 988 | Batch: 3 | Loss: 11.0023\n",
      "Epoch 988 | Batch: 4 | Loss: 10.9892\n",
      "Epoch 988 | Batch: 5 | Loss: 11.3214\n",
      "Mean of loss / batch 10.931390762329102\n",
      "Epoch 989 | Batch: 1 | Loss: 10.6927\n",
      "Epoch 989 | Batch: 2 | Loss: 10.6551\n",
      "Epoch 989 | Batch: 3 | Loss: 11.3420\n",
      "Epoch 989 | Batch: 4 | Loss: 10.1114\n",
      "Epoch 989 | Batch: 5 | Loss: 12.3122\n",
      "Mean of loss / batch 11.02270221710205\n",
      "Epoch 990 | Batch: 1 | Loss: 11.4535\n",
      "Epoch 990 | Batch: 2 | Loss: 10.6960\n",
      "Epoch 990 | Batch: 3 | Loss: 10.6990\n",
      "Epoch 990 | Batch: 4 | Loss: 11.2862\n",
      "Epoch 990 | Batch: 5 | Loss: 10.7137\n",
      "Mean of loss / batch 10.969651222229004\n",
      "Epoch 991 | Batch: 1 | Loss: 11.5726\n",
      "Epoch 991 | Batch: 2 | Loss: 10.7806\n",
      "Epoch 991 | Batch: 3 | Loss: 11.2184\n",
      "Epoch 991 | Batch: 4 | Loss: 10.3608\n",
      "Epoch 991 | Batch: 5 | Loss: 10.9892\n",
      "Mean of loss / batch 10.984323501586914\n",
      "Epoch 992 | Batch: 1 | Loss: 10.9807\n",
      "Epoch 992 | Batch: 2 | Loss: 10.6519\n",
      "Epoch 992 | Batch: 3 | Loss: 11.3470\n",
      "Epoch 992 | Batch: 4 | Loss: 11.5439\n",
      "Epoch 992 | Batch: 5 | Loss: 10.4322\n",
      "Mean of loss / batch 10.991142272949219\n",
      "Epoch 993 | Batch: 1 | Loss: 10.2926\n",
      "Epoch 993 | Batch: 2 | Loss: 10.5984\n",
      "Epoch 993 | Batch: 3 | Loss: 11.9213\n",
      "Epoch 993 | Batch: 4 | Loss: 11.5816\n",
      "Epoch 993 | Batch: 5 | Loss: 10.5817\n",
      "Mean of loss / batch 10.9951171875\n",
      "Epoch 994 | Batch: 1 | Loss: 10.6649\n",
      "Epoch 994 | Batch: 2 | Loss: 10.6371\n",
      "Epoch 994 | Batch: 3 | Loss: 10.2421\n",
      "Epoch 994 | Batch: 4 | Loss: 11.0438\n",
      "Epoch 994 | Batch: 5 | Loss: 12.2566\n",
      "Mean of loss / batch 10.968914985656738\n",
      "Epoch 995 | Batch: 1 | Loss: 11.1977\n",
      "Epoch 995 | Batch: 2 | Loss: 10.6021\n",
      "Epoch 995 | Batch: 3 | Loss: 10.9694\n",
      "Epoch 995 | Batch: 4 | Loss: 10.6785\n",
      "Epoch 995 | Batch: 5 | Loss: 11.3097\n",
      "Mean of loss / batch 10.951470375061035\n",
      "Epoch 996 | Batch: 1 | Loss: 9.9009\n",
      "Epoch 996 | Batch: 2 | Loss: 11.5157\n",
      "Epoch 996 | Batch: 3 | Loss: 11.3658\n",
      "Epoch 996 | Batch: 4 | Loss: 11.5666\n",
      "Epoch 996 | Batch: 5 | Loss: 10.7833\n",
      "Mean of loss / batch 11.02647876739502\n",
      "Epoch 997 | Batch: 1 | Loss: 10.7135\n",
      "Epoch 997 | Batch: 2 | Loss: 10.9700\n",
      "Epoch 997 | Batch: 3 | Loss: 11.5516\n",
      "Epoch 997 | Batch: 4 | Loss: 10.6065\n",
      "Epoch 997 | Batch: 5 | Loss: 10.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of loss / batch 10.962138175964355\n",
      "Epoch 998 | Batch: 1 | Loss: 10.9677\n",
      "Epoch 998 | Batch: 2 | Loss: 11.2476\n",
      "Epoch 998 | Batch: 3 | Loss: 11.1915\n",
      "Epoch 998 | Batch: 4 | Loss: 10.9750\n",
      "Epoch 998 | Batch: 5 | Loss: 10.3886\n",
      "Mean of loss / batch 10.954065322875977\n",
      "Epoch 999 | Batch: 1 | Loss: 10.9863\n",
      "Epoch 999 | Batch: 2 | Loss: 11.9844\n",
      "Epoch 999 | Batch: 3 | Loss: 11.1473\n",
      "Epoch 999 | Batch: 4 | Loss: 10.5864\n",
      "Epoch 999 | Batch: 5 | Loss: 10.3551\n",
      "Mean of loss / batch 11.011906623840332\n",
      "Epoch 1000 | Batch: 1 | Loss: 11.0065\n",
      "Epoch 1000 | Batch: 2 | Loss: 11.3606\n",
      "Epoch 1000 | Batch: 3 | Loss: 10.9689\n",
      "Epoch 1000 | Batch: 4 | Loss: 10.6805\n",
      "Epoch 1000 | Batch: 5 | Loss: 10.6472\n",
      "Mean of loss / batch 10.932740211486816\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "  loss_arr = []\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "      # get the inputs\n",
    "      inputs, labels = data\n",
    "\n",
    "      # Forward pass: Compute predicted y by passing x to the model\n",
    "      y_pred = model(inputs)\n",
    "      \n",
    "      # Compute and print loss\n",
    "      loss = criterion(y_pred, labels)\n",
    "      print(f'Epoch {epoch + 1} | Batch: {i+1} | Loss: {loss.item():.4f}')\n",
    "      loss_arr.append(loss)\n",
    "      # Zero gradients, perform a backward pass, and update the weights.\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  mean = sum(loss_arr)/len(loss_arr) \n",
    "  print(f'Mean of loss / batch {mean}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DiabetesExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
