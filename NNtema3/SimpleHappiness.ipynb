{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "tVm68ThnfSQw"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "DKMMh-YnfSQ_"
   },
   "outputs": [],
   "source": [
    "#matplotlib este folosit pentru a realiza grafice\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XytQWckMfSRK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"happiness.csv\")\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ph1yGMQAfSRS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country (region)</th>\n",
       "      <th>Ladder</th>\n",
       "      <th>SD of Ladder</th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Log of GDP\\nper capita</th>\n",
       "      <th>Healthy life\\nexpectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norway</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country (region)  Ladder  SD of Ladder  Positive affect  Negative affect  \\\n",
       "0          Finland       1             4             41.0             10.0   \n",
       "1          Denmark       2            13             24.0             26.0   \n",
       "2           Norway       3             8             16.0             29.0   \n",
       "3          Iceland       4             9              3.0              3.0   \n",
       "4      Netherlands       5             1             12.0             25.0   \n",
       "\n",
       "   Social support  Freedom  Corruption  Generosity  Log of GDP\\nper capita  \\\n",
       "0             2.0      5.0         4.0        47.0                    22.0   \n",
       "1             4.0      6.0         3.0        22.0                    14.0   \n",
       "2             3.0      3.0         8.0        11.0                     7.0   \n",
       "3             1.0      7.0        45.0         3.0                    15.0   \n",
       "4            15.0     19.0        12.0         7.0                    12.0   \n",
       "\n",
       "   Healthy life\\nexpectancy  \n",
       "0                      27.0  \n",
       "1                      23.0  \n",
       "2                      12.0  \n",
       "3                      13.0  \n",
       "4                      18.0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5E3uQ9iBjyAM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sJigmCckL9c"
   },
   "source": [
    "pandas_profiling - o librărie ce oferă o analiză automată a setului de date: distributii, tipuri de variabile, valori și o serie intreaga de informatii aditionale.\n",
    "Pentru a o putea folosi trebuie să ștergem libraria default din colab și să instalăm o versiune specifică. \n",
    "După instalare trebuie să facem restart la runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntTgqB42XRSl"
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2hBghqyXR9G"
   },
   "outputs": [],
   "source": [
    "#prof=ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3bhlEFcWvKN"
   },
   "outputs": [],
   "source": [
    "#Statisticile pot fi salvate În format html\n",
    "#prof.to_file(output_file='happiness.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5okLNZ-NV4HG"
   },
   "outputs": [],
   "source": [
    "#prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS4D1RFvcQsk"
   },
   "outputs": [],
   "source": [
    "#Pentru seturi de date mari este indicat să folosim versiunea minimală a librăriei\n",
    "#prof=ProfileReport(df,minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cshaUY4VcUKC"
   },
   "outputs": [],
   "source": [
    "#prof.to_file(output_file='happiness-min.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbnJVh7JcX1m"
   },
   "outputs": [],
   "source": [
    "#prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_UUlJ8KfSRZ"
   },
   "outputs": [],
   "source": [
    "#Selectăm datele de intrare in retea eliminand ultima coloană din csv\n",
    "X = df.drop([\"Country (region)\", \"Ladder\", \"SD of Ladder\"], axis=1)\n",
    "#obținem etichetele pentru date salvand ultima coloana\n",
    "y = df['Ladder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-Cg9ewufSRh"
   },
   "outputs": [],
   "source": [
    "#folosim o functie din sklearn ce creaza seturi de date pentru antrenare si validare\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzSoXozDfSRp"
   },
   "outputs": [],
   "source": [
    "#primim ca output seturile de date corespunzatoare.\n",
    "#Test size ne spune cat de mare procentual sa avem setul de validare\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJHOFiIKjuhm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9792, 124)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificam distributia etichetelor de 0 si 1.\n",
    "#Suma etichetelor ne da numarul de intrari cu 1.\n",
    "#Ideal ar trebui sa avem o distributie echilibrata intre cele 2 valori\n",
    "sum(y_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlqD0qTQjuj8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2454, 32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNbCkEgrjumv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rEU0qmIjupE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2qY5O3UfSRu"
   },
   "outputs": [],
   "source": [
    "#Pentru normalizarea datelor folosim MinMaxScaler din sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bfdh7k1s8lz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive affect</th>\n",
       "      <th>Negative affect</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Log of GDP\\nper capita</th>\n",
       "      <th>Healthy life\\nexpectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>146.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>126.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>117.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>95.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Positive affect  Negative affect  Social support  Freedom  Corruption  \\\n",
       "26               8.0             85.0            78.0     25.0        82.0   \n",
       "110             68.0             60.0           106.0    121.0        88.0   \n",
       "136            146.0            124.0           118.0    129.0        89.0   \n",
       "31              69.0            105.0            43.0     84.0        71.0   \n",
       "11               4.0             87.0            42.0     16.0        58.0   \n",
       "..               ...              ...             ...      ...         ...   \n",
       "115            126.0            145.0           117.0    123.0        93.0   \n",
       "96             117.0             13.0            18.0    115.0       147.0   \n",
       "91               9.0            104.0            94.0     48.0       129.0   \n",
       "30               7.0             48.0            41.0     32.0       104.0   \n",
       "82              95.0             17.0            10.0    112.0       119.0   \n",
       "\n",
       "     Generosity  Log of GDP\\nper capita  Healthy life\\nexpectancy  \n",
       "26         78.0                    99.0                      85.0  \n",
       "110       130.0                   126.0                     109.0  \n",
       "136       132.0                    85.0                     101.0  \n",
       "31        108.0                    70.0                      72.0  \n",
       "11         75.0                    67.0                      28.0  \n",
       "..          ...                     ...                       ...  \n",
       "115       129.0                    91.0                      64.0  \n",
       "96        112.0                    56.0                      65.0  \n",
       "91          2.0                    83.0                      98.0  \n",
       "30         88.0                    51.0                      33.0  \n",
       "82         38.0                    80.0                      97.0  \n",
       "\n",
       "[124 rows x 8 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6UTX8sttBPn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26      27\n",
       "110    111\n",
       "136    137\n",
       "31      32\n",
       "11      12\n",
       "      ... \n",
       "115    116\n",
       "96      97\n",
       "91      92\n",
       "30      31\n",
       "82      83\n",
       "Name: Ladder, Length: 124, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CTwxoWZfSRy"
   },
   "outputs": [],
   "source": [
    "# Functia va translata fiecare feature in parte in intervalul (-1,1)\n",
    "# Funcția practic relizează următoarele\n",
    "# X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "# X_scaled = X_std * (max - min) + min\n",
    "\n",
    "\n",
    "sc = MinMaxScaler((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeLHff3CfSR3"
   },
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEqnXDHmfSR9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81818182, -0.32467532, -0.62580645, -0.34193548,  0.90540541,\n",
       "        -0.47096774, -0.5       ,  0.24      ],\n",
       "       [ 0.01298701, -0.35064935,  0.69032258,  0.00645161, -0.54054054,\n",
       "        -0.36774194,  0.64473684,  0.57333333],\n",
       "       [-0.98701299, -0.49350649, -0.61290323, -0.56129032,  0.02702703,\n",
       "        -0.13548387,  0.18421053,  0.08      ],\n",
       "       [ 0.27272727,  0.63636364,  0.96129032,  0.74193548, -0.68918919,\n",
       "         0.92258065,  0.98684211,  0.8       ],\n",
       "       [-0.66233766, -0.25974026,  0.32903226,  0.45806452, -0.44594595,\n",
       "         0.87096774,  0.26315789, -1.        ],\n",
       "       [ 0.94805195, -0.20779221,  0.1483871 ,  0.75483871,  0.7972973 ,\n",
       "        -0.18709677, -0.03947368, -0.12      ],\n",
       "       [ 0.45454545,  0.55844156,  0.13548387,  0.13548387, -1.        ,\n",
       "         0.52258065,  0.21052632, -0.16      ],\n",
       "       [ 0.32467532,  0.22077922,  0.31612903,  0.93548387,  0.66216216,\n",
       "         0.96129032, -0.39473684, -0.72      ],\n",
       "       [-0.76623377, -0.36363636, -0.74193548, -0.88387097, -0.85135135,\n",
       "        -0.81935484, -0.75      , -0.89333333],\n",
       "       [ 0.38961039,  0.38961039, -0.66451613,  0.22580645,  0.05405405,\n",
       "        -0.35483871, -0.60526316, -0.96      ],\n",
       "       [ 1.01298701,  1.01298701,  0.98709677,  0.97419355, -0.48648649,\n",
       "        -0.10967742, -1.        ,  0.70666667],\n",
       "       [-0.68831169, -0.66233766, -0.9483871 , -0.92258065, -0.95945946,\n",
       "        -0.71612903, -0.81578947, -0.69333333],\n",
       "       [-0.48051948,  0.03896104, -0.18709677,  0.09677419,  0.37837838,\n",
       "         0.1483871 ,  0.01315789,  0.64      ],\n",
       "       [ 0.        ,  0.75324675, -0.36774194,  0.87096774,  0.48648649,\n",
       "         0.79354839,  0.02631579, -0.05333333],\n",
       "       [-0.22077922,  0.28571429,  0.16129032,  0.04516129,  0.55405405,\n",
       "        -0.49677419, -0.56578947, -0.92      ],\n",
       "       [ 0.02597403,  0.83116883,  0.80645161,  0.43225806, -0.31081081,\n",
       "         0.74193548,  0.94736842,  0.84      ],\n",
       "       [ 0.31168831, -0.41558442,  0.17419355,  0.85806452,  0.35135135,\n",
       "        -0.48387097, -0.64473684, -0.88      ],\n",
       "       [ 0.61038961,  0.76623377,  0.78064516,  0.18709677, -0.18918919,\n",
       "         0.80645161,  0.46052632,  0.54666667],\n",
       "       [-0.63636364,  0.20779221, -0.40645161, -0.30322581,  0.47297297,\n",
       "         0.58709677, -0.27631579, -0.50666667],\n",
       "       [-0.46753247, -0.87012987, -0.97419355, -0.93548387, -0.94594595,\n",
       "        -0.39354839, -0.71052632, -0.64      ],\n",
       "       [-0.87012987, -0.01298701, -0.5483871 , -0.61290323, -0.55405405,\n",
       "         0.03225806, -0.31578947, -0.53333333],\n",
       "       [-0.36363636,  0.06493506, -0.2       , -0.12258065, -1.        ,\n",
       "         0.05806452, -0.85526316, -0.01333333],\n",
       "       [ 0.53246753,  0.92207792,  0.97419355,  0.32903226,  0.01351351,\n",
       "         0.49677419,  0.68421053,  0.77333333],\n",
       "       [-0.75324675, -0.80519481, -0.85806452, -0.98709677, -0.75675676,\n",
       "        -0.62580645,  0.36842105,  0.10666667],\n",
       "       [ 0.68831169,  0.44155844,  0.67741935,  0.47096774, -0.25675676,\n",
       "        -0.2516129 ,  0.44736842,  0.52      ],\n",
       "       [ 0.18181818,  0.80519481,  0.47096774,  0.27741935,  0.28378378,\n",
       "        -0.04516129,  0.78947368,  0.69333333],\n",
       "       [-0.38961039, -0.51948052, -0.90967742, -0.78064516, -0.82432432,\n",
       "        -0.92258065, -0.76315789, -0.86666667],\n",
       "       [ 0.06493506,  0.85714286,  0.75483871,  0.40645161, -0.05405405,\n",
       "         0.21290323,  0.71052632,  0.82666667],\n",
       "       [-0.93506494,  0.45454545,  0.5483871 , -0.71612903, -0.63513514,\n",
       "        -0.56129032,  0.34210526,  0.49333333],\n",
       "       [-0.24675325, -0.94805195, -0.41935484, -0.50967742,  0.86486486,\n",
       "        -0.53548387,  0.57894737,  0.21333333],\n",
       "       [ 0.07792208,  0.33766234, -0.79354839, -0.84516129, -0.56756757,\n",
       "        -0.93548387, -0.63157895, -0.74666667],\n",
       "       [ 0.90909091,  0.71428571,  0.56129032,  0.84516129,  0.36486486,\n",
       "         0.85806452,  0.10526316, -0.10666667]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xa9U77VcfSSE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqEBq7LAfSSK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMSDboU8fSSQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CBOO0C3fSSV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 8)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MPgMngsfSSa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124,)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZv_HSpDtU2v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cE4YqjFxfSSg"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBgAcgm6uD9v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 1])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(124, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPIV0ruYuECM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(32, 1)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQjv5QsKfSSk"
   },
   "outputs": [],
   "source": [
    "class HappinessNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HappinessNN, self).__init__()\n",
    "\n",
    "        #Sequential oferă o alternativă mai estetică a codului\n",
    "        #Rețeaua noastră are 2 neuroni pentru output. \n",
    "        #Unul va prezice probabilitatea pentru cazul afirmativ al bolii, iar celălalt va prezice probabilitatea cazului negativ al bolii.\n",
    "        self.sequential= nn.Sequential(\n",
    "            nn.Linear(8,100),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(100, 60),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qI_tjxPWfSSn"
   },
   "outputs": [],
   "source": [
    "net = HappinessNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eI80PhVafSSt"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaqzqBOcfSSx"
   },
   "outputs": [],
   "source": [
    "#Colectăm loss-urile din antrenare pentru a le plota ulterior\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qt8b44MfSS3"
   },
   "outputs": [],
   "source": [
    "# Colectăm accuratetea pentru a o plota ulterior\n",
    "accuracies=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2779h43uwuO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_woyjjffSTA"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(epoch):\n",
    "    # Setează câteva flaguri în rețeaua neurală. Specific activează Dropout-ul și BatchNormalization dacă este cazul.\n",
    "    # În exemplul nostru are un rol pur demonstrativ, nefiind necesar.\n",
    "    net.train()\n",
    "\n",
    "    #Obținem predictii\n",
    "    outputs = net(X_train)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Train Epoch: {epoch} Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNNf-W4shrIH"
   },
   "outputs": [],
   "source": [
    "# Colectăm loss-ul din validare pentru a o plota ulterior\n",
    "test_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8by5McSEfSTF"
   },
   "outputs": [],
   "source": [
    "def validation():\n",
    "    #Pune pe off flagurile setate in model.train()\n",
    "    #Din nou, în exemplul nostru e pur demonstrativ.\n",
    "    net.eval()\n",
    "\n",
    "    test_loss=0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output=net(X_test)\n",
    "        \n",
    "        test_loss= criterion(output, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        #Obținem predictiile pentru fiecare linie din setul de validare.\n",
    "        #Practic ne returnează rezultatul cu cea mai mare probabilitate pentru fiecare intrare din setul de validare \n",
    "        pred = output\n",
    "\n",
    "        #Verificăm câte predicții sunt corecte și le însumăm numărul pentru a afla totalul de predicții corecte\n",
    "        #correct += pred.eq(y_test.data.view_as(pred)).sum()\n",
    "        #O altă functie din sklearn ne poate ajuta să abstractizăm operatia de mai sus.\n",
    "        #print(pred.shape)\n",
    "        #print(y_test.shape)\n",
    "        #print(pred)\n",
    "        #print(y_test)\n",
    "        #accuracy = accuracy_score(y_test[:, 0], pred[:, 0])\n",
    "        \n",
    "        print(\"============\")\n",
    "        print(f\"[Validation set] Average loss: {test_loss}, Accuracy: nu exista la regresii%\")\n",
    "        print(\"============\")\n",
    "\n",
    "        #ccuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuyLaJgafSTJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Loss:211.1588134765625\n",
      "============\n",
      "[Validation set] Average loss: 627.1766967773438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 1 Loss:210.84774780273438\n",
      "============\n",
      "[Validation set] Average loss: 644.7625732421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 2 Loss:210.7075653076172\n",
      "============\n",
      "[Validation set] Average loss: 627.9705810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 3 Loss:210.3965301513672\n",
      "============\n",
      "[Validation set] Average loss: 645.3463745117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 4 Loss:210.2554473876953\n",
      "============\n",
      "[Validation set] Average loss: 628.7661743164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 5 Loss:209.9446258544922\n",
      "============\n",
      "[Validation set] Average loss: 645.933349609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 6 Loss:209.80276489257812\n",
      "============\n",
      "[Validation set] Average loss: 629.5635375976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 7 Loss:209.4923858642578\n",
      "============\n",
      "[Validation set] Average loss: 646.5231323242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 8 Loss:209.34971618652344\n",
      "============\n",
      "[Validation set] Average loss: 630.3627319335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 9 Loss:209.03968811035156\n",
      "============\n",
      "[Validation set] Average loss: 647.1158447265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 10 Loss:208.89622497558594\n",
      "============\n",
      "[Validation set] Average loss: 631.16357421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 11 Loss:208.5865936279297\n",
      "============\n",
      "[Validation set] Average loss: 647.711669921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 12 Loss:208.4424285888672\n",
      "============\n",
      "[Validation set] Average loss: 631.9654541015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 13 Loss:208.13345336914062\n",
      "============\n",
      "[Validation set] Average loss: 648.3101196289062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 14 Loss:207.98846435546875\n",
      "============\n",
      "[Validation set] Average loss: 632.7684326171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 15 Loss:207.68002319335938\n",
      "============\n",
      "[Validation set] Average loss: 648.9112548828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 16 Loss:207.5343475341797\n",
      "============\n",
      "[Validation set] Average loss: 633.5723266601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 17 Loss:207.22659301757812\n",
      "============\n",
      "[Validation set] Average loss: 649.5154418945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 18 Loss:207.0802459716797\n",
      "============\n",
      "[Validation set] Average loss: 634.3770751953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 19 Loss:206.77325439453125\n",
      "============\n",
      "[Validation set] Average loss: 650.1220703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 20 Loss:206.62623596191406\n",
      "============\n",
      "[Validation set] Average loss: 635.1821899414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 21 Loss:206.3199920654297\n",
      "============\n",
      "[Validation set] Average loss: 650.731201171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 22 Loss:206.17233276367188\n",
      "============\n",
      "[Validation set] Average loss: 635.9877319335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 23 Loss:205.86708068847656\n",
      "============\n",
      "[Validation set] Average loss: 651.3428344726562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 24 Loss:205.71875\n",
      "============\n",
      "[Validation set] Average loss: 636.7935791015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 25 Loss:205.41458129882812\n",
      "============\n",
      "[Validation set] Average loss: 651.95703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 26 Loss:205.2655792236328\n",
      "============\n",
      "[Validation set] Average loss: 637.5991821289062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 27 Loss:204.96243286132812\n",
      "============\n",
      "[Validation set] Average loss: 652.5733642578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 28 Loss:204.8129119873047\n",
      "============\n",
      "[Validation set] Average loss: 638.4046020507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 29 Loss:204.5108184814453\n",
      "============\n",
      "[Validation set] Average loss: 653.19189453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 30 Loss:204.3607177734375\n",
      "============\n",
      "[Validation set] Average loss: 639.2095336914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 31 Loss:204.0598907470703\n",
      "============\n",
      "[Validation set] Average loss: 653.8125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 32 Loss:203.90927124023438\n",
      "============\n",
      "[Validation set] Average loss: 640.0138549804688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 33 Loss:203.60952758789062\n",
      "============\n",
      "[Validation set] Average loss: 654.4352416992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 34 Loss:203.45860290527344\n",
      "============\n",
      "[Validation set] Average loss: 640.8170166015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 35 Loss:203.1601104736328\n",
      "============\n",
      "[Validation set] Average loss: 655.0595703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 36 Loss:203.00869750976562\n",
      "============\n",
      "[Validation set] Average loss: 641.6192626953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 37 Loss:202.71151733398438\n",
      "============\n",
      "[Validation set] Average loss: 655.6859130859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 38 Loss:202.55978393554688\n",
      "============\n",
      "[Validation set] Average loss: 642.4203491210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 39 Loss:202.2638702392578\n",
      "============\n",
      "[Validation set] Average loss: 656.3135986328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 40 Loss:202.1118621826172\n",
      "============\n",
      "[Validation set] Average loss: 643.2196044921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 41 Loss:201.81723022460938\n",
      "============\n",
      "[Validation set] Average loss: 656.9426879882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 42 Loss:201.66500854492188\n",
      "============\n",
      "[Validation set] Average loss: 644.0173950195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 43 Loss:201.37181091308594\n",
      "============\n",
      "[Validation set] Average loss: 657.5733032226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 44 Loss:201.2192840576172\n",
      "============\n",
      "[Validation set] Average loss: 644.8131103515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 45 Loss:200.92764282226562\n",
      "============\n",
      "[Validation set] Average loss: 658.204833984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 46 Loss:200.77496337890625\n",
      "============\n",
      "[Validation set] Average loss: 645.6065063476562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 47 Loss:200.48463439941406\n",
      "============\n",
      "[Validation set] Average loss: 658.8372192382812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 48 Loss:200.3318328857422\n",
      "============\n",
      "[Validation set] Average loss: 646.3975219726562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 49 Loss:200.04296875\n",
      "============\n",
      "[Validation set] Average loss: 659.4708862304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 50 Loss:199.89012145996094\n",
      "============\n",
      "[Validation set] Average loss: 647.185791015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 51 Loss:199.60281372070312\n",
      "============\n",
      "[Validation set] Average loss: 660.1047973632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 52 Loss:199.44984436035156\n",
      "============\n",
      "[Validation set] Average loss: 647.9712524414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 53 Loss:199.16403198242188\n",
      "============\n",
      "[Validation set] Average loss: 660.7393188476562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 54 Loss:199.0111541748047\n",
      "============\n",
      "[Validation set] Average loss: 648.7532958984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 55 Loss:198.72694396972656\n",
      "============\n",
      "[Validation set] Average loss: 661.3742065429688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 56 Loss:198.5740966796875\n",
      "============\n",
      "[Validation set] Average loss: 649.5321655273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 57 Loss:198.2913360595703\n",
      "============\n",
      "[Validation set] Average loss: 662.0091552734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 58 Loss:198.1387176513672\n",
      "============\n",
      "[Validation set] Average loss: 650.3073120117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 59 Loss:197.85760498046875\n",
      "============\n",
      "[Validation set] Average loss: 662.6441040039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 60 Loss:197.7051544189453\n",
      "============\n",
      "[Validation set] Average loss: 651.0785522460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 61 Loss:197.4256591796875\n",
      "============\n",
      "[Validation set] Average loss: 663.2791748046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 62 Loss:197.2735137939453\n",
      "============\n",
      "[Validation set] Average loss: 651.8457641601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 63 Loss:196.99563598632812\n",
      "============\n",
      "[Validation set] Average loss: 663.9136352539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 64 Loss:196.8438262939453\n",
      "============\n",
      "[Validation set] Average loss: 652.6087646484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 65 Loss:196.56773376464844\n",
      "============\n",
      "[Validation set] Average loss: 664.5480346679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 66 Loss:196.41641235351562\n",
      "============\n",
      "[Validation set] Average loss: 653.366943359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 67 Loss:196.14207458496094\n",
      "============\n",
      "[Validation set] Average loss: 665.1817626953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 68 Loss:195.9912109375\n",
      "============\n",
      "[Validation set] Average loss: 654.1204223632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 69 Loss:195.7186737060547\n",
      "============\n",
      "[Validation set] Average loss: 665.81494140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 70 Loss:195.56837463378906\n",
      "============\n",
      "[Validation set] Average loss: 654.8688354492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 71 Loss:195.2977294921875\n",
      "============\n",
      "[Validation set] Average loss: 666.447509765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 72 Loss:195.14816284179688\n",
      "============\n",
      "[Validation set] Average loss: 655.6121826171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 73 Loss:194.87945556640625\n",
      "============\n",
      "[Validation set] Average loss: 667.0792236328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 74 Loss:194.73085021972656\n",
      "============\n",
      "[Validation set] Average loss: 656.3499755859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 75 Loss:194.4641571044922\n",
      "============\n",
      "[Validation set] Average loss: 667.7102661132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 76 Loss:194.31640625\n",
      "============\n",
      "[Validation set] Average loss: 657.082275390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 77 Loss:194.05186462402344\n",
      "============\n",
      "[Validation set] Average loss: 668.34033203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 78 Loss:193.90516662597656\n",
      "============\n",
      "[Validation set] Average loss: 657.8087158203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 79 Loss:193.64280700683594\n",
      "============\n",
      "[Validation set] Average loss: 668.9696655273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 80 Loss:193.49734497070312\n",
      "============\n",
      "[Validation set] Average loss: 658.5292358398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 81 Loss:193.23744201660156\n",
      "============\n",
      "[Validation set] Average loss: 669.5982666015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 82 Loss:193.0933074951172\n",
      "============\n",
      "[Validation set] Average loss: 659.2439575195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 83 Loss:192.83602905273438\n",
      "============\n",
      "[Validation set] Average loss: 670.2264404296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 84 Loss:192.69357299804688\n",
      "============\n",
      "[Validation set] Average loss: 659.952392578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 85 Loss:192.43890380859375\n",
      "============\n",
      "[Validation set] Average loss: 670.8539428710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 86 Loss:192.29827880859375\n",
      "============\n",
      "[Validation set] Average loss: 660.6549072265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 87 Loss:192.0464324951172\n",
      "============\n",
      "[Validation set] Average loss: 671.4813232421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 88 Loss:191.9079132080078\n",
      "============\n",
      "[Validation set] Average loss: 661.3515014648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 89 Loss:191.6591796875\n",
      "============\n",
      "[Validation set] Average loss: 672.1082153320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 90 Loss:191.52301025390625\n",
      "============\n",
      "[Validation set] Average loss: 662.0420532226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 91 Loss:191.27737426757812\n",
      "============\n",
      "[Validation set] Average loss: 672.7354125976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 92 Loss:191.1439971923828\n",
      "============\n",
      "[Validation set] Average loss: 662.726806640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 93 Loss:190.90171813964844\n",
      "============\n",
      "[Validation set] Average loss: 673.363037109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 94 Loss:190.7713165283203\n",
      "============\n",
      "[Validation set] Average loss: 663.4061279296875, Accuracy: nu exista la regresii%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "Train Epoch: 95 Loss:190.53248596191406\n",
      "============\n",
      "[Validation set] Average loss: 673.9905395507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 96 Loss:190.4054412841797\n",
      "============\n",
      "[Validation set] Average loss: 664.0800170898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 97 Loss:190.17007446289062\n",
      "============\n",
      "[Validation set] Average loss: 674.6183471679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 98 Loss:190.0467071533203\n",
      "============\n",
      "[Validation set] Average loss: 664.7486572265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 99 Loss:189.8146514892578\n",
      "============\n",
      "[Validation set] Average loss: 675.2460327148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 100 Loss:189.69522094726562\n",
      "============\n",
      "[Validation set] Average loss: 665.4119873046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 101 Loss:189.46630859375\n",
      "============\n",
      "[Validation set] Average loss: 675.8731689453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 102 Loss:189.35073852539062\n",
      "============\n",
      "[Validation set] Average loss: 666.0702514648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 103 Loss:189.12464904785156\n",
      "============\n",
      "[Validation set] Average loss: 676.4988403320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 104 Loss:189.01303100585938\n",
      "============\n",
      "[Validation set] Average loss: 666.7235107421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 105 Loss:188.78915405273438\n",
      "============\n",
      "[Validation set] Average loss: 677.1223754882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 106 Loss:188.68141174316406\n",
      "============\n",
      "[Validation set] Average loss: 667.371337890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 107 Loss:188.45899963378906\n",
      "============\n",
      "[Validation set] Average loss: 677.7428588867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 108 Loss:188.35470581054688\n",
      "============\n",
      "[Validation set] Average loss: 668.01416015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 109 Loss:188.13316345214844\n",
      "============\n",
      "[Validation set] Average loss: 678.3589477539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 110 Loss:188.0318603515625\n",
      "============\n",
      "[Validation set] Average loss: 668.6510620117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 111 Loss:187.81036376953125\n",
      "============\n",
      "[Validation set] Average loss: 678.969970703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 112 Loss:187.7116241455078\n",
      "============\n",
      "[Validation set] Average loss: 669.2826538085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 113 Loss:187.48931884765625\n",
      "============\n",
      "[Validation set] Average loss: 679.574951171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 114 Loss:187.39271545410156\n",
      "============\n",
      "[Validation set] Average loss: 669.9086303710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 115 Loss:187.16873168945312\n",
      "============\n",
      "[Validation set] Average loss: 680.17333984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 116 Loss:187.07374572753906\n",
      "============\n",
      "[Validation set] Average loss: 670.5289306640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 117 Loss:186.84754943847656\n",
      "============\n",
      "[Validation set] Average loss: 680.7645263671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 118 Loss:186.75367736816406\n",
      "============\n",
      "[Validation set] Average loss: 671.1438598632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 119 Loss:186.5246124267578\n",
      "============\n",
      "[Validation set] Average loss: 681.3482055664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 120 Loss:186.43136596679688\n",
      "============\n",
      "[Validation set] Average loss: 671.7537841796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 121 Loss:186.19918823242188\n",
      "============\n",
      "[Validation set] Average loss: 681.9246826171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 122 Loss:186.10630798339844\n",
      "============\n",
      "[Validation set] Average loss: 672.358642578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 123 Loss:185.87057495117188\n",
      "============\n",
      "[Validation set] Average loss: 682.4934692382812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 124 Loss:185.77798461914062\n",
      "============\n",
      "[Validation set] Average loss: 672.9593505859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 125 Loss:185.5386199951172\n",
      "============\n",
      "[Validation set] Average loss: 683.0556030273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 126 Loss:185.4461669921875\n",
      "============\n",
      "[Validation set] Average loss: 673.555419921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 127 Loss:185.20318603515625\n",
      "============\n",
      "[Validation set] Average loss: 683.6112060546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 128 Loss:185.1107635498047\n",
      "============\n",
      "[Validation set] Average loss: 674.1478881835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 129 Loss:184.86436462402344\n",
      "============\n",
      "[Validation set] Average loss: 684.1607055664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 130 Loss:184.77203369140625\n",
      "============\n",
      "[Validation set] Average loss: 674.73681640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 131 Loss:184.52235412597656\n",
      "============\n",
      "[Validation set] Average loss: 684.705078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 132 Loss:184.4303741455078\n",
      "============\n",
      "[Validation set] Average loss: 675.3224487304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 133 Loss:184.17776489257812\n",
      "============\n",
      "[Validation set] Average loss: 685.2446899414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 134 Loss:184.0863494873047\n",
      "============\n",
      "[Validation set] Average loss: 675.9052734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 135 Loss:183.83119201660156\n",
      "============\n",
      "[Validation set] Average loss: 685.7806396484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 136 Loss:183.7406768798828\n",
      "============\n",
      "[Validation set] Average loss: 676.4851684570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 137 Loss:183.48321533203125\n",
      "============\n",
      "[Validation set] Average loss: 686.31298828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 138 Loss:183.3938446044922\n",
      "============\n",
      "[Validation set] Average loss: 677.0625610351562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 139 Loss:183.13473510742188\n",
      "============\n",
      "[Validation set] Average loss: 686.8428955078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 140 Loss:183.046875\n",
      "============\n",
      "[Validation set] Average loss: 677.6377563476562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 141 Loss:182.7865447998047\n",
      "============\n",
      "[Validation set] Average loss: 687.3706665039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 142 Loss:182.70057678222656\n",
      "============\n",
      "[Validation set] Average loss: 678.2103881835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 143 Loss:182.43919372558594\n",
      "============\n",
      "[Validation set] Average loss: 687.89697265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 144 Loss:182.3555908203125\n",
      "============\n",
      "[Validation set] Average loss: 678.7810668945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 145 Loss:182.09371948242188\n",
      "============\n",
      "[Validation set] Average loss: 688.4222412109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 146 Loss:182.01275634765625\n",
      "============\n",
      "[Validation set] Average loss: 679.3494873046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 147 Loss:181.75076293945312\n",
      "============\n",
      "[Validation set] Average loss: 688.94677734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 148 Loss:181.6727752685547\n",
      "============\n",
      "[Validation set] Average loss: 679.9155883789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 149 Loss:181.41082763671875\n",
      "============\n",
      "[Validation set] Average loss: 689.4712524414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 150 Loss:181.33627319335938\n",
      "============\n",
      "[Validation set] Average loss: 680.479736328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 151 Loss:181.07464599609375\n",
      "============\n",
      "[Validation set] Average loss: 689.9954223632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 152 Loss:181.00384521484375\n",
      "============\n",
      "[Validation set] Average loss: 681.0416259765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 153 Loss:180.7427520751953\n",
      "============\n",
      "[Validation set] Average loss: 690.52001953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 154 Loss:180.67591857910156\n",
      "============\n",
      "[Validation set] Average loss: 681.6011962890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 155 Loss:180.41563415527344\n",
      "============\n",
      "[Validation set] Average loss: 691.0450439453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 156 Loss:180.35296630859375\n",
      "============\n",
      "[Validation set] Average loss: 682.1585693359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 157 Loss:180.09335327148438\n",
      "============\n",
      "[Validation set] Average loss: 691.5701904296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 158 Loss:180.03521728515625\n",
      "============\n",
      "[Validation set] Average loss: 682.713623046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 159 Loss:179.77633666992188\n",
      "============\n",
      "[Validation set] Average loss: 692.0960083007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 160 Loss:179.72280883789062\n",
      "============\n",
      "[Validation set] Average loss: 683.26611328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 161 Loss:179.46469116210938\n",
      "============\n",
      "[Validation set] Average loss: 692.622314453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 162 Loss:179.41600036621094\n",
      "============\n",
      "[Validation set] Average loss: 683.8161010742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 163 Loss:179.15853881835938\n",
      "============\n",
      "[Validation set] Average loss: 693.1486206054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 164 Loss:179.1147918701172\n",
      "============\n",
      "[Validation set] Average loss: 684.3636474609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 165 Loss:178.8577880859375\n",
      "============\n",
      "[Validation set] Average loss: 693.67529296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 166 Loss:178.81907653808594\n",
      "============\n",
      "[Validation set] Average loss: 684.9086303710938, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 167 Loss:178.56224060058594\n",
      "============\n",
      "[Validation set] Average loss: 694.2019653320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 168 Loss:178.5287628173828\n",
      "============\n",
      "[Validation set] Average loss: 685.4508056640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 169 Loss:178.27191162109375\n",
      "============\n",
      "[Validation set] Average loss: 694.7282104492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 170 Loss:178.2436065673828\n",
      "============\n",
      "[Validation set] Average loss: 685.9901733398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 171 Loss:177.98646545410156\n",
      "============\n",
      "[Validation set] Average loss: 695.2543334960938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 172 Loss:177.9633331298828\n",
      "============\n",
      "[Validation set] Average loss: 686.5264282226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 173 Loss:177.70547485351562\n",
      "============\n",
      "[Validation set] Average loss: 695.7794189453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 174 Loss:177.68759155273438\n",
      "============\n",
      "[Validation set] Average loss: 687.0595703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 175 Loss:177.42864990234375\n",
      "============\n",
      "[Validation set] Average loss: 696.3033447265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 176 Loss:177.41603088378906\n",
      "============\n",
      "[Validation set] Average loss: 687.5895385742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 177 Loss:177.15557861328125\n",
      "============\n",
      "[Validation set] Average loss: 696.8256225585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 178 Loss:177.14813232421875\n",
      "============\n",
      "[Validation set] Average loss: 688.1157836914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 179 Loss:176.88587951660156\n",
      "============\n",
      "[Validation set] Average loss: 697.3457641601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 180 Loss:176.8834991455078\n",
      "============\n",
      "[Validation set] Average loss: 688.6384887695312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 181 Loss:176.6187744140625\n",
      "============\n",
      "[Validation set] Average loss: 697.8634033203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 182 Loss:176.62152099609375\n",
      "============\n",
      "[Validation set] Average loss: 689.1571655273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 183 Loss:176.35391235351562\n",
      "============\n",
      "[Validation set] Average loss: 698.3771362304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 184 Loss:176.36143493652344\n",
      "============\n",
      "[Validation set] Average loss: 689.6716918945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 185 Loss:176.0904541015625\n",
      "============\n",
      "[Validation set] Average loss: 698.886962890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 186 Loss:176.10260009765625\n",
      "============\n",
      "[Validation set] Average loss: 690.1815795898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 187 Loss:175.82763671875\n",
      "============\n",
      "[Validation set] Average loss: 699.3912963867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 188 Loss:175.84402465820312\n",
      "============\n",
      "[Validation set] Average loss: 690.6866455078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 189 Loss:175.5645751953125\n",
      "============\n",
      "[Validation set] Average loss: 699.8893432617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 190 Loss:175.58477783203125\n",
      "============\n",
      "[Validation set] Average loss: 691.1866455078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 191 Loss:175.3002166748047\n",
      "============\n",
      "[Validation set] Average loss: 700.380126953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 192 Loss:175.32363891601562\n",
      "============\n",
      "[Validation set] Average loss: 691.6815185546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 193 Loss:175.03338623046875\n",
      "============\n",
      "[Validation set] Average loss: 700.8622436523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 194 Loss:175.05918884277344\n",
      "============\n",
      "[Validation set] Average loss: 692.1708984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 195 Loss:174.7626190185547\n",
      "============\n",
      "[Validation set] Average loss: 701.3344116210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 196 Loss:174.79000854492188\n",
      "============\n",
      "[Validation set] Average loss: 692.6549072265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 197 Loss:174.48667907714844\n",
      "============\n",
      "[Validation set] Average loss: 701.7960205078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 198 Loss:174.51463317871094\n",
      "============\n",
      "[Validation set] Average loss: 693.1338500976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 199 Loss:174.2039794921875\n",
      "============\n",
      "[Validation set] Average loss: 702.2460327148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 200 Loss:174.23159790039062\n",
      "============\n",
      "[Validation set] Average loss: 693.607666015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 201 Loss:173.9132843017578\n",
      "============\n",
      "[Validation set] Average loss: 702.683837890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 202 Loss:173.9395751953125\n",
      "============\n",
      "[Validation set] Average loss: 694.0770263671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 203 Loss:173.6135711669922\n",
      "============\n",
      "[Validation set] Average loss: 703.1093139648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 204 Loss:173.63778686523438\n",
      "============\n",
      "[Validation set] Average loss: 694.542236328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 205 Loss:173.30397033691406\n",
      "============\n",
      "[Validation set] Average loss: 703.5225830078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 206 Loss:173.3253936767578\n",
      "============\n",
      "[Validation set] Average loss: 695.0042114257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 207 Loss:172.9840087890625\n",
      "============\n",
      "[Validation set] Average loss: 703.92431640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 208 Loss:173.00230407714844\n",
      "============\n",
      "[Validation set] Average loss: 695.46337890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 209 Loss:172.65394592285156\n",
      "============\n",
      "[Validation set] Average loss: 704.3152465820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 210 Loss:172.6688232421875\n",
      "============\n",
      "[Validation set] Average loss: 695.92041015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 211 Loss:172.3139190673828\n",
      "============\n",
      "[Validation set] Average loss: 704.6962890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 212 Loss:172.32550048828125\n",
      "============\n",
      "[Validation set] Average loss: 696.3765258789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 213 Loss:171.96498107910156\n",
      "============\n",
      "[Validation set] Average loss: 705.0689086914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 214 Loss:171.9735107421875\n",
      "============\n",
      "[Validation set] Average loss: 696.8322143554688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 215 Loss:171.60818481445312\n",
      "============\n",
      "[Validation set] Average loss: 705.434326171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 216 Loss:171.61407470703125\n",
      "============\n",
      "[Validation set] Average loss: 697.2879638671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 217 Loss:171.24501037597656\n",
      "============\n",
      "[Validation set] Average loss: 705.7938232421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 218 Loss:171.2488250732422\n",
      "============\n",
      "[Validation set] Average loss: 697.7444458007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 219 Loss:170.8770751953125\n",
      "============\n",
      "[Validation set] Average loss: 706.14892578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 220 Loss:170.87960815429688\n",
      "============\n",
      "[Validation set] Average loss: 698.2023315429688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 221 Loss:170.50608825683594\n",
      "============\n",
      "[Validation set] Average loss: 706.5009765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 222 Loss:170.5079803466797\n",
      "============\n",
      "[Validation set] Average loss: 698.6618041992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 223 Loss:170.13360595703125\n",
      "============\n",
      "[Validation set] Average loss: 706.8505859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 224 Loss:170.13575744628906\n",
      "============\n",
      "[Validation set] Average loss: 699.123046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 225 Loss:169.7613067626953\n",
      "============\n",
      "[Validation set] Average loss: 707.1988525390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 226 Loss:169.76438903808594\n",
      "============\n",
      "[Validation set] Average loss: 699.586181640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 227 Loss:169.3907470703125\n",
      "============\n",
      "[Validation set] Average loss: 707.546142578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 228 Loss:169.39540100097656\n",
      "============\n",
      "[Validation set] Average loss: 700.0509643554688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 229 Loss:169.02304077148438\n",
      "============\n",
      "[Validation set] Average loss: 707.893310546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 230 Loss:169.02978515625\n",
      "============\n",
      "[Validation set] Average loss: 700.517822265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 231 Loss:168.6592559814453\n",
      "============\n",
      "[Validation set] Average loss: 708.2403564453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 232 Loss:168.66876220703125\n",
      "============\n",
      "[Validation set] Average loss: 700.986083984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 233 Loss:168.3003387451172\n",
      "============\n",
      "[Validation set] Average loss: 708.5870361328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 234 Loss:168.3129425048828\n",
      "============\n",
      "[Validation set] Average loss: 701.4559326171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 235 Loss:167.9467010498047\n",
      "============\n",
      "[Validation set] Average loss: 708.9334716796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 236 Loss:167.96275329589844\n",
      "============\n",
      "[Validation set] Average loss: 701.9267578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 237 Loss:167.59881591796875\n",
      "============\n",
      "[Validation set] Average loss: 709.279052734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 238 Loss:167.6186065673828\n",
      "============\n",
      "[Validation set] Average loss: 702.398193359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 239 Loss:167.25692749023438\n",
      "============\n",
      "[Validation set] Average loss: 709.6234741210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 240 Loss:167.28036499023438\n",
      "============\n",
      "[Validation set] Average loss: 702.869873046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 241 Loss:166.92098999023438\n",
      "============\n",
      "[Validation set] Average loss: 709.9662475585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 242 Loss:166.94822692871094\n",
      "============\n",
      "[Validation set] Average loss: 703.3416137695312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 243 Loss:166.5906982421875\n",
      "============\n",
      "[Validation set] Average loss: 710.30615234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 244 Loss:166.62181091308594\n",
      "============\n",
      "[Validation set] Average loss: 703.8126220703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 245 Loss:166.26602172851562\n",
      "============\n",
      "[Validation set] Average loss: 710.6427001953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 246 Loss:166.30081176757812\n",
      "============\n",
      "[Validation set] Average loss: 704.282470703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 247 Loss:165.94642639160156\n",
      "============\n",
      "[Validation set] Average loss: 710.974853515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 248 Loss:165.98471069335938\n",
      "============\n",
      "[Validation set] Average loss: 704.7503051757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 249 Loss:165.63140869140625\n",
      "============\n",
      "[Validation set] Average loss: 711.3013916015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 250 Loss:165.6731414794922\n",
      "============\n",
      "[Validation set] Average loss: 705.2159423828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 251 Loss:165.3206787109375\n",
      "============\n",
      "[Validation set] Average loss: 711.6212158203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 252 Loss:165.3656463623047\n",
      "============\n",
      "[Validation set] Average loss: 705.6783447265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 253 Loss:165.013671875\n",
      "============\n",
      "[Validation set] Average loss: 711.9332275390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 254 Loss:165.06167602539062\n",
      "============\n",
      "[Validation set] Average loss: 706.13671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 255 Loss:164.7098846435547\n",
      "============\n",
      "[Validation set] Average loss: 712.2363891601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 256 Loss:164.7607421875\n",
      "============\n",
      "[Validation set] Average loss: 706.5907592773438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 257 Loss:164.4089813232422\n",
      "============\n",
      "[Validation set] Average loss: 712.5291748046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 258 Loss:164.46253967285156\n",
      "============\n",
      "[Validation set] Average loss: 707.0387573242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 259 Loss:164.11056518554688\n",
      "============\n",
      "[Validation set] Average loss: 712.8099365234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 260 Loss:164.16664123535156\n",
      "============\n",
      "[Validation set] Average loss: 707.4805297851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 261 Loss:163.81439208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "[Validation set] Average loss: 713.0779418945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 262 Loss:163.87281799316406\n",
      "============\n",
      "[Validation set] Average loss: 707.9144287109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 263 Loss:163.52015686035156\n",
      "============\n",
      "[Validation set] Average loss: 713.3314819335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 264 Loss:163.5808868408203\n",
      "============\n",
      "[Validation set] Average loss: 708.339599609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 265 Loss:163.2277374267578\n",
      "============\n",
      "[Validation set] Average loss: 713.569091796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 266 Loss:163.2905731201172\n",
      "============\n",
      "[Validation set] Average loss: 708.755126953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 267 Loss:162.93695068359375\n",
      "============\n",
      "[Validation set] Average loss: 713.7899169921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 268 Loss:163.00189208984375\n",
      "============\n",
      "[Validation set] Average loss: 709.1596069335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 269 Loss:162.64779663085938\n",
      "============\n",
      "[Validation set] Average loss: 713.992919921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 270 Loss:162.71463012695312\n",
      "============\n",
      "[Validation set] Average loss: 709.5524291992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 271 Loss:162.36009216308594\n",
      "============\n",
      "[Validation set] Average loss: 714.177001953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 272 Loss:162.42860412597656\n",
      "============\n",
      "[Validation set] Average loss: 709.9325561523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 273 Loss:162.0735626220703\n",
      "============\n",
      "[Validation set] Average loss: 714.3414306640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 274 Loss:162.1436767578125\n",
      "============\n",
      "[Validation set] Average loss: 710.299560546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 275 Loss:161.78811645507812\n",
      "============\n",
      "[Validation set] Average loss: 714.4864501953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 276 Loss:161.85935974121094\n",
      "============\n",
      "[Validation set] Average loss: 710.653076171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 277 Loss:161.50315856933594\n",
      "============\n",
      "[Validation set] Average loss: 714.6119995117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 278 Loss:161.57521057128906\n",
      "============\n",
      "[Validation set] Average loss: 710.9932861328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 279 Loss:161.2181854248047\n",
      "============\n",
      "[Validation set] Average loss: 714.71923828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 280 Loss:161.29051208496094\n",
      "============\n",
      "[Validation set] Average loss: 711.320556640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 281 Loss:160.93228149414062\n",
      "============\n",
      "[Validation set] Average loss: 714.8088989257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 282 Loss:161.00416564941406\n",
      "============\n",
      "[Validation set] Average loss: 711.6362915039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 283 Loss:160.64437866210938\n",
      "============\n",
      "[Validation set] Average loss: 714.8827514648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 284 Loss:160.71493530273438\n",
      "============\n",
      "[Validation set] Average loss: 711.9415283203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 285 Loss:160.35304260253906\n",
      "============\n",
      "[Validation set] Average loss: 714.9432373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 286 Loss:160.4212646484375\n",
      "============\n",
      "[Validation set] Average loss: 712.23828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 287 Loss:160.0565185546875\n",
      "============\n",
      "[Validation set] Average loss: 714.99267578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 288 Loss:160.1211700439453\n",
      "============\n",
      "[Validation set] Average loss: 712.5289916992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 289 Loss:159.75291442871094\n",
      "============\n",
      "[Validation set] Average loss: 715.0343627929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 290 Loss:159.8128204345703\n",
      "============\n",
      "[Validation set] Average loss: 712.81640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 291 Loss:159.44032287597656\n",
      "============\n",
      "[Validation set] Average loss: 715.0711059570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 292 Loss:159.49398803710938\n",
      "============\n",
      "[Validation set] Average loss: 713.103271484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 293 Loss:159.1165313720703\n",
      "============\n",
      "[Validation set] Average loss: 715.10595703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 294 Loss:159.16275024414062\n",
      "============\n",
      "[Validation set] Average loss: 713.3921508789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 295 Loss:158.7796173095703\n",
      "============\n",
      "[Validation set] Average loss: 715.1420288085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 296 Loss:158.81700134277344\n",
      "============\n",
      "[Validation set] Average loss: 713.6864624023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 297 Loss:158.4278564453125\n",
      "============\n",
      "[Validation set] Average loss: 715.182373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 298 Loss:158.45538330078125\n",
      "============\n",
      "[Validation set] Average loss: 713.9883422851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 299 Loss:158.0597686767578\n",
      "============\n",
      "[Validation set] Average loss: 715.2293090820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 300 Loss:158.07667541503906\n",
      "============\n",
      "[Validation set] Average loss: 714.3001708984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 301 Loss:157.6748504638672\n",
      "============\n",
      "[Validation set] Average loss: 715.28515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 302 Loss:157.6808319091797\n",
      "============\n",
      "[Validation set] Average loss: 714.6241455078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 303 Loss:157.2730255126953\n",
      "============\n",
      "[Validation set] Average loss: 715.351806640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 304 Loss:157.2678680419922\n",
      "============\n",
      "[Validation set] Average loss: 714.9615478515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 305 Loss:156.85499572753906\n",
      "============\n",
      "[Validation set] Average loss: 715.4307250976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 306 Loss:156.83901977539062\n",
      "============\n",
      "[Validation set] Average loss: 715.3134765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 307 Loss:156.42202758789062\n",
      "============\n",
      "[Validation set] Average loss: 715.523193359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 308 Loss:156.3959197998047\n",
      "============\n",
      "[Validation set] Average loss: 715.680908203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 309 Loss:155.9762725830078\n",
      "============\n",
      "[Validation set] Average loss: 715.6297607421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 310 Loss:155.94082641601562\n",
      "============\n",
      "[Validation set] Average loss: 716.064208984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 311 Loss:155.52001953125\n",
      "============\n",
      "[Validation set] Average loss: 715.7515869140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 312 Loss:155.4766387939453\n",
      "============\n",
      "[Validation set] Average loss: 716.4631958007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 313 Loss:155.0562286376953\n",
      "============\n",
      "[Validation set] Average loss: 715.8885498046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 314 Loss:155.00604248046875\n",
      "============\n",
      "[Validation set] Average loss: 716.877685546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 315 Loss:154.5874481201172\n",
      "============\n",
      "[Validation set] Average loss: 716.040283203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 316 Loss:154.5318603515625\n",
      "============\n",
      "[Validation set] Average loss: 717.3074951171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 317 Loss:154.11668395996094\n",
      "============\n",
      "[Validation set] Average loss: 716.2070922851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 318 Loss:154.05691528320312\n",
      "============\n",
      "[Validation set] Average loss: 717.7515258789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 319 Loss:153.64634704589844\n",
      "============\n",
      "[Validation set] Average loss: 716.387939453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 320 Loss:153.58352661132812\n",
      "============\n",
      "[Validation set] Average loss: 718.2088623046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 321 Loss:153.17872619628906\n",
      "============\n",
      "[Validation set] Average loss: 716.5820922851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 322 Loss:153.11386108398438\n",
      "============\n",
      "[Validation set] Average loss: 718.678466796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 323 Loss:152.7156982421875\n",
      "============\n",
      "[Validation set] Average loss: 716.788330078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 324 Loss:152.64962768554688\n",
      "============\n",
      "[Validation set] Average loss: 719.1593627929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 325 Loss:152.25869750976562\n",
      "============\n",
      "[Validation set] Average loss: 717.00537109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 326 Loss:152.1920623779297\n",
      "============\n",
      "[Validation set] Average loss: 719.6500244140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 327 Loss:151.8087615966797\n",
      "============\n",
      "[Validation set] Average loss: 717.2320556640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 328 Loss:151.74200439453125\n",
      "============\n",
      "[Validation set] Average loss: 720.1492919921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 329 Loss:151.36656188964844\n",
      "============\n",
      "[Validation set] Average loss: 717.4666137695312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 330 Loss:151.29989624023438\n",
      "============\n",
      "[Validation set] Average loss: 720.6559448242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 331 Loss:150.93246459960938\n",
      "============\n",
      "[Validation set] Average loss: 717.7075805664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 332 Loss:150.86593627929688\n",
      "============\n",
      "[Validation set] Average loss: 721.16845703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 333 Loss:150.5064239501953\n",
      "============\n",
      "[Validation set] Average loss: 717.9535522460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 334 Loss:150.44000244140625\n",
      "============\n",
      "[Validation set] Average loss: 721.6858520507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 335 Loss:150.08811950683594\n",
      "============\n",
      "[Validation set] Average loss: 718.202880859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 336 Loss:150.0217742919922\n",
      "============\n",
      "[Validation set] Average loss: 722.2069702148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 337 Loss:149.6773223876953\n",
      "============\n",
      "[Validation set] Average loss: 718.4539794921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 338 Loss:149.61073303222656\n",
      "============\n",
      "[Validation set] Average loss: 722.730712890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 339 Loss:149.27345275878906\n",
      "============\n",
      "[Validation set] Average loss: 718.705810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 340 Loss:149.2062225341797\n",
      "============\n",
      "[Validation set] Average loss: 723.2557373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 341 Loss:148.8756103515625\n",
      "============\n",
      "[Validation set] Average loss: 718.9571533203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 342 Loss:148.8074188232422\n",
      "============\n",
      "[Validation set] Average loss: 723.7816162109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 343 Loss:148.48318481445312\n",
      "============\n",
      "[Validation set] Average loss: 719.20654296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 344 Loss:148.41372680664062\n",
      "============\n",
      "[Validation set] Average loss: 724.3072509765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 345 Loss:148.09559631347656\n",
      "============\n",
      "[Validation set] Average loss: 719.4532470703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 346 Loss:148.0243377685547\n",
      "============\n",
      "[Validation set] Average loss: 724.83203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 347 Loss:147.71177673339844\n",
      "============\n",
      "[Validation set] Average loss: 719.6967163085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 348 Loss:147.63839721679688\n",
      "============\n",
      "[Validation set] Average loss: 725.35546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 349 Loss:147.3312225341797\n",
      "============\n",
      "[Validation set] Average loss: 719.9359130859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 350 Loss:147.2551727294922\n",
      "============\n",
      "[Validation set] Average loss: 725.8771362304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 351 Loss:146.95294189453125\n",
      "============\n",
      "[Validation set] Average loss: 720.1710205078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 352 Loss:146.87393188476562\n",
      "============\n",
      "[Validation set] Average loss: 726.3967895507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 353 Loss:146.5763397216797\n",
      "============\n",
      "[Validation set] Average loss: 720.4016723632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 354 Loss:146.4938201904297\n",
      "============\n",
      "[Validation set] Average loss: 726.9144897460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 355 Loss:146.20054626464844\n",
      "============\n",
      "[Validation set] Average loss: 720.6277465820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 356 Loss:146.1141357421875\n",
      "============\n",
      "[Validation set] Average loss: 727.4301147460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 357 Loss:145.8249053955078\n",
      "============\n",
      "[Validation set] Average loss: 720.8501586914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 358 Loss:145.7341766357422\n",
      "============\n",
      "[Validation set] Average loss: 727.9442749023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 359 Loss:145.4486083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "[Validation set] Average loss: 721.0690307617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 360 Loss:145.35305786132812\n",
      "============\n",
      "[Validation set] Average loss: 728.456787109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 361 Loss:145.07090759277344\n",
      "============\n",
      "[Validation set] Average loss: 721.2850341796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 362 Loss:144.97015380859375\n",
      "============\n",
      "[Validation set] Average loss: 728.9684448242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 363 Loss:144.6911163330078\n",
      "============\n",
      "[Validation set] Average loss: 721.4993286132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 364 Loss:144.58465576171875\n",
      "============\n",
      "[Validation set] Average loss: 729.47998046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 365 Loss:144.3084259033203\n",
      "============\n",
      "[Validation set] Average loss: 721.7128295898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 366 Loss:144.19607543945312\n",
      "============\n",
      "[Validation set] Average loss: 729.9920043945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 367 Loss:143.92227172851562\n",
      "============\n",
      "[Validation set] Average loss: 721.926513671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 368 Loss:143.8035888671875\n",
      "============\n",
      "[Validation set] Average loss: 730.5048217773438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 369 Loss:143.5321502685547\n",
      "============\n",
      "[Validation set] Average loss: 722.1415405273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 370 Loss:143.4067840576172\n",
      "============\n",
      "[Validation set] Average loss: 731.0197143554688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 371 Loss:143.13754272460938\n",
      "============\n",
      "[Validation set] Average loss: 722.3592529296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 372 Loss:143.0054168701172\n",
      "============\n",
      "[Validation set] Average loss: 731.537353515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 373 Loss:142.73806762695312\n",
      "============\n",
      "[Validation set] Average loss: 722.580810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 374 Loss:142.59909057617188\n",
      "============\n",
      "[Validation set] Average loss: 732.0586547851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 375 Loss:142.33358764648438\n",
      "============\n",
      "[Validation set] Average loss: 722.807373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 376 Loss:142.1876220703125\n",
      "============\n",
      "[Validation set] Average loss: 732.5841064453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 377 Loss:141.9240264892578\n",
      "============\n",
      "[Validation set] Average loss: 723.0399169921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 378 Loss:141.77117919921875\n",
      "============\n",
      "[Validation set] Average loss: 733.1148071289062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 379 Loss:141.5095672607422\n",
      "============\n",
      "[Validation set] Average loss: 723.2797241210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 380 Loss:141.34999084472656\n",
      "============\n",
      "[Validation set] Average loss: 733.651611328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 381 Loss:141.09043884277344\n",
      "============\n",
      "[Validation set] Average loss: 723.52783203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 382 Loss:140.9243927001953\n",
      "============\n",
      "[Validation set] Average loss: 734.1952514648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 383 Loss:140.6671905517578\n",
      "============\n",
      "[Validation set] Average loss: 723.7850341796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 384 Loss:140.49497985839844\n",
      "============\n",
      "[Validation set] Average loss: 734.7464599609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 385 Loss:140.2403564453125\n",
      "============\n",
      "[Validation set] Average loss: 724.0519409179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 386 Loss:140.0623779296875\n",
      "============\n",
      "[Validation set] Average loss: 735.3058471679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 387 Loss:139.81068420410156\n",
      "============\n",
      "[Validation set] Average loss: 724.3297119140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 388 Loss:139.62734985351562\n",
      "============\n",
      "[Validation set] Average loss: 735.8740844726562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 389 Loss:139.37892150878906\n",
      "============\n",
      "[Validation set] Average loss: 724.6185913085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 390 Loss:139.1905975341797\n",
      "============\n",
      "[Validation set] Average loss: 736.45166015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 391 Loss:138.94581604003906\n",
      "============\n",
      "[Validation set] Average loss: 724.91943359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 392 Loss:138.75306701660156\n",
      "============\n",
      "[Validation set] Average loss: 737.0392456054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 393 Loss:138.51231384277344\n",
      "============\n",
      "[Validation set] Average loss: 725.2324829101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 394 Loss:138.31556701660156\n",
      "============\n",
      "[Validation set] Average loss: 737.63720703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 395 Loss:138.07916259765625\n",
      "============\n",
      "[Validation set] Average loss: 725.5575561523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 396 Loss:137.87889099121094\n",
      "============\n",
      "[Validation set] Average loss: 738.2456665039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 397 Loss:137.64712524414062\n",
      "============\n",
      "[Validation set] Average loss: 725.8950805664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 398 Loss:137.44371032714844\n",
      "============\n",
      "[Validation set] Average loss: 738.865234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 399 Loss:137.21685791015625\n",
      "============\n",
      "[Validation set] Average loss: 726.2451782226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 400 Loss:137.01065063476562\n",
      "============\n",
      "[Validation set] Average loss: 739.4957275390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 401 Loss:136.78892517089844\n",
      "============\n",
      "[Validation set] Average loss: 726.6077270507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 402 Loss:136.58030700683594\n",
      "============\n",
      "[Validation set] Average loss: 740.1373291015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 403 Loss:136.36395263671875\n",
      "============\n",
      "[Validation set] Average loss: 726.9824829101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 404 Loss:136.1531982421875\n",
      "============\n",
      "[Validation set] Average loss: 740.7899780273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 405 Loss:135.94236755371094\n",
      "============\n",
      "[Validation set] Average loss: 727.3689575195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 406 Loss:135.7296600341797\n",
      "============\n",
      "[Validation set] Average loss: 741.4533081054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 407 Loss:135.5244598388672\n",
      "============\n",
      "[Validation set] Average loss: 727.767333984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 408 Loss:135.3100128173828\n",
      "============\n",
      "[Validation set] Average loss: 742.1271362304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 409 Loss:135.11044311523438\n",
      "============\n",
      "[Validation set] Average loss: 728.176513671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 410 Loss:134.8943328857422\n",
      "============\n",
      "[Validation set] Average loss: 742.8112182617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 411 Loss:134.70042419433594\n",
      "============\n",
      "[Validation set] Average loss: 728.5966796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 412 Loss:134.48272705078125\n",
      "============\n",
      "[Validation set] Average loss: 743.5053100585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 413 Loss:134.29443359375\n",
      "============\n",
      "[Validation set] Average loss: 729.0267944335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 414 Loss:134.07518005371094\n",
      "============\n",
      "[Validation set] Average loss: 744.2086181640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 415 Loss:133.8922882080078\n",
      "============\n",
      "[Validation set] Average loss: 729.4664306640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 416 Loss:133.67147827148438\n",
      "============\n",
      "[Validation set] Average loss: 744.9209594726562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 417 Loss:133.4940185546875\n",
      "============\n",
      "[Validation set] Average loss: 729.9151611328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 418 Loss:133.2715301513672\n",
      "============\n",
      "[Validation set] Average loss: 745.6416625976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 419 Loss:133.0992889404297\n",
      "============\n",
      "[Validation set] Average loss: 730.3724365234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 420 Loss:132.87501525878906\n",
      "============\n",
      "[Validation set] Average loss: 746.3699340820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 421 Loss:132.70773315429688\n",
      "============\n",
      "[Validation set] Average loss: 730.8375244140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 422 Loss:132.48165893554688\n",
      "============\n",
      "[Validation set] Average loss: 747.10546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 423 Loss:132.31918334960938\n",
      "============\n",
      "[Validation set] Average loss: 731.31005859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 424 Loss:132.09115600585938\n",
      "============\n",
      "[Validation set] Average loss: 747.8477172851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 425 Loss:131.9333038330078\n",
      "============\n",
      "[Validation set] Average loss: 731.7894897460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 426 Loss:131.70315551757812\n",
      "============\n",
      "[Validation set] Average loss: 748.5960693359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 427 Loss:131.5496826171875\n",
      "============\n",
      "[Validation set] Average loss: 732.2754516601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 428 Loss:131.31727600097656\n",
      "============\n",
      "[Validation set] Average loss: 749.3499145507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 429 Loss:131.16802978515625\n",
      "============\n",
      "[Validation set] Average loss: 732.76708984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 430 Loss:130.93321228027344\n",
      "============\n",
      "[Validation set] Average loss: 750.1090698242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 431 Loss:130.7879638671875\n",
      "============\n",
      "[Validation set] Average loss: 733.2645263671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 432 Loss:130.55059814453125\n",
      "============\n",
      "[Validation set] Average loss: 750.8727416992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 433 Loss:130.4091796875\n",
      "============\n",
      "[Validation set] Average loss: 733.7667846679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 434 Loss:130.16928100585938\n",
      "============\n",
      "[Validation set] Average loss: 751.6405639648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 435 Loss:130.03155517578125\n",
      "============\n",
      "[Validation set] Average loss: 734.2739868164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 436 Loss:129.78887939453125\n",
      "============\n",
      "[Validation set] Average loss: 752.4124145507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 437 Loss:129.65464782714844\n",
      "============\n",
      "[Validation set] Average loss: 734.7854614257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 438 Loss:129.40927124023438\n",
      "============\n",
      "[Validation set] Average loss: 753.18798828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 439 Loss:129.27850341796875\n",
      "============\n",
      "[Validation set] Average loss: 735.30126953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 440 Loss:129.0303192138672\n",
      "============\n",
      "[Validation set] Average loss: 753.9666137695312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 441 Loss:128.90286254882812\n",
      "============\n",
      "[Validation set] Average loss: 735.8209838867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 442 Loss:128.65185546875\n",
      "============\n",
      "[Validation set] Average loss: 754.74853515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 443 Loss:128.52772521972656\n",
      "============\n",
      "[Validation set] Average loss: 736.3443603515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 444 Loss:128.2738800048828\n",
      "============\n",
      "[Validation set] Average loss: 755.5330810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 445 Loss:128.1530303955078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "[Validation set] Average loss: 736.8712768554688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 446 Loss:127.8963394165039\n",
      "============\n",
      "[Validation set] Average loss: 756.3206176757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 447 Loss:127.7787857055664\n",
      "============\n",
      "[Validation set] Average loss: 737.4012451171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 448 Loss:127.51939392089844\n",
      "============\n",
      "[Validation set] Average loss: 757.1106567382812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 449 Loss:127.40507507324219\n",
      "============\n",
      "[Validation set] Average loss: 737.9345092773438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 450 Loss:127.14295196533203\n",
      "============\n",
      "[Validation set] Average loss: 757.9031982421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 451 Loss:127.0319595336914\n",
      "============\n",
      "[Validation set] Average loss: 738.470703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 452 Loss:126.76721954345703\n",
      "============\n",
      "[Validation set] Average loss: 758.6983642578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 453 Loss:126.65953063964844\n",
      "============\n",
      "[Validation set] Average loss: 739.0094604492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 454 Loss:126.39234924316406\n",
      "============\n",
      "[Validation set] Average loss: 759.4956665039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 455 Loss:126.28810119628906\n",
      "============\n",
      "[Validation set] Average loss: 739.5506591796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 456 Loss:126.0184555053711\n",
      "============\n",
      "[Validation set] Average loss: 760.295654296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 457 Loss:125.91764068603516\n",
      "============\n",
      "[Validation set] Average loss: 740.0944213867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 458 Loss:125.64566040039062\n",
      "============\n",
      "[Validation set] Average loss: 761.0977172851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 459 Loss:125.54840850830078\n",
      "============\n",
      "[Validation set] Average loss: 740.64013671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 460 Loss:125.27421569824219\n",
      "============\n",
      "[Validation set] Average loss: 761.9020385742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 461 Loss:125.18055725097656\n",
      "============\n",
      "[Validation set] Average loss: 741.1878662109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 462 Loss:124.90416717529297\n",
      "============\n",
      "[Validation set] Average loss: 762.70849609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 463 Loss:124.81419372558594\n",
      "============\n",
      "[Validation set] Average loss: 741.7372436523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 464 Loss:124.5357437133789\n",
      "============\n",
      "[Validation set] Average loss: 763.5170288085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 465 Loss:124.44951629638672\n",
      "============\n",
      "[Validation set] Average loss: 742.2882080078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 466 Loss:124.16913604736328\n",
      "============\n",
      "[Validation set] Average loss: 764.3276977539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 467 Loss:124.086669921875\n",
      "============\n",
      "[Validation set] Average loss: 742.8404541015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 468 Loss:123.80435943603516\n",
      "============\n",
      "[Validation set] Average loss: 765.1401977539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 469 Loss:123.72573852539062\n",
      "============\n",
      "[Validation set] Average loss: 743.3936157226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 470 Loss:123.44158172607422\n",
      "============\n",
      "[Validation set] Average loss: 765.9547729492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 471 Loss:123.36681365966797\n",
      "============\n",
      "[Validation set] Average loss: 743.9475708007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 472 Loss:123.08085632324219\n",
      "============\n",
      "[Validation set] Average loss: 766.7708740234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 473 Loss:123.0099868774414\n",
      "============\n",
      "[Validation set] Average loss: 744.5023193359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 474 Loss:122.72225952148438\n",
      "============\n",
      "[Validation set] Average loss: 767.5888671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 475 Loss:122.65535736083984\n",
      "============\n",
      "[Validation set] Average loss: 745.057373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 476 Loss:122.36588287353516\n",
      "============\n",
      "[Validation set] Average loss: 768.4085083007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 477 Loss:122.30290985107422\n",
      "============\n",
      "[Validation set] Average loss: 745.6127319335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 478 Loss:122.01170349121094\n",
      "============\n",
      "[Validation set] Average loss: 769.2293701171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 479 Loss:121.95262145996094\n",
      "============\n",
      "[Validation set] Average loss: 746.1683959960938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 480 Loss:121.65965270996094\n",
      "============\n",
      "[Validation set] Average loss: 770.0518188476562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 481 Loss:121.60448455810547\n",
      "============\n",
      "[Validation set] Average loss: 746.7239990234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 482 Loss:121.30976867675781\n",
      "============\n",
      "[Validation set] Average loss: 770.8755493164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 483 Loss:121.25843048095703\n",
      "============\n",
      "[Validation set] Average loss: 747.2794799804688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 484 Loss:120.96186065673828\n",
      "============\n",
      "[Validation set] Average loss: 771.7005615234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 485 Loss:120.91436004638672\n",
      "============\n",
      "[Validation set] Average loss: 747.8348999023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 486 Loss:120.61590576171875\n",
      "============\n",
      "[Validation set] Average loss: 772.5267944335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 487 Loss:120.57213592529297\n",
      "============\n",
      "[Validation set] Average loss: 748.3904418945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 488 Loss:120.27175903320312\n",
      "============\n",
      "[Validation set] Average loss: 773.3541870117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 489 Loss:120.23160552978516\n",
      "============\n",
      "[Validation set] Average loss: 748.946044921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 490 Loss:119.92920684814453\n",
      "============\n",
      "[Validation set] Average loss: 774.1829223632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 491 Loss:119.89258575439453\n",
      "============\n",
      "[Validation set] Average loss: 749.5017700195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 492 Loss:119.58811950683594\n",
      "============\n",
      "[Validation set] Average loss: 775.0125732421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 493 Loss:119.55487060546875\n",
      "============\n",
      "[Validation set] Average loss: 750.0581665039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 494 Loss:119.24807739257812\n",
      "============\n",
      "[Validation set] Average loss: 775.8434448242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 495 Loss:119.21810913085938\n",
      "============\n",
      "[Validation set] Average loss: 750.614990234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 496 Loss:118.90902709960938\n",
      "============\n",
      "[Validation set] Average loss: 776.6753540039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 497 Loss:118.88217163085938\n",
      "============\n",
      "[Validation set] Average loss: 751.1727905273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 498 Loss:118.57069396972656\n",
      "============\n",
      "[Validation set] Average loss: 777.5086059570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 499 Loss:118.54681396484375\n",
      "============\n",
      "[Validation set] Average loss: 751.731689453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 500 Loss:118.23283386230469\n",
      "============\n",
      "[Validation set] Average loss: 778.3431396484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 501 Loss:118.21174621582031\n",
      "============\n",
      "[Validation set] Average loss: 752.2921752929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 502 Loss:117.89518737792969\n",
      "============\n",
      "[Validation set] Average loss: 779.1788330078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 503 Loss:117.87677001953125\n",
      "============\n",
      "[Validation set] Average loss: 752.8545532226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 504 Loss:117.5576171875\n",
      "============\n",
      "[Validation set] Average loss: 780.015869140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 505 Loss:117.54173278808594\n",
      "============\n",
      "[Validation set] Average loss: 753.4187622070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 506 Loss:117.2199478149414\n",
      "============\n",
      "[Validation set] Average loss: 780.854248046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 507 Loss:117.20650482177734\n",
      "============\n",
      "[Validation set] Average loss: 753.9854736328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 508 Loss:116.88212585449219\n",
      "============\n",
      "[Validation set] Average loss: 781.694580078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 509 Loss:116.87103271484375\n",
      "============\n",
      "[Validation set] Average loss: 754.5546264648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 510 Loss:116.5440902709961\n",
      "============\n",
      "[Validation set] Average loss: 782.53662109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 511 Loss:116.53530883789062\n",
      "============\n",
      "[Validation set] Average loss: 755.1264038085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 512 Loss:116.20588684082031\n",
      "============\n",
      "[Validation set] Average loss: 783.3801879882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 513 Loss:116.19933319091797\n",
      "============\n",
      "[Validation set] Average loss: 755.701171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 514 Loss:115.8675308227539\n",
      "============\n",
      "[Validation set] Average loss: 784.2258911132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 515 Loss:115.86331939697266\n",
      "============\n",
      "[Validation set] Average loss: 756.27880859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 516 Loss:115.52925109863281\n",
      "============\n",
      "[Validation set] Average loss: 785.0735473632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 517 Loss:115.52726745605469\n",
      "============\n",
      "[Validation set] Average loss: 756.859619140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 518 Loss:115.19108581542969\n",
      "============\n",
      "[Validation set] Average loss: 785.9237670898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 519 Loss:115.19149017333984\n",
      "============\n",
      "[Validation set] Average loss: 757.443115234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 520 Loss:114.85343933105469\n",
      "============\n",
      "[Validation set] Average loss: 786.7763671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 521 Loss:114.85625457763672\n",
      "============\n",
      "[Validation set] Average loss: 758.0297241210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 522 Loss:114.51636505126953\n",
      "============\n",
      "[Validation set] Average loss: 787.631591796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 523 Loss:114.52180480957031\n",
      "============\n",
      "[Validation set] Average loss: 758.6192016601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 524 Loss:114.1803207397461\n",
      "============\n",
      "[Validation set] Average loss: 788.48974609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 525 Loss:114.18836975097656\n",
      "============\n",
      "[Validation set] Average loss: 759.2110595703125, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 526 Loss:113.84542846679688\n",
      "============\n",
      "[Validation set] Average loss: 789.3504028320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 527 Loss:113.85623168945312\n",
      "============\n",
      "[Validation set] Average loss: 759.8060913085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 528 Loss:113.51197814941406\n",
      "============\n",
      "[Validation set] Average loss: 790.21435546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 529 Loss:113.5256118774414\n",
      "============\n",
      "[Validation set] Average loss: 760.4033203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 530 Loss:113.18019104003906\n",
      "============\n",
      "[Validation set] Average loss: 791.0814208984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 531 Loss:113.19685363769531\n",
      "============\n",
      "[Validation set] Average loss: 761.0030517578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 532 Loss:112.85031127929688\n",
      "============\n",
      "[Validation set] Average loss: 791.9515380859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 533 Loss:112.87001037597656\n",
      "============\n",
      "[Validation set] Average loss: 761.6047973632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 534 Loss:112.52254486083984\n",
      "============\n",
      "[Validation set] Average loss: 792.824951171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 535 Loss:112.5453109741211\n",
      "============\n",
      "[Validation set] Average loss: 762.208740234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 536 Loss:112.19683837890625\n",
      "============\n",
      "[Validation set] Average loss: 793.7015380859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 537 Loss:112.22270202636719\n",
      "============\n",
      "[Validation set] Average loss: 762.814697265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 538 Loss:111.87335968017578\n",
      "============\n",
      "[Validation set] Average loss: 794.5813598632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 539 Loss:111.90242004394531\n",
      "============\n",
      "[Validation set] Average loss: 763.4227294921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 540 Loss:111.55215454101562\n",
      "============\n",
      "[Validation set] Average loss: 795.4644775390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 541 Loss:111.58441162109375\n",
      "============\n",
      "[Validation set] Average loss: 764.0326538085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 542 Loss:111.23318481445312\n",
      "============\n",
      "[Validation set] Average loss: 796.350830078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 543 Loss:111.26856231689453\n",
      "============\n",
      "[Validation set] Average loss: 764.6444702148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 544 Loss:110.91632843017578\n",
      "============\n",
      "[Validation set] Average loss: 797.2402954101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 545 Loss:110.95478820800781\n",
      "============\n",
      "[Validation set] Average loss: 765.25830078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 546 Loss:110.6015396118164\n",
      "============\n",
      "[Validation set] Average loss: 798.1329956054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 547 Loss:110.64295959472656\n",
      "============\n",
      "[Validation set] Average loss: 765.874755859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 548 Loss:110.28852081298828\n",
      "============\n",
      "[Validation set] Average loss: 799.0289306640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 549 Loss:110.33293914794922\n",
      "============\n",
      "[Validation set] Average loss: 766.4931030273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 550 Loss:109.97725677490234\n",
      "============\n",
      "[Validation set] Average loss: 799.927978515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 551 Loss:110.02442169189453\n",
      "============\n",
      "[Validation set] Average loss: 767.1141357421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 552 Loss:109.66738891601562\n",
      "============\n",
      "[Validation set] Average loss: 800.829833984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 553 Loss:109.71730041503906\n",
      "============\n",
      "[Validation set] Average loss: 767.7378540039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 554 Loss:109.35882568359375\n",
      "============\n",
      "[Validation set] Average loss: 801.7351684570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 555 Loss:109.41132354736328\n",
      "============\n",
      "[Validation set] Average loss: 768.3646240234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 556 Loss:109.05134582519531\n",
      "============\n",
      "[Validation set] Average loss: 802.6434326171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 557 Loss:109.10637664794922\n",
      "============\n",
      "[Validation set] Average loss: 768.9945068359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 558 Loss:108.74483489990234\n",
      "============\n",
      "[Validation set] Average loss: 803.5549926757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 559 Loss:108.8022689819336\n",
      "============\n",
      "[Validation set] Average loss: 769.6277465820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 560 Loss:108.43905639648438\n",
      "============\n",
      "[Validation set] Average loss: 804.4696655273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 561 Loss:108.4988021850586\n",
      "============\n",
      "[Validation set] Average loss: 770.2647705078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 562 Loss:108.13396453857422\n",
      "============\n",
      "[Validation set] Average loss: 805.3875732421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 563 Loss:108.19593811035156\n",
      "============\n",
      "[Validation set] Average loss: 770.9053344726562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 564 Loss:107.82942962646484\n",
      "============\n",
      "[Validation set] Average loss: 806.3087158203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 565 Loss:107.8936538696289\n",
      "============\n",
      "[Validation set] Average loss: 771.5498657226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 566 Loss:107.52548217773438\n",
      "============\n",
      "[Validation set] Average loss: 807.2335205078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 567 Loss:107.5919418334961\n",
      "============\n",
      "[Validation set] Average loss: 772.1984252929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 568 Loss:107.22222137451172\n",
      "============\n",
      "[Validation set] Average loss: 808.16162109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 569 Loss:107.29080963134766\n",
      "============\n",
      "[Validation set] Average loss: 772.8510131835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 570 Loss:106.9195327758789\n",
      "============\n",
      "[Validation set] Average loss: 809.0933837890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 571 Loss:106.99041748046875\n",
      "============\n",
      "[Validation set] Average loss: 773.50732421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 572 Loss:106.6176986694336\n",
      "============\n",
      "[Validation set] Average loss: 810.0286254882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 573 Loss:106.69095611572266\n",
      "============\n",
      "[Validation set] Average loss: 774.1674194335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 574 Loss:106.31688690185547\n",
      "============\n",
      "[Validation set] Average loss: 810.9677124023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 575 Loss:106.39253997802734\n",
      "============\n",
      "[Validation set] Average loss: 774.8313598632812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 576 Loss:106.01718139648438\n",
      "============\n",
      "[Validation set] Average loss: 811.9105224609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 577 Loss:106.09539794921875\n",
      "============\n",
      "[Validation set] Average loss: 775.498779296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 578 Loss:105.71892547607422\n",
      "============\n",
      "[Validation set] Average loss: 812.8573608398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 579 Loss:105.79979705810547\n",
      "============\n",
      "[Validation set] Average loss: 776.1692504882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 580 Loss:105.42227172851562\n",
      "============\n",
      "[Validation set] Average loss: 813.8077392578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 581 Loss:105.5060043334961\n",
      "============\n",
      "[Validation set] Average loss: 776.842529296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 582 Loss:105.12749481201172\n",
      "============\n",
      "[Validation set] Average loss: 814.7618408203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 583 Loss:105.2142105102539\n",
      "============\n",
      "[Validation set] Average loss: 777.5182495117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 584 Loss:104.83477783203125\n",
      "============\n",
      "[Validation set] Average loss: 815.7194213867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 585 Loss:104.9246597290039\n",
      "============\n",
      "[Validation set] Average loss: 778.1961059570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 586 Loss:104.54434967041016\n",
      "============\n",
      "[Validation set] Average loss: 816.6804809570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 587 Loss:104.63750457763672\n",
      "============\n",
      "[Validation set] Average loss: 778.8755493164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 588 Loss:104.25633239746094\n",
      "============\n",
      "[Validation set] Average loss: 817.6444702148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 589 Loss:104.3529281616211\n",
      "============\n",
      "[Validation set] Average loss: 779.556396484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 590 Loss:103.97076416015625\n",
      "============\n",
      "[Validation set] Average loss: 818.6114501953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 591 Loss:104.0708999633789\n",
      "============\n",
      "[Validation set] Average loss: 780.2380981445312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 592 Loss:103.68773651123047\n",
      "============\n",
      "[Validation set] Average loss: 819.5804443359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 593 Loss:103.79147338867188\n",
      "============\n",
      "[Validation set] Average loss: 780.920166015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 594 Loss:103.40719604492188\n",
      "============\n",
      "[Validation set] Average loss: 820.5513916015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 595 Loss:103.51467895507812\n",
      "============\n",
      "[Validation set] Average loss: 781.6024169921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 596 Loss:103.12909698486328\n",
      "============\n",
      "[Validation set] Average loss: 821.5237426757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 597 Loss:103.24028015136719\n",
      "============\n",
      "[Validation set] Average loss: 782.2841796875, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 598 Loss:102.853271484375\n",
      "============\n",
      "[Validation set] Average loss: 822.4967041015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 599 Loss:102.96821594238281\n",
      "============\n",
      "[Validation set] Average loss: 782.96533203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 600 Loss:102.57947540283203\n",
      "============\n",
      "[Validation set] Average loss: 823.4697265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 601 Loss:102.69812774658203\n",
      "============\n",
      "[Validation set] Average loss: 783.6458129882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 602 Loss:102.30741882324219\n",
      "============\n",
      "[Validation set] Average loss: 824.4421997070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 603 Loss:102.42969512939453\n",
      "============\n",
      "[Validation set] Average loss: 784.3253784179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 604 Loss:102.03669738769531\n",
      "============\n",
      "[Validation set] Average loss: 825.413330078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 605 Loss:102.16252899169922\n",
      "============\n",
      "[Validation set] Average loss: 785.0035400390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 606 Loss:101.76689147949219\n",
      "============\n",
      "[Validation set] Average loss: 826.3822631835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 607 Loss:101.89611053466797\n",
      "============\n",
      "[Validation set] Average loss: 785.6807250976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 608 Loss:101.4975357055664\n",
      "============\n",
      "[Validation set] Average loss: 827.3482666015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 609 Loss:101.62995910644531\n",
      "============\n",
      "[Validation set] Average loss: 786.3566284179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 610 Loss:101.22808074951172\n",
      "============\n",
      "[Validation set] Average loss: 828.3106079101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 611 Loss:101.36354064941406\n",
      "============\n",
      "[Validation set] Average loss: 787.031494140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 612 Loss:100.95802307128906\n",
      "============\n",
      "[Validation set] Average loss: 829.2687377929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 613 Loss:101.09634399414062\n",
      "============\n",
      "[Validation set] Average loss: 787.7052001953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 614 Loss:100.68692779541016\n",
      "============\n",
      "[Validation set] Average loss: 830.2217407226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 615 Loss:100.82785034179688\n",
      "============\n",
      "[Validation set] Average loss: 788.3779907226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 616 Loss:100.4141616821289\n",
      "============\n",
      "[Validation set] Average loss: 831.1691284179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 617 Loss:100.55747985839844\n",
      "============\n",
      "[Validation set] Average loss: 789.050048828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 618 Loss:100.13931274414062\n",
      "============\n",
      "[Validation set] Average loss: 832.1102905273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 619 Loss:100.28482818603516\n",
      "============\n",
      "[Validation set] Average loss: 789.7212524414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 620 Loss:99.86192321777344\n",
      "============\n",
      "[Validation set] Average loss: 833.0446166992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 621 Loss:100.00955200195312\n",
      "============\n",
      "[Validation set] Average loss: 790.3922119140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 622 Loss:99.58170318603516\n",
      "============\n",
      "[Validation set] Average loss: 833.9720458984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 623 Loss:99.73119354248047\n",
      "============\n",
      "[Validation set] Average loss: 791.06298828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 624 Loss:99.29832458496094\n",
      "============\n",
      "[Validation set] Average loss: 834.891845703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 625 Loss:99.44952392578125\n",
      "============\n",
      "[Validation set] Average loss: 791.7330932617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 626 Loss:99.0116195678711\n",
      "============\n",
      "[Validation set] Average loss: 835.8041381835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 627 Loss:99.16444396972656\n",
      "============\n",
      "[Validation set] Average loss: 792.4033203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 628 Loss:98.72140502929688\n",
      "============\n",
      "[Validation set] Average loss: 836.70849609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 629 Loss:98.87578582763672\n",
      "============\n",
      "[Validation set] Average loss: 793.07373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 630 Loss:98.42768096923828\n",
      "============\n",
      "[Validation set] Average loss: 837.6049194335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 631 Loss:98.58354949951172\n",
      "============\n",
      "[Validation set] Average loss: 793.7442016601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 632 Loss:98.13043212890625\n",
      "============\n",
      "[Validation set] Average loss: 838.4935302734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 633 Loss:98.28779602050781\n",
      "============\n",
      "[Validation set] Average loss: 794.4149169921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 634 Loss:97.82979583740234\n",
      "============\n",
      "[Validation set] Average loss: 839.3743896484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 635 Loss:97.98860931396484\n",
      "============\n",
      "[Validation set] Average loss: 795.0861206054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 636 Loss:97.52586364746094\n",
      "============\n",
      "[Validation set] Average loss: 840.247314453125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 637 Loss:97.6861343383789\n",
      "============\n",
      "[Validation set] Average loss: 795.7576293945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 638 Loss:97.21875\n",
      "============\n",
      "[Validation set] Average loss: 841.11279296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 639 Loss:97.38052368164062\n",
      "============\n",
      "[Validation set] Average loss: 796.4295654296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 640 Loss:96.90863800048828\n",
      "============\n",
      "[Validation set] Average loss: 841.970703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 641 Loss:97.07189178466797\n",
      "============\n",
      "[Validation set] Average loss: 797.1023559570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 642 Loss:96.59578704833984\n",
      "============\n",
      "[Validation set] Average loss: 842.8216552734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 643 Loss:96.76049041748047\n",
      "============\n",
      "[Validation set] Average loss: 797.7756958007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 644 Loss:96.28028106689453\n",
      "============\n",
      "[Validation set] Average loss: 843.6655883789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 645 Loss:96.44645690917969\n",
      "============\n",
      "[Validation set] Average loss: 798.4497680664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 646 Loss:95.96234130859375\n",
      "============\n",
      "[Validation set] Average loss: 844.5028076171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 647 Loss:96.12997436523438\n",
      "============\n",
      "[Validation set] Average loss: 799.1249389648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 648 Loss:95.64214324951172\n",
      "============\n",
      "[Validation set] Average loss: 845.3333740234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 649 Loss:95.81114196777344\n",
      "============\n",
      "[Validation set] Average loss: 799.801025390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 650 Loss:95.31975555419922\n",
      "============\n",
      "[Validation set] Average loss: 846.1577758789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 651 Loss:95.4902114868164\n",
      "============\n",
      "[Validation set] Average loss: 800.4782104492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 652 Loss:94.9955062866211\n",
      "============\n",
      "[Validation set] Average loss: 846.9763793945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 653 Loss:95.1672592163086\n",
      "============\n",
      "[Validation set] Average loss: 801.1567993164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 654 Loss:94.66944122314453\n",
      "============\n",
      "[Validation set] Average loss: 847.7891235351562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 655 Loss:94.8425521850586\n",
      "============\n",
      "[Validation set] Average loss: 801.8365478515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 656 Loss:94.34184265136719\n",
      "============\n",
      "[Validation set] Average loss: 848.5967407226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 657 Loss:94.51624298095703\n",
      "============\n",
      "[Validation set] Average loss: 802.5177001953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 658 Loss:94.01284790039062\n",
      "============\n",
      "[Validation set] Average loss: 849.3991088867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 659 Loss:94.18852233886719\n",
      "============\n",
      "[Validation set] Average loss: 803.2002563476562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 660 Loss:93.68264770507812\n",
      "============\n",
      "[Validation set] Average loss: 850.1969604492188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 661 Loss:93.85955810546875\n",
      "============\n",
      "[Validation set] Average loss: 803.88427734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 662 Loss:93.35143280029297\n",
      "============\n",
      "[Validation set] Average loss: 850.9902954101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 663 Loss:93.5295181274414\n",
      "============\n",
      "[Validation set] Average loss: 804.56982421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 664 Loss:93.0193862915039\n",
      "============\n",
      "[Validation set] Average loss: 851.7794799804688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 665 Loss:93.19873809814453\n",
      "============\n",
      "[Validation set] Average loss: 805.2567138671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 666 Loss:92.68692016601562\n",
      "============\n",
      "[Validation set] Average loss: 852.5650634765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 667 Loss:92.86748504638672\n",
      "============\n",
      "[Validation set] Average loss: 805.9451904296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 668 Loss:92.35409545898438\n",
      "============\n",
      "[Validation set] Average loss: 853.3468017578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 669 Loss:92.53594970703125\n",
      "============\n",
      "[Validation set] Average loss: 806.6348266601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 670 Loss:92.02120971679688\n",
      "============\n",
      "[Validation set] Average loss: 854.1254272460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 671 Loss:92.20435333251953\n",
      "============\n",
      "[Validation set] Average loss: 807.3258056640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 672 Loss:91.68853759765625\n",
      "============\n",
      "[Validation set] Average loss: 854.9014282226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 673 Loss:91.8729476928711\n",
      "============\n",
      "[Validation set] Average loss: 808.01806640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 674 Loss:91.35624694824219\n",
      "============\n",
      "[Validation set] Average loss: 855.6741333007812, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 675 Loss:91.54197692871094\n",
      "============\n",
      "[Validation set] Average loss: 808.7109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 676 Loss:91.02455139160156\n",
      "============\n",
      "[Validation set] Average loss: 856.444580078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 677 Loss:91.21165466308594\n",
      "============\n",
      "[Validation set] Average loss: 809.4050903320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 678 Loss:90.6936264038086\n",
      "============\n",
      "[Validation set] Average loss: 857.2125244140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 679 Loss:90.8821029663086\n",
      "============\n",
      "[Validation set] Average loss: 810.0999145507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 680 Loss:90.36365509033203\n",
      "============\n",
      "[Validation set] Average loss: 857.9779663085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 681 Loss:90.553466796875\n",
      "============\n",
      "[Validation set] Average loss: 810.7954711914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 682 Loss:90.03462982177734\n",
      "============\n",
      "[Validation set] Average loss: 858.7408447265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 683 Loss:90.22577667236328\n",
      "============\n",
      "[Validation set] Average loss: 811.4915771484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 684 Loss:89.70668029785156\n",
      "============\n",
      "[Validation set] Average loss: 859.5014038085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 685 Loss:89.89918518066406\n",
      "============\n",
      "[Validation set] Average loss: 812.188232421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 686 Loss:89.37987518310547\n",
      "============\n",
      "[Validation set] Average loss: 860.2596435546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 687 Loss:89.5735855102539\n",
      "============\n",
      "[Validation set] Average loss: 812.88525390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 688 Loss:89.0541763305664\n",
      "============\n",
      "[Validation set] Average loss: 861.0152587890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 689 Loss:89.24913024902344\n",
      "============\n",
      "[Validation set] Average loss: 813.5824584960938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 690 Loss:88.72956848144531\n",
      "============\n",
      "[Validation set] Average loss: 861.7680053710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 691 Loss:88.92573547363281\n",
      "============\n",
      "[Validation set] Average loss: 814.2798461914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 692 Loss:88.406005859375\n",
      "============\n",
      "[Validation set] Average loss: 862.5182495117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 693 Loss:88.60330200195312\n",
      "============\n",
      "[Validation set] Average loss: 814.9772338867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 694 Loss:88.08340454101562\n",
      "============\n",
      "[Validation set] Average loss: 863.2655029296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 695 Loss:88.28179931640625\n",
      "============\n",
      "[Validation set] Average loss: 815.6746215820312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 696 Loss:87.7617416381836\n",
      "============\n",
      "[Validation set] Average loss: 864.009521484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 697 Loss:87.96112060546875\n",
      "============\n",
      "[Validation set] Average loss: 816.3718872070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 698 Loss:87.4408950805664\n",
      "============\n",
      "[Validation set] Average loss: 864.7501831054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 699 Loss:87.64117431640625\n",
      "============\n",
      "[Validation set] Average loss: 817.0689697265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 700 Loss:87.12074279785156\n",
      "============\n",
      "[Validation set] Average loss: 865.487548828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 701 Loss:87.32188415527344\n",
      "============\n",
      "[Validation set] Average loss: 817.765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 702 Loss:86.8012466430664\n",
      "============\n",
      "[Validation set] Average loss: 866.2212524414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 703 Loss:87.00316619873047\n",
      "============\n",
      "[Validation set] Average loss: 818.4619140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 704 Loss:86.48235321044922\n",
      "============\n",
      "[Validation set] Average loss: 866.9511108398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 705 Loss:86.68501281738281\n",
      "============\n",
      "[Validation set] Average loss: 819.1575927734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 706 Loss:86.16387939453125\n",
      "============\n",
      "[Validation set] Average loss: 867.6771850585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 707 Loss:86.36720275878906\n",
      "============\n",
      "[Validation set] Average loss: 819.8524169921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 708 Loss:85.84586334228516\n",
      "============\n",
      "[Validation set] Average loss: 868.39892578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 709 Loss:86.04989624023438\n",
      "============\n",
      "[Validation set] Average loss: 820.5465698242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 710 Loss:85.52821350097656\n",
      "============\n",
      "[Validation set] Average loss: 869.1166381835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 711 Loss:85.73280334472656\n",
      "============\n",
      "[Validation set] Average loss: 821.2395629882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 712 Loss:85.21088409423828\n",
      "============\n",
      "[Validation set] Average loss: 869.8300170898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 713 Loss:85.41605377197266\n",
      "============\n",
      "[Validation set] Average loss: 821.931396484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 714 Loss:84.89384460449219\n",
      "============\n",
      "[Validation set] Average loss: 870.5389404296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 715 Loss:85.09961700439453\n",
      "============\n",
      "[Validation set] Average loss: 822.6219482421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 716 Loss:84.57706451416016\n",
      "============\n",
      "[Validation set] Average loss: 871.2431640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 717 Loss:84.78337097167969\n",
      "============\n",
      "[Validation set] Average loss: 823.3109130859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 718 Loss:84.2605209350586\n",
      "============\n",
      "[Validation set] Average loss: 871.9427490234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 719 Loss:84.46736145019531\n",
      "============\n",
      "[Validation set] Average loss: 823.9979248046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 720 Loss:83.9442367553711\n",
      "============\n",
      "[Validation set] Average loss: 872.6376342773438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 721 Loss:84.15168762207031\n",
      "============\n",
      "[Validation set] Average loss: 824.6829833984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 722 Loss:83.62828826904297\n",
      "============\n",
      "[Validation set] Average loss: 873.3277587890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 723 Loss:83.8362808227539\n",
      "============\n",
      "[Validation set] Average loss: 825.36572265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 724 Loss:83.31266784667969\n",
      "============\n",
      "[Validation set] Average loss: 874.0125122070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 725 Loss:83.5212173461914\n",
      "============\n",
      "[Validation set] Average loss: 826.0457153320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 726 Loss:82.99739837646484\n",
      "============\n",
      "[Validation set] Average loss: 874.6925659179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 727 Loss:83.20655059814453\n",
      "============\n",
      "[Validation set] Average loss: 826.7230224609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 728 Loss:82.68242645263672\n",
      "============\n",
      "[Validation set] Average loss: 875.366943359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 729 Loss:82.89210510253906\n",
      "============\n",
      "[Validation set] Average loss: 827.3973388671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 730 Loss:82.36769104003906\n",
      "============\n",
      "[Validation set] Average loss: 876.0363159179688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 731 Loss:82.57803344726562\n",
      "============\n",
      "[Validation set] Average loss: 828.0682373046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 732 Loss:82.05340576171875\n",
      "============\n",
      "[Validation set] Average loss: 876.6998291015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 733 Loss:82.26427459716797\n",
      "============\n",
      "[Validation set] Average loss: 828.7354736328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 734 Loss:81.73939514160156\n",
      "============\n",
      "[Validation set] Average loss: 877.357666015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 735 Loss:81.9508285522461\n",
      "============\n",
      "[Validation set] Average loss: 829.3990478515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 736 Loss:81.42566680908203\n",
      "============\n",
      "[Validation set] Average loss: 878.0095825195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 737 Loss:81.63758850097656\n",
      "============\n",
      "[Validation set] Average loss: 830.0587158203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 738 Loss:81.1121597290039\n",
      "============\n",
      "[Validation set] Average loss: 878.656005859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 739 Loss:81.32454681396484\n",
      "============\n",
      "[Validation set] Average loss: 830.7142333984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 740 Loss:80.79888916015625\n",
      "============\n",
      "[Validation set] Average loss: 879.2958374023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 741 Loss:81.01177215576172\n",
      "============\n",
      "[Validation set] Average loss: 831.365234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 742 Loss:80.48575592041016\n",
      "============\n",
      "[Validation set] Average loss: 879.9293823242188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 743 Loss:80.69904327392578\n",
      "============\n",
      "[Validation set] Average loss: 832.0120239257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 744 Loss:80.17266845703125\n",
      "============\n",
      "[Validation set] Average loss: 880.556396484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 745 Loss:80.38633728027344\n",
      "============\n",
      "[Validation set] Average loss: 832.6541748046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 746 Loss:79.85967254638672\n",
      "============\n",
      "[Validation set] Average loss: 881.1773681640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 747 Loss:80.07367706298828\n",
      "============\n",
      "[Validation set] Average loss: 833.2919921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 748 Loss:79.54669189453125\n",
      "============\n",
      "[Validation set] Average loss: 881.791748046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 749 Loss:79.7608413696289\n",
      "============\n",
      "[Validation set] Average loss: 833.9248046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 750 Loss:79.23358154296875\n",
      "============\n",
      "[Validation set] Average loss: 882.39892578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 751 Loss:79.44788360595703\n",
      "============\n",
      "[Validation set] Average loss: 834.5534057617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 752 Loss:78.92034149169922\n",
      "============\n",
      "[Validation set] Average loss: 883.0001220703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 753 Loss:79.13471984863281\n",
      "============\n",
      "[Validation set] Average loss: 835.177490234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 754 Loss:78.60692596435547\n",
      "============\n",
      "[Validation set] Average loss: 883.5942993164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 755 Loss:78.82125091552734\n",
      "============\n",
      "[Validation set] Average loss: 835.7971801757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 756 Loss:78.29325103759766\n",
      "============\n",
      "[Validation set] Average loss: 884.1820678710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 757 Loss:78.50749206542969\n",
      "============\n",
      "[Validation set] Average loss: 836.4125366210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 758 Loss:77.97932434082031\n",
      "============\n",
      "[Validation set] Average loss: 884.76318359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 759 Loss:78.1933822631836\n",
      "============\n",
      "[Validation set] Average loss: 837.0233764648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 760 Loss:77.66514587402344\n",
      "============\n",
      "[Validation set] Average loss: 885.3380737304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 761 Loss:77.8789291381836\n",
      "============\n",
      "[Validation set] Average loss: 837.6301879882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 762 Loss:77.3507308959961\n",
      "============\n",
      "[Validation set] Average loss: 885.906494140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 763 Loss:77.56422424316406\n",
      "============\n",
      "[Validation set] Average loss: 838.23291015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 764 Loss:77.03616333007812\n",
      "============\n",
      "[Validation set] Average loss: 886.468994140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 765 Loss:77.24927520751953\n",
      "============\n",
      "[Validation set] Average loss: 838.8316650390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 766 Loss:76.72151947021484\n",
      "============\n",
      "[Validation set] Average loss: 887.0256958007812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 767 Loss:76.93412780761719\n",
      "============\n",
      "[Validation set] Average loss: 839.4265747070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 768 Loss:76.40670776367188\n",
      "============\n",
      "[Validation set] Average loss: 887.5765991210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 769 Loss:76.61891174316406\n",
      "============\n",
      "[Validation set] Average loss: 840.017578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 770 Loss:76.0920181274414\n",
      "============\n",
      "[Validation set] Average loss: 888.1221923828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 771 Loss:76.30369567871094\n",
      "============\n",
      "[Validation set] Average loss: 840.6051635742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 772 Loss:75.77751159667969\n",
      "============\n",
      "[Validation set] Average loss: 888.6624145507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 773 Loss:75.98868560791016\n",
      "============\n",
      "[Validation set] Average loss: 841.1887817382812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 774 Loss:75.46330261230469\n",
      "============\n",
      "[Validation set] Average loss: 889.1978759765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 775 Loss:75.67395782470703\n",
      "============\n",
      "[Validation set] Average loss: 841.7689208984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 776 Loss:75.14957427978516\n",
      "============\n",
      "[Validation set] Average loss: 889.7289428710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 777 Loss:75.35972595214844\n",
      "============\n",
      "[Validation set] Average loss: 842.345458984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 778 Loss:74.83649444580078\n",
      "============\n",
      "[Validation set] Average loss: 890.2553100585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 779 Loss:75.04605865478516\n",
      "============\n",
      "[Validation set] Average loss: 842.9183349609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 780 Loss:74.52415466308594\n",
      "============\n",
      "[Validation set] Average loss: 890.7776489257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 781 Loss:74.7332534790039\n",
      "============\n",
      "[Validation set] Average loss: 843.4879760742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 782 Loss:74.2127914428711\n",
      "============\n",
      "[Validation set] Average loss: 891.2965087890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 783 Loss:74.42140197753906\n",
      "============\n",
      "[Validation set] Average loss: 844.0540771484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 784 Loss:73.90255737304688\n",
      "============\n",
      "[Validation set] Average loss: 891.8112182617188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 785 Loss:74.11064910888672\n",
      "============\n",
      "[Validation set] Average loss: 844.6168212890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 786 Loss:73.59353637695312\n",
      "============\n",
      "[Validation set] Average loss: 892.3228759765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 787 Loss:73.80113983154297\n",
      "============\n",
      "[Validation set] Average loss: 845.1757202148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 788 Loss:73.28581237792969\n",
      "============\n",
      "[Validation set] Average loss: 892.8312377929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 789 Loss:73.49293518066406\n",
      "============\n",
      "[Validation set] Average loss: 845.7312622070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 790 Loss:72.97962951660156\n",
      "============\n",
      "[Validation set] Average loss: 893.3364868164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 791 Loss:73.18636322021484\n",
      "============\n",
      "[Validation set] Average loss: 846.283447265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 792 Loss:72.67510223388672\n",
      "============\n",
      "[Validation set] Average loss: 893.8390502929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 793 Loss:72.88140106201172\n",
      "============\n",
      "[Validation set] Average loss: 846.8319091796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 794 Loss:72.37226867675781\n",
      "============\n",
      "[Validation set] Average loss: 894.3388671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 795 Loss:72.57813262939453\n",
      "============\n",
      "[Validation set] Average loss: 847.3770751953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 796 Loss:72.07123565673828\n",
      "============\n",
      "[Validation set] Average loss: 894.836181640625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 797 Loss:72.27664184570312\n",
      "============\n",
      "[Validation set] Average loss: 847.9185180664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 798 Loss:71.77200317382812\n",
      "============\n",
      "[Validation set] Average loss: 895.330810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 799 Loss:71.97697448730469\n",
      "============\n",
      "[Validation set] Average loss: 848.4567260742188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 800 Loss:71.47467803955078\n",
      "============\n",
      "[Validation set] Average loss: 895.8234252929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 801 Loss:71.67930603027344\n",
      "============\n",
      "[Validation set] Average loss: 848.9911499023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 802 Loss:71.17939758300781\n",
      "============\n",
      "[Validation set] Average loss: 896.3134765625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 803 Loss:71.383544921875\n",
      "============\n",
      "[Validation set] Average loss: 849.5223388671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 804 Loss:70.8860855102539\n",
      "============\n",
      "[Validation set] Average loss: 896.801513671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 805 Loss:71.08980560302734\n",
      "============\n",
      "[Validation set] Average loss: 850.0497436523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 806 Loss:70.59481811523438\n",
      "============\n",
      "[Validation set] Average loss: 897.2872924804688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 807 Loss:70.798095703125\n",
      "============\n",
      "[Validation set] Average loss: 850.5736694335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 808 Loss:70.30553436279297\n",
      "============\n",
      "[Validation set] Average loss: 897.77099609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 809 Loss:70.50843048095703\n",
      "============\n",
      "[Validation set] Average loss: 851.094482421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 810 Loss:70.0183334350586\n",
      "============\n",
      "[Validation set] Average loss: 898.252685546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 811 Loss:70.22078704833984\n",
      "============\n",
      "[Validation set] Average loss: 851.6112670898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 812 Loss:69.73323822021484\n",
      "============\n",
      "[Validation set] Average loss: 898.732421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 813 Loss:69.93525695800781\n",
      "============\n",
      "[Validation set] Average loss: 852.1248779296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 814 Loss:69.45022583007812\n",
      "============\n",
      "[Validation set] Average loss: 899.2102661132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 815 Loss:69.65187072753906\n",
      "============\n",
      "[Validation set] Average loss: 852.6349487304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 816 Loss:69.16939544677734\n",
      "============\n",
      "[Validation set] Average loss: 899.6861572265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 817 Loss:69.37061309814453\n",
      "============\n",
      "[Validation set] Average loss: 853.1414794921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 818 Loss:68.89065551757812\n",
      "============\n",
      "[Validation set] Average loss: 900.1602172851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 819 Loss:69.09140014648438\n",
      "============\n",
      "[Validation set] Average loss: 853.6446533203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 820 Loss:68.61395263671875\n",
      "============\n",
      "[Validation set] Average loss: 900.6323852539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 821 Loss:68.81433868408203\n",
      "============\n",
      "[Validation set] Average loss: 854.144287109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 822 Loss:68.33943176269531\n",
      "============\n",
      "[Validation set] Average loss: 901.1029052734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 823 Loss:68.53935241699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "[Validation set] Average loss: 854.6405029296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 824 Loss:68.06700897216797\n",
      "============\n",
      "[Validation set] Average loss: 901.5716552734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 825 Loss:68.26656341552734\n",
      "============\n",
      "[Validation set] Average loss: 855.1332397460938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 826 Loss:67.79669189453125\n",
      "============\n",
      "[Validation set] Average loss: 902.03857421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 827 Loss:67.995849609375\n",
      "============\n",
      "[Validation set] Average loss: 855.6226196289062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 828 Loss:67.52850341796875\n",
      "============\n",
      "[Validation set] Average loss: 902.50390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 829 Loss:67.72724151611328\n",
      "============\n",
      "[Validation set] Average loss: 856.1085815429688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 830 Loss:67.26238250732422\n",
      "============\n",
      "[Validation set] Average loss: 902.967529296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 831 Loss:67.46075439453125\n",
      "============\n",
      "[Validation set] Average loss: 856.5912475585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 832 Loss:66.9983901977539\n",
      "============\n",
      "[Validation set] Average loss: 903.4296264648438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 833 Loss:67.19635009765625\n",
      "============\n",
      "[Validation set] Average loss: 857.0703735351562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 834 Loss:66.73644256591797\n",
      "============\n",
      "[Validation set] Average loss: 903.8899536132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 835 Loss:66.93402862548828\n",
      "============\n",
      "[Validation set] Average loss: 857.5460205078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 836 Loss:66.47659301757812\n",
      "============\n",
      "[Validation set] Average loss: 904.3484497070312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 837 Loss:66.673828125\n",
      "============\n",
      "[Validation set] Average loss: 858.0186157226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 838 Loss:66.21880340576172\n",
      "============\n",
      "[Validation set] Average loss: 904.8057250976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 839 Loss:66.41569519042969\n",
      "============\n",
      "[Validation set] Average loss: 858.4876708984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 840 Loss:65.9631118774414\n",
      "============\n",
      "[Validation set] Average loss: 905.2611694335938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 841 Loss:66.15961456298828\n",
      "============\n",
      "[Validation set] Average loss: 858.9534301757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 842 Loss:65.70942687988281\n",
      "============\n",
      "[Validation set] Average loss: 905.7149658203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 843 Loss:65.90563201904297\n",
      "============\n",
      "[Validation set] Average loss: 859.416015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 844 Loss:65.4577865600586\n",
      "============\n",
      "[Validation set] Average loss: 906.16748046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 845 Loss:65.65362548828125\n",
      "============\n",
      "[Validation set] Average loss: 859.8751220703125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 846 Loss:65.2081298828125\n",
      "============\n",
      "[Validation set] Average loss: 906.6182250976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 847 Loss:65.40370178222656\n",
      "============\n",
      "[Validation set] Average loss: 860.3309936523438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 848 Loss:64.96051025390625\n",
      "============\n",
      "[Validation set] Average loss: 907.0675048828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 849 Loss:65.1557846069336\n",
      "============\n",
      "[Validation set] Average loss: 860.7836303710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 850 Loss:64.71492004394531\n",
      "============\n",
      "[Validation set] Average loss: 907.5149536132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 851 Loss:64.90986633300781\n",
      "============\n",
      "[Validation set] Average loss: 861.2328491210938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 852 Loss:64.47122192382812\n",
      "============\n",
      "[Validation set] Average loss: 907.9611206054688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 853 Loss:64.66588592529297\n",
      "============\n",
      "[Validation set] Average loss: 861.6788330078125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 854 Loss:64.22950744628906\n",
      "============\n",
      "[Validation set] Average loss: 908.4055786132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 855 Loss:64.42391204833984\n",
      "============\n",
      "[Validation set] Average loss: 862.12158203125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 856 Loss:63.98967361450195\n",
      "============\n",
      "[Validation set] Average loss: 908.8485107421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 857 Loss:64.18379211425781\n",
      "============\n",
      "[Validation set] Average loss: 862.5611572265625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 858 Loss:63.751800537109375\n",
      "============\n",
      "[Validation set] Average loss: 909.2896118164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 859 Loss:63.945648193359375\n",
      "============\n",
      "[Validation set] Average loss: 862.9974365234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 860 Loss:63.51578903198242\n",
      "============\n",
      "[Validation set] Average loss: 909.7291870117188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 861 Loss:63.70943069458008\n",
      "============\n",
      "[Validation set] Average loss: 863.4304809570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 862 Loss:63.28168869018555\n",
      "============\n",
      "[Validation set] Average loss: 910.167236328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 863 Loss:63.4750862121582\n",
      "============\n",
      "[Validation set] Average loss: 863.8602294921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 864 Loss:63.049415588378906\n",
      "============\n",
      "[Validation set] Average loss: 910.6036987304688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 865 Loss:63.24256896972656\n",
      "============\n",
      "[Validation set] Average loss: 864.2868041992188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 866 Loss:62.81895446777344\n",
      "============\n",
      "[Validation set] Average loss: 911.0380859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 867 Loss:63.01191329956055\n",
      "============\n",
      "[Validation set] Average loss: 864.7097778320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 868 Loss:62.59034729003906\n",
      "============\n",
      "[Validation set] Average loss: 911.4711303710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 869 Loss:62.78305435180664\n",
      "============\n",
      "[Validation set] Average loss: 865.1300048828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 870 Loss:62.36344528198242\n",
      "============\n",
      "[Validation set] Average loss: 911.9022216796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 871 Loss:62.555965423583984\n",
      "============\n",
      "[Validation set] Average loss: 865.5466918945312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 872 Loss:62.13835906982422\n",
      "============\n",
      "[Validation set] Average loss: 912.3316040039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 873 Loss:62.33063888549805\n",
      "============\n",
      "[Validation set] Average loss: 865.9598999023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 874 Loss:61.914947509765625\n",
      "============\n",
      "[Validation set] Average loss: 912.7589721679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 875 Loss:62.107059478759766\n",
      "============\n",
      "[Validation set] Average loss: 866.370361328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 876 Loss:61.69321823120117\n",
      "============\n",
      "[Validation set] Average loss: 913.1846923828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 877 Loss:61.88510513305664\n",
      "============\n",
      "[Validation set] Average loss: 866.7771606445312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 878 Loss:61.47311782836914\n",
      "============\n",
      "[Validation set] Average loss: 913.6082153320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 879 Loss:61.664817810058594\n",
      "============\n",
      "[Validation set] Average loss: 867.1808471679688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 880 Loss:61.25465774536133\n",
      "============\n",
      "[Validation set] Average loss: 914.0296630859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 881 Loss:61.44614791870117\n",
      "============\n",
      "[Validation set] Average loss: 867.5810546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 882 Loss:61.03779983520508\n",
      "============\n",
      "[Validation set] Average loss: 914.4494018554688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 883 Loss:61.22909164428711\n",
      "============\n",
      "[Validation set] Average loss: 867.97802734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 884 Loss:60.822547912597656\n",
      "============\n",
      "[Validation set] Average loss: 914.8666381835938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 885 Loss:61.01367950439453\n",
      "============\n",
      "[Validation set] Average loss: 868.3713989257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 886 Loss:60.60881805419922\n",
      "============\n",
      "[Validation set] Average loss: 915.281982421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 887 Loss:60.79973602294922\n",
      "============\n",
      "[Validation set] Average loss: 868.7617797851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 888 Loss:60.396583557128906\n",
      "============\n",
      "[Validation set] Average loss: 915.6948852539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 889 Loss:60.58732223510742\n",
      "============\n",
      "[Validation set] Average loss: 869.1483154296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 890 Loss:60.185874938964844\n",
      "============\n",
      "[Validation set] Average loss: 916.1052856445312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 891 Loss:60.37639617919922\n",
      "============\n",
      "[Validation set] Average loss: 869.5316162109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 892 Loss:59.97659683227539\n",
      "============\n",
      "[Validation set] Average loss: 916.513671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 893 Loss:60.16696548461914\n",
      "============\n",
      "[Validation set] Average loss: 869.9112548828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 894 Loss:59.76877975463867\n",
      "============\n",
      "[Validation set] Average loss: 916.9192504882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 895 Loss:59.95891189575195\n",
      "============\n",
      "[Validation set] Average loss: 870.2874145507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 896 Loss:59.56230545043945\n",
      "============\n",
      "[Validation set] Average loss: 917.3222045898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 897 Loss:59.75220489501953\n",
      "============\n",
      "[Validation set] Average loss: 870.6600952148438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 898 Loss:59.35713195800781\n",
      "============\n",
      "[Validation set] Average loss: 917.7222290039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 899 Loss:59.54684066772461\n",
      "============\n",
      "[Validation set] Average loss: 871.029052734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 900 Loss:59.153289794921875\n",
      "============\n",
      "[Validation set] Average loss: 918.1195678710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 901 Loss:59.34274673461914\n",
      "============\n",
      "[Validation set] Average loss: 871.394287109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 902 Loss:58.9506950378418\n",
      "============\n",
      "[Validation set] Average loss: 918.513916015625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 903 Loss:59.139984130859375\n",
      "============\n",
      "[Validation set] Average loss: 871.7559204101562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 904 Loss:58.749412536621094\n",
      "============\n",
      "[Validation set] Average loss: 918.9052124023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 905 Loss:58.93842315673828\n",
      "============\n",
      "[Validation set] Average loss: 872.11376953125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 906 Loss:58.5493049621582\n",
      "============\n",
      "[Validation set] Average loss: 919.2933349609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 907 Loss:58.73812484741211\n",
      "============\n",
      "[Validation set] Average loss: 872.4675903320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 908 Loss:58.35041046142578\n",
      "============\n",
      "[Validation set] Average loss: 919.6780395507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 909 Loss:58.53897476196289\n",
      "============\n",
      "[Validation set] Average loss: 872.8176879882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 910 Loss:58.152645111083984\n",
      "============\n",
      "[Validation set] Average loss: 920.0594482421875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 911 Loss:58.340938568115234\n",
      "============\n",
      "[Validation set] Average loss: 873.1636962890625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 912 Loss:57.95601272583008\n",
      "============\n",
      "[Validation set] Average loss: 920.4370727539062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 913 Loss:58.14403533935547\n",
      "============\n",
      "[Validation set] Average loss: 873.5057983398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 914 Loss:57.76042938232422\n",
      "============\n",
      "[Validation set] Average loss: 920.8109130859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 915 Loss:57.948184967041016\n",
      "============\n",
      "[Validation set] Average loss: 873.84375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 916 Loss:57.565895080566406\n",
      "============\n",
      "[Validation set] Average loss: 921.1810302734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 917 Loss:57.75339126586914\n",
      "============\n",
      "[Validation set] Average loss: 874.1776733398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 918 Loss:57.37239456176758\n",
      "============\n",
      "[Validation set] Average loss: 921.5472412109375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 919 Loss:57.559608459472656\n",
      "============\n",
      "[Validation set] Average loss: 874.5073852539062, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 920 Loss:57.17987823486328\n",
      "============\n",
      "[Validation set] Average loss: 921.9093017578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 921 Loss:57.366817474365234\n",
      "============\n",
      "[Validation set] Average loss: 874.832763671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 922 Loss:56.98832321166992\n",
      "============\n",
      "[Validation set] Average loss: 922.2670288085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 923 Loss:57.17494583129883\n",
      "============\n",
      "[Validation set] Average loss: 875.154052734375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 924 Loss:56.79764938354492\n",
      "============\n",
      "[Validation set] Average loss: 922.6204833984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 925 Loss:56.983943939208984\n",
      "============\n",
      "[Validation set] Average loss: 875.4707641601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 926 Loss:56.60782241821289\n",
      "============\n",
      "[Validation set] Average loss: 922.9693603515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 927 Loss:56.79378128051758\n",
      "============\n",
      "[Validation set] Average loss: 875.7832641601562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 928 Loss:56.41887283325195\n",
      "============\n",
      "[Validation set] Average loss: 923.3135375976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 929 Loss:56.60454559326172\n",
      "============\n",
      "[Validation set] Average loss: 876.09130859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 930 Loss:56.23075485229492\n",
      "============\n",
      "[Validation set] Average loss: 923.653076171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 931 Loss:56.41609573364258\n",
      "============\n",
      "[Validation set] Average loss: 876.3950805664062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 932 Loss:56.04338836669922\n",
      "============\n",
      "[Validation set] Average loss: 923.98779296875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 933 Loss:56.22840118408203\n",
      "============\n",
      "[Validation set] Average loss: 876.6942749023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 934 Loss:55.8568000793457\n",
      "============\n",
      "[Validation set] Average loss: 924.3176879882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 935 Loss:56.04143524169922\n",
      "============\n",
      "[Validation set] Average loss: 876.9892578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 936 Loss:55.670875549316406\n",
      "============\n",
      "[Validation set] Average loss: 924.6424560546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 937 Loss:55.855133056640625\n",
      "============\n",
      "[Validation set] Average loss: 877.2796020507812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 938 Loss:55.485633850097656\n",
      "============\n",
      "[Validation set] Average loss: 924.9623413085938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 939 Loss:55.66956329345703\n",
      "============\n",
      "[Validation set] Average loss: 877.5660400390625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 940 Loss:55.301090240478516\n",
      "============\n",
      "[Validation set] Average loss: 925.2772216796875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 941 Loss:55.4846305847168\n",
      "============\n",
      "[Validation set] Average loss: 877.8479614257812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 942 Loss:55.117103576660156\n",
      "============\n",
      "[Validation set] Average loss: 925.5869750976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 943 Loss:55.30027770996094\n",
      "============\n",
      "[Validation set] Average loss: 878.1257934570312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 944 Loss:54.933719635009766\n",
      "============\n",
      "[Validation set] Average loss: 925.8916625976562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 945 Loss:55.11655044555664\n",
      "============\n",
      "[Validation set] Average loss: 878.3995361328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 946 Loss:54.75092697143555\n",
      "============\n",
      "[Validation set] Average loss: 926.19140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 947 Loss:54.93342208862305\n",
      "============\n",
      "[Validation set] Average loss: 878.6693725585938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 948 Loss:54.56871032714844\n",
      "============\n",
      "[Validation set] Average loss: 926.486328125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 949 Loss:54.750823974609375\n",
      "============\n",
      "[Validation set] Average loss: 878.9354248046875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 950 Loss:54.38699722290039\n",
      "============\n",
      "[Validation set] Average loss: 926.7765502929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 951 Loss:54.56876754760742\n",
      "============\n",
      "[Validation set] Average loss: 879.1976318359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 952 Loss:54.20581817626953\n",
      "============\n",
      "[Validation set] Average loss: 927.0618896484375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 953 Loss:54.38722610473633\n",
      "============\n",
      "[Validation set] Average loss: 879.4564208984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 954 Loss:54.025169372558594\n",
      "============\n",
      "[Validation set] Average loss: 927.3427124023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 955 Loss:54.206233978271484\n",
      "============\n",
      "[Validation set] Average loss: 879.711669921875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 956 Loss:53.844974517822266\n",
      "============\n",
      "[Validation set] Average loss: 927.6189575195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 957 Loss:54.02568435668945\n",
      "============\n",
      "[Validation set] Average loss: 879.9639282226562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 958 Loss:53.66523742675781\n",
      "============\n",
      "[Validation set] Average loss: 927.8912353515625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 959 Loss:53.845638275146484\n",
      "============\n",
      "[Validation set] Average loss: 880.2133178710938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 960 Loss:53.485984802246094\n",
      "============\n",
      "[Validation set] Average loss: 928.1593017578125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 961 Loss:53.66603088378906\n",
      "============\n",
      "[Validation set] Average loss: 880.4598999023438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 962 Loss:53.307167053222656\n",
      "============\n",
      "[Validation set] Average loss: 928.4234008789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 963 Loss:53.48691177368164\n",
      "============\n",
      "[Validation set] Average loss: 880.7037963867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 964 Loss:53.12881851196289\n",
      "============\n",
      "[Validation set] Average loss: 928.6839599609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 965 Loss:53.308250427246094\n",
      "============\n",
      "[Validation set] Average loss: 880.9456176757812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 966 Loss:52.95090866088867\n",
      "============\n",
      "[Validation set] Average loss: 928.9409790039062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 967 Loss:53.13007354736328\n",
      "============\n",
      "[Validation set] Average loss: 881.18505859375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 968 Loss:52.77347183227539\n",
      "============\n",
      "[Validation set] Average loss: 929.195068359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 969 Loss:52.95238494873047\n",
      "============\n",
      "[Validation set] Average loss: 881.4227905273438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 970 Loss:52.596519470214844\n",
      "============\n",
      "[Validation set] Average loss: 929.4459838867188, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 971 Loss:52.77519607543945\n",
      "============\n",
      "[Validation set] Average loss: 881.6587524414062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 972 Loss:52.42003631591797\n",
      "============\n",
      "[Validation set] Average loss: 929.6942138671875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 973 Loss:52.59848403930664\n",
      "============\n",
      "[Validation set] Average loss: 881.8934326171875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 974 Loss:52.24401092529297\n",
      "============\n",
      "[Validation set] Average loss: 929.93994140625, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 975 Loss:52.42223358154297\n",
      "============\n",
      "[Validation set] Average loss: 882.1268920898438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 976 Loss:52.06848907470703\n",
      "============\n",
      "[Validation set] Average loss: 930.1834106445312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 977 Loss:52.24650573730469\n",
      "============\n",
      "[Validation set] Average loss: 882.359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 978 Loss:51.893436431884766\n",
      "============\n",
      "[Validation set] Average loss: 930.4249877929688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 979 Loss:52.0712890625\n",
      "============\n",
      "[Validation set] Average loss: 882.5909423828125, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 980 Loss:51.71885681152344\n",
      "============\n",
      "[Validation set] Average loss: 930.6646118164062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 981 Loss:51.89653396606445\n",
      "============\n",
      "[Validation set] Average loss: 882.8218383789062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 982 Loss:51.5448112487793\n",
      "============\n",
      "[Validation set] Average loss: 930.9027709960938, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 983 Loss:51.72238540649414\n",
      "============\n",
      "[Validation set] Average loss: 883.052490234375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 984 Loss:51.37128829956055\n",
      "============\n",
      "[Validation set] Average loss: 931.1394653320312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 985 Loss:51.548702239990234\n",
      "============\n",
      "[Validation set] Average loss: 883.282958984375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 986 Loss:51.198219299316406\n",
      "============\n",
      "[Validation set] Average loss: 931.375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 987 Loss:51.37553405761719\n",
      "============\n",
      "[Validation set] Average loss: 883.51318359375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 988 Loss:51.025665283203125\n",
      "============\n",
      "[Validation set] Average loss: 931.6094360351562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 989 Loss:51.20287322998047\n",
      "============\n",
      "[Validation set] Average loss: 883.7434692382812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 990 Loss:50.85365295410156\n",
      "============\n",
      "[Validation set] Average loss: 931.8430786132812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 991 Loss:51.03075408935547\n",
      "============\n",
      "[Validation set] Average loss: 883.9739379882812, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 992 Loss:50.68215560913086\n",
      "============\n",
      "[Validation set] Average loss: 932.0761108398438, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 993 Loss:50.859214782714844\n",
      "============\n",
      "[Validation set] Average loss: 884.2048950195312, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 994 Loss:50.511207580566406\n",
      "============\n",
      "[Validation set] Average loss: 932.3086547851562, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 995 Loss:50.688209533691406\n",
      "============\n",
      "[Validation set] Average loss: 884.4360961914062, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 996 Loss:50.34080505371094\n",
      "============\n",
      "[Validation set] Average loss: 932.5408935546875, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 997 Loss:50.517784118652344\n",
      "============\n",
      "[Validation set] Average loss: 884.667724609375, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 998 Loss:50.171016693115234\n",
      "============\n",
      "[Validation set] Average loss: 932.7726440429688, Accuracy: nu exista la regresii%\n",
      "============\n",
      "Train Epoch: 999 Loss:50.347965240478516\n",
      "============\n",
      "[Validation set] Average loss: 884.9002685546875, Accuracy: nu exista la regresii%\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "#după fiecare epocă de train() verificăm rezultatele pe setul de validare\n",
    "for epoch in range(1000):\n",
    "  train(epoch)\n",
    "  validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNO72JVEjVy1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f68b887ae90>,\n",
       " <matplotlib.lines.Line2D at 0x7f68b88710d0>]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printăm comparativ cu roșu loss-ul de pe setul de validare și cu albastru loss-ul de pe setul de validare.\n",
    "plt.plot(losses, \"r-\", test_losses, \"b-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9oNbLYZfSTU"
   },
   "outputs": [],
   "source": [
    "def try_a_single_example_with_the_network(index_from_the_validation_set):\n",
    "  with torch.no_grad():\n",
    "    preds_y = net(X_test[index_from_the_validation_set])\n",
    "    print(preds_y)\n",
    "    print(y_test[index_from_the_validation_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnsqqEqMuI67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([106.8545])\n",
      "tensor([101.])\n"
     ]
    }
   ],
   "source": [
    "try_a_single_example_with_the_network(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVbvWrE2uI9q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwjpjFuifSTi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SimpleHeartDiseasePytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
